IssueComment
  { issueCommentUpdatedAt = 2013 (-04) (-05) 03 : 31 : 39 UTC
  , issueCommentUser =
      SimpleUser
        { simpleUserId = Id 646357
        , simpleUserLogin = N "wmrowan"
        , simpleUserAvatarUrl =
            "https://avatars.githubusercontent.com/u/646357?v=3"
        , simpleUserUrl = "https://api.github.com/users/wmrowan"
        , simpleUserType = OwnerUser
        }
  , issueCommentUrl =
      "https://api.github.com/repos/rethinkdb/rethinkdb/issues/comments/15937440"
  , issueCommentHtmlUrl =
      "https://github.com/rethinkdb/rethinkdb/issues/612#issuecomment-15937440"
  , issueCommentCreatedAt = 2013 (-04) (-05) 03 : 31 : 39 UTC
  , issueCommentBody =
      "I almost forgot, the other reason why we don't do this is because it bounds the memory usage of RethinkDB client applications (or at least it will when we switch from row count based batching to result set size based batching). If we eagerly load results faster than we're processing them for a huge dataset we may swamp the application server with data."
  , issueCommentId = 15937440
  }