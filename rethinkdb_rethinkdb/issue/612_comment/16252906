IssueComment
  { issueCommentUpdatedAt = 2013 (-04) (-11) 18 : 33 : 23 UTC
  , issueCommentUser =
      SimpleUser
        { simpleUserId = Id 646357
        , simpleUserLogin = N "wmrowan"
        , simpleUserAvatarUrl =
            "https://avatars.githubusercontent.com/u/646357?v=3"
        , simpleUserUrl = "https://api.github.com/users/wmrowan"
        , simpleUserType = OwnerUser
        }
  , issueCommentUrl =
      "https://api.github.com/repos/rethinkdb/rethinkdb/issues/comments/16252906"
  , issueCommentHtmlUrl =
      "https://github.com/rethinkdb/rethinkdb/issues/612#issuecomment-16252906"
  , issueCommentCreatedAt = 2013 (-04) (-11) 18 : 33 : 23 UTC
  , issueCommentBody =
      "Yes. Large result sets are currently batched by 1000 rows. The client is responsible for requesting the next batch for a given query but can initiate new queries at any time. Unique query tokens are used to separate new requests from requests for the next chunk of an older query."
  , issueCommentId = 16252906
  }