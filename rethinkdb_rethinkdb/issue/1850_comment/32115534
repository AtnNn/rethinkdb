IssueComment
  { issueCommentUpdatedAt = 2014 (-01) (-12) 05 : 10 : 18 UTC
  , issueCommentUser =
      SimpleUser
        { simpleUserId = Id 297060
        , simpleUserLogin = N "nviennot"
        , simpleUserAvatarUrl =
            "https://avatars.githubusercontent.com/u/297060?v=3"
        , simpleUserUrl = "https://api.github.com/users/nviennot"
        , simpleUserType = OwnerUser
        }
  , issueCommentUrl =
      "https://api.github.com/repos/rethinkdb/rethinkdb/issues/comments/32115534"
  , issueCommentHtmlUrl =
      "https://github.com/rethinkdb/rethinkdb/issues/1850#issuecomment-32115534"
  , issueCommentCreatedAt = 2014 (-01) (-12) 05 : 10 : 18 UTC
  , issueCommentBody =
      "@danielmewes actually with PHP, you could do it by returning EAGAIN or something if you call value and the data hasn't come just yet. The user will have to call it again at a later point it time (or just call c.wait to wait for outstanding requests).\r\n\r\nAbout the lazy parsing, You probably can parse the token + packet length with ~20 lines of dirty code, because the protobuf to parse should be super simple and fairly deterministic (If packet[0] == 'XX' would mean that it's a message respoonse, then packet[1..8] would be the token (might be packed so careful) then the length of the terms, and then you  jump to see if there are some optional stuff and you know the packet lenght. It's a bit gross, but that's what you have to do to do optimizations that I think we shouldn't need in the near future.\r\n\r\n@mlucy I recommend the studies done by @aphyr: http://aphyr.com/tags/jepsen and also one of his talk: http://www.infoq.com/presentations/partitioning-comparison to get a feel of how NoSQL databases behave in the field.\r\n\r\n"
  , issueCommentId = 32115534
  }