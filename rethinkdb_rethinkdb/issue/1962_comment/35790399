IssueComment
  { issueCommentUpdatedAt = 2014 (-02) (-22) 01 : 25 : 02 UTC
  , issueCommentUser =
      SimpleUser
        { simpleUserId = Id 505365
        , simpleUserLogin = N "danielmewes"
        , simpleUserAvatarUrl =
            "https://avatars.githubusercontent.com/u/505365?v=3"
        , simpleUserUrl = "https://api.github.com/users/danielmewes"
        , simpleUserType = OwnerUser
        }
  , issueCommentUrl =
      "https://api.github.com/repos/rethinkdb/rethinkdb/issues/comments/35790399"
  , issueCommentHtmlUrl =
      "https://github.com/rethinkdb/rethinkdb/issues/1962#issuecomment-35790399"
  , issueCommentCreatedAt = 2014 (-02) (-22) 01 : 24 : 38 UTC
  , issueCommentBody =
      "There's a small program in /home/daniel/throw_away_documents_experiment.cc that computes the average fraction of documents we throw away for a given per-shard batch size (in documents).\r\nThis is the plot (assuming 8 hash shards):\r\n![throw_away_documents](https://f.cloud.github.com/assets/505365/2236468/793d02c6-9b5f-11e3-9fcc-e349c468fb9d.png)\r\n\r\nAs a compromise between limiting memory usage when documents are very large, and not throwing away too much, a minimum batch size of 8 seems to be a reasonable choice. At that size we would throw away 27% of the documents on average. Having 8 documents per shard * 8 shards * for example 1 MB per document in memory would use 64 MB.\r\nNote that 8 would just be the *minimum* batch size (it's currently 1). If documents are small enough, we would have larger batches and throw away correspondingly fewer documents."
  , issueCommentId = 35790399
  }