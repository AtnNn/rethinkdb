IssueComment
  { issueCommentUpdatedAt = 2014 (-02) (-21) 23 : 40 : 43 UTC
  , issueCommentUser =
      SimpleUser
        { simpleUserId = Id 505365
        , simpleUserLogin = N "danielmewes"
        , simpleUserAvatarUrl =
            "https://avatars.githubusercontent.com/u/505365?v=3"
        , simpleUserUrl = "https://api.github.com/users/danielmewes"
        , simpleUserType = OwnerUser
        }
  , issueCommentUrl =
      "https://api.github.com/repos/rethinkdb/rethinkdb/issues/comments/35785407"
  , issueCommentHtmlUrl =
      "https://github.com/rethinkdb/rethinkdb/issues/1962#issuecomment-35785407"
  , issueCommentCreatedAt = 2014 (-02) (-21) 23 : 40 : 43 UTC
  , issueCommentBody =
      "Talked to @mlucy. Going to implement two additions to our batch size logic:\r\n- a minimum number of documents per batch. If we have very few documents, we end up throwing away a lot of data on average (see explanation in #1969). This reduces the overall efficiency.\r\n- batch sizes that increase after the first batch. That way we return the first results very quickly, but maintain efficiency if a larger amount of data is actually needed by the client."
  , issueCommentId = 35785407
  }