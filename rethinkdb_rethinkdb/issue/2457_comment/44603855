IssueComment
  { issueCommentUpdatedAt = 2014 (-05) (-30) 00 : 55 : 43 UTC
  , issueCommentUser =
      SimpleUser
        { simpleUserId = Id 48436
        , simpleUserLogin = N "coffeemug"
        , simpleUserAvatarUrl =
            "https://avatars.githubusercontent.com/u/48436?v=3"
        , simpleUserUrl = "https://api.github.com/users/coffeemug"
        , simpleUserType = OwnerUser
        }
  , issueCommentUrl =
      "https://api.github.com/repos/rethinkdb/rethinkdb/issues/comments/44603855"
  , issueCommentHtmlUrl =
      "https://github.com/rethinkdb/rethinkdb/issues/2457#issuecomment-44603855"
  , issueCommentCreatedAt = 2014 (-05) (-30) 00 : 55 : 43 UTC
  , issueCommentBody =
      "> When did you check the garbage ratio in the stats? [...] Generally, peak size while importing data also matters.\r\n\r\nI checked at the end. I agree that peak size matters, but I think there are two separate problems at work. The first is that people run an insert script, wait 'till it's done, then go check the table size. It's important to fix that first, because people who care about disk space utilization never get past this step to measure peak utilization. I think peak utilization is a very important, but secondary problem.\r\n\r\n> However the file is still 1.9 GB.\r\n\r\n@srh fixed file truncation in https://github.com/rethinkdb/rethinkdb/issues/310#issuecomment-21904841. Is this a regression?"
  , issueCommentId = 44603855
  }