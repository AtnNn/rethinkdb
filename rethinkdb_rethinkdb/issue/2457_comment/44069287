IssueComment
  { issueCommentUpdatedAt = 2014 (-05) (-23) 23 : 10 : 45 UTC
  , issueCommentUser =
      SimpleUser
        { simpleUserId = Id 2489012
        , simpleUserLogin = N "diegogub"
        , simpleUserAvatarUrl =
            "https://avatars.githubusercontent.com/u/2489012?v=3"
        , simpleUserUrl = "https://api.github.com/users/diegogub"
        , simpleUserType = OwnerUser
        }
  , issueCommentUrl =
      "https://api.github.com/repos/rethinkdb/rethinkdb/issues/comments/44069287"
  , issueCommentHtmlUrl =
      "https://github.com/rethinkdb/rethinkdb/issues/2457#issuecomment-44069287"
  , issueCommentCreatedAt = 2014 (-05) (-23) 23 : 10 : 45 UTC
  , issueCommentBody =
      "@danielmewes No, it was a new tables created for the migration. It was never used before. Thank you for your fast replies. I was considering rethinkDB mostly because easy replication and sharding. So anyway, I will evaluate if I can deal with a limited number of records per batch. And maybe start pre aggregating my data in smaller chunks and delete processed documents."
  , issueCommentId = 44069287
  }