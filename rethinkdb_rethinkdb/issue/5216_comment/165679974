IssueComment
  { issueCommentUpdatedAt = 2015 (-12) (-18) 05 : 52 : 58 UTC
  , issueCommentUser =
      SimpleUser
        { simpleUserId = Id 1777134
        , simpleUserLogin = N "mlucy"
        , simpleUserAvatarUrl =
            "https://avatars.githubusercontent.com/u/1777134?v=3"
        , simpleUserUrl = "https://api.github.com/users/mlucy"
        , simpleUserType = OwnerUser
        }
  , issueCommentUrl =
      "https://api.github.com/repos/rethinkdb/rethinkdb/issues/comments/165679974"
  , issueCommentHtmlUrl =
      "https://github.com/rethinkdb/rethinkdb/issues/5216#issuecomment-165679974"
  , issueCommentCreatedAt = 2015 (-12) (-18) 05 : 52 : 58 UTC
  , issueCommentBody =
      "I took a look at this and I think there are two problems: the first is that the `active_ranges_t` has no entries for the empty hash shards, but the other one (which is harder to catch with the test script) is that reads issued after truncating sometimes have ranges that are too small.\r\n\r\nConsider the case where you're ordering on field `A` and have two shards.  Your first read returns:\r\n\r\nShard 1: [1, 3, 5, 7] (remaining range: (7, INF))\r\nShard 2: [2, 4] (remaining range: (4, INF))\r\n\r\nWe pop off `[1, 2, 3, 4]`, but we can't pop off `5` because there might be a `4.5` on shard 2 that we didn't read.  So we're left with:\r\n\r\nShard 1: [5, 7] (remaining range: (7, INF))\r\nShard 2: [] (remaining range: (4, INF))\r\n\r\nThen we do the truncate step, and we get:\r\n\r\nShard 1: [] (remaining range: (5, INF))\r\nShard 2: [] (remaining range: (4, INF))\r\n\r\nWhile returning a `last_read_range` of (-INF, 4].\r\n\r\nThe problem is that when we issue the next read, it's still issued on a per-shard basis, so if between the two reads a value is inserted at `4.5` on Shard 1, we'll miss it.\r\n\r\nWe could patch this to work by updating the remaining range for Shard 1 to `(4, INF)` (and making sure it does something correct if you have multiple range shards), but I think that the underlying problem here is that we introduced a needlessly complicated range-recalculation step because we didn't want to have to make the changefeed logic shard-aware for the release.  I think that was a mistake in retrospect: we should probably fix this by making the changefeed logic track active ranges on a per-shard basis."
  , issueCommentId = 165679974
  }