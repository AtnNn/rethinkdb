IssueComment
  { issueCommentUpdatedAt = 2014 (-11) (-05) 23 : 43 : 16 UTC
  , issueCommentUser =
      SimpleUser
        { simpleUserId = Id 505365
        , simpleUserLogin = N "danielmewes"
        , simpleUserAvatarUrl =
            "https://avatars.githubusercontent.com/u/505365?v=3"
        , simpleUserUrl = "https://api.github.com/users/danielmewes"
        , simpleUserType = OwnerUser
        }
  , issueCommentUrl =
      "https://api.github.com/repos/rethinkdb/rethinkdb/issues/comments/61903187"
  , issueCommentHtmlUrl =
      "https://github.com/rethinkdb/rethinkdb/issues/2356#issuecomment-61903187"
  , issueCommentCreatedAt = 2014 (-11) (-05) 23 : 43 : 16 UTC
  , issueCommentBody =
      "I'm on board with some degree of automatic query optimization.\r\nDoing it well is a pretty big project though.\r\n\r\nThere seem to be three things we have to solve:\r\n* Make sure that indexed operations have the same semantics as non-indexed ones. See for example https://github.com/rethinkdb/rethinkdb/issues/1032\r\n* Find a way to maintain reliability of queries. There should be a way to make sure that if we tweak the optimizer in a later versions, queries that used to be fast don't suddenly become slower\r\n* Present the feature such that a) it's easy to use b) it doesn't break the advantages of our current explicit system and c) it doesn't raise expectations that it cannot fulfill\r\n\r\n\r\nAn option I can think of would be having a function such as `suggestOptimization(query)` that you run explicitly to get an optimized form of the given query. The optimized query is again a normal query, and you can either run it directly or have it returned and store it on the client or the server for later use.\r\n(vaguely related to adding `r.eval()` https://github.com/rethinkdb/rethinkdb/issues/1863 )"
  , issueCommentId = 61903187
  }