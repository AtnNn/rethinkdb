IssueComment
  { issueCommentUpdatedAt = 2014 (-11) (-26) 02 : 50 : 39 UTC
  , issueCommentUser =
      SimpleUser
        { simpleUserId = Id 119317
        , simpleUserLogin = N "solatis"
        , simpleUserAvatarUrl =
            "https://avatars.githubusercontent.com/u/119317?v=3"
        , simpleUserUrl = "https://api.github.com/users/solatis"
        , simpleUserType = OwnerUser
        }
  , issueCommentUrl =
      "https://api.github.com/repos/rethinkdb/rethinkdb/issues/comments/64506804"
  , issueCommentHtmlUrl =
      "https://github.com/rethinkdb/rethinkdb/issues/1973#issuecomment-64506804"
  , issueCommentCreatedAt = 2014 (-11) (-26) 02 : 35 : 46 UTC
  , issueCommentBody =
      "@timmaxw don't forget it's not just \"any\" subprocess you're launching, it's a subprocess written and maintained by the developers using RethinkDB.\r\n\r\nHaving said that, it's my experience that you'll probably need to make debugging as easy as possible with this (what are you going to do with stdout/stderr, how are developers able to provide debugging information, etc). But I can see that a command like r.pipe(\"/foo/bar/script.py\") and just leave the responsibility of \"not going out of control\" to the end-user (developer of the script).\r\n\r\nEach language, as with Hadoop, will probably needs a rethinkdb.pipes \"api\" implemented, and the website needs to clearly define that protocol (so it can be implemented for other languages). I would recommend just sticking with JSON -- I've seen other projects go the \"specialized serialization library\" route (notably Hadoop and Twitter's Storm) using Protocol Buffers or Apache Avro, and it becomes a complete mess and greatly complicates the implementation of an API. Furthermore, if performance is an issue, there are better ways to approach this."
  , issueCommentId = 64506804
  }