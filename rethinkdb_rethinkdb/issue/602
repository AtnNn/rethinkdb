Issue
  { issueClosedAt = Just 2013 (-05) (-02) 00 : 28 : 27 UTC
  , issueUpdatedAt = 2013 (-06) (-06) 22 : 02 : 35 UTC
  , issueEventsUrl =
      "https://api.github.com/repos/rethinkdb/rethinkdb/issues/602/events"
  , issueHtmlUrl =
      Just "https://github.com/rethinkdb/rethinkdb/issues/602"
  , issueClosedBy = Nothing
  , issueLabels = []
  , issueNumber = 602
  , issueAssignee =
      Just
        SimpleUser
          { simpleUserId = Id 1777134
          , simpleUserLogin = N "mlucy"
          , simpleUserAvatarUrl =
              "https://avatars.githubusercontent.com/u/1777134?v=3"
          , simpleUserUrl = "https://api.github.com/users/mlucy"
          , simpleUserType = OwnerUser
          }
  , issueUser =
      SimpleUser
        { simpleUserId = Id 646357
        , simpleUserLogin = N "wmrowan"
        , simpleUserAvatarUrl =
            "https://avatars.githubusercontent.com/u/646357?v=3"
        , simpleUserUrl = "https://api.github.com/users/wmrowan"
        , simpleUserType = OwnerUser
        }
  , issueTitle = "Secondary indices interface"
  , issuePullRequest = Nothing
  , issueUrl =
      "https://api.github.com/repos/rethinkdb/rethinkdb/issues/602"
  , issueCreatedAt = 2013 (-04) (-04) 05 : 19 : 53 UTC
  , issueBody =
      Just
        "Now that secondary indices are almost complete it's time to nail down just how it is that secondary indices will be presented to users and how they will have to use them. After a short discussion earlier today it became clear that said interface hadn't yet been settled on so I'd like to present a more fleshed out version of one of the two proposals then discussed and advocate for it's adoption.\r\n\r\nIn previous discussions we have looked to SQL both for helpful suggestions as to what users might be looking for and for warnings of what to avoid. It's thus helpful to first review how it is that SQL addresses the question of secondary index access.\r\n\r\nThe short answer is that it doesn't present secondary index directly in the interface at all. In SQL all specification of row access is done in the `WHERE` clause. In RQL the most direct analog to `WHERE` is `filter` yet RQL also presents other ways to access a table based on the value of rows, namely `get`, `between`, and eventually a combination of `order_by` plus `nth` or `slice`. These latter ways of accessing a RQL table make use of the primary index to speed up the query while `filter` is guaranteed to be linear in the size of the table. In SQL these cases are handled by the optimizer. The clause `WHERE id = 1` is identified in the query planning stage as an operation that can be assisted by an index and is automatically turned into a log(n) operation (like `get` in RQL).\r\n\r\nThere are a few problems with taking inspiration from this approach. The first is that we simply don't already have an optimizer and it would require a lot of infrastructure to be put in place to even do simple optimizations like this.\r\n\r\nA more important objection though is philosophical. RQL doesn't really need an optimizer at this point because the programmer is able to ask for the optimal behavior directly. In RQL she doesn't have to trust that the optimizer will just do the right thing, she either gets the linear behavior of `filter` or the logarithmic behavior of `get`. This enhances the clarity of queries and allows for more direct performance tuning. Furthermore, to introduce such magical behavior now for secondary indices would make them feel extremely out of place and likely confuse users as the performance characteristics of otherwise identical queries would change significantly based on the prior creation of a secondary index. It's presently possible to look at a RQL query an immediately know what's it's doing. We shouldn't destroy that merely to replicate an established but bad design.\r\n\r\nThe basis of my proposal it to replicate the existing API we've developed for sublinear access of rows based on the primary index. Again, the three ways of leveraging the primary index are `table.get(id)`, `table.between(lower, upper)` and in the future `table.order_by(key)` plus `nth` or `slice`. In a sense, `r.table` is how we reference the primary index for a table. We should similarly have a way to construct a reference to a secondary index which would then support a similar set of operations. I say similar, not identical, due to the slightly different semantics of primary and secondary indices.\r\n\r\nDepending on whether secondary indexes exist in the same namespace as primary indexes (tables) or there is a secondary index namespace per table, one would construct a secondary index reference in one of the following ways:\r\n\r\n```python\r\n# Secondary and primary indices exist in the same namespace\r\nr.table(...) # primary index reference\r\nr.sindex(...) # secondary index reference\r\n\r\n# Secondary index exist in separate table based namespaces\r\nr.table(...).sindex(...) # secondary index reference on table\r\n```\r\n\r\nI have a mild preference for the latter (per table sindex namespaces). While it results in more typing it resolves potential name conflicts (say you want each table to have a 'type' field with a secondary index based on it) and better preserves the relationship between secondary indices and parent tables.\r\n\r\nSecondary index objects would support the following API:\r\n\r\n```python\r\nsindex.get_set(key) => StreamSelection\r\nsindex.between(lower, upper) => StreamSelection\r\n\r\n# The use of `ordered` in place of `order_by` is\r\n# actually a separate proposal and is only included\r\n# here for completeness.\r\nsindex.ordered() => StreamSelection\r\n```\r\n\r\nThe main divergence from our primary index API is the use of `get_set` inplace of `get`. This is because key values in secondary indices are not guaranteed to be unique so we must be prepared to handle a stream of rows from the table with that key value.\r\n\r\nThere are some important open questions here that I would like specific feedback on. The first relates to that divergence between `get` and `get_set`. I would also like to propose implementing both `get` and `get_set` on both primary and secondary index references (i.e. make them both polymorphic). `get_set` on a primary index would return either the empty stream or a stream with one element. `get` on a secondary index would either return an error when there are more than one results in the result set or would return an arbitrary element from the set in that case. This would allow primary and secondary indices to be used interchangeably in many situations as well as simplifying use of primary indices even without consideration of the secondary sort. See below for a good example of how this is useful in `eq_join`.\r\n\r\nThe second is whether we want `between` to be polymorphic on both index types or have a separate name for each. Though in this case they both support the same output type their performance characteristics are slightly different (`between` on a secondary index adds a multiplicative log(n) to the runtime). Making `between` polymorphic thus slightly clouds the performance clarity of affected queries though increases flexibility (see the argument for `get_set` above). My slight preference is to make `between` polymorphic despite this drawback.\r\n\r\nThe third is whether secondary index objects also support the other operations of primary indices. These fall into two groups, the sequence operations that treat a table as a stream and the update operations that modify the underlying table. In both cases, these operations could transparently treat a secondary index object as synonymous with the underlying table. There is precedent for this if you consider such operations on a primary index reference as again bypassing the index for the underlying table, treating it as just a collection of rows on disk and not as an ordered, queryable set.\r\n\r\nAll three of these open questions are related for when taken together they imply interchangeability between primary and secondary index references. This turns out to be quite powerful and is perhaps the best argument for this proposal over the alternatives.\r\n\r\nConsider the case of `eq_join`. Though no longer implemented this way, it may be implemented in the Python DSL as follows:\r\n\r\n```python\r\ndef eq_join(table1, attr, table2):\r\n    table1.concatMap(\r\n        lambda row1: table2.get(x[attr]).do(\r\n            lambda row2: r.branch(row2 == None,\r\n                [],\r\n                [{'left':row1, 'right':row2}]\r\n        )\r\n    )\r\n\r\n# What this would look like with `get_set`, ignoring secondary indices\r\ndef eq_join(table1, attr, table2):\r\n    table1.concatMap(\r\n        lambda row1: table2.get_set(x[attr]).map(\r\n            lambda row2: {'left':row1, 'right':row2}\r\n        )\r\n    )\r\n```\r\n\r\nThe first thing you notice with this example is just how much cleaner it looks with `get_set` instead of `get`. There is no need for an ugly `branch` on NULL because that case is handled neatly by the empty stream.\r\n\r\nThe second remarkable thing about this function is that it is completely agnostic to whether `table1` and `table2` are primary or secondary indices since they both support `get_set` with roughly comparable performance characteristics. This advantage will become even more apparent when we eventually support libraries of helpful RQL functions that, like `eq_join`, take index arguments that may be primary or secondary indices.\r\n\r\nThis, I think, preserves what's actually good about the SQL API, that once you've created a secondary index it's trivial to begin using it to speed up your queries because there is no separate interface for interacting with secondary indices, it just works exactly like primary indices do."
  , issueState = "closed"
  , issueId = Id 12786022
  , issueComments = 57
  , issueMilestone =
      Just
        Milestone
          { milestoneCreator =
              SimpleUser
                { simpleUserId = Id 48436
                , simpleUserLogin = N "coffeemug"
                , simpleUserAvatarUrl =
                    "https://avatars.githubusercontent.com/u/48436?v=3"
                , simpleUserUrl = "https://api.github.com/users/coffeemug"
                , simpleUserType = OwnerUser
                }
          , milestoneDueOn = Just 2013 (-05) (-15) 07 : 00 : 00 UTC
          , milestoneOpenIssues = 0
          , milestoneNumber = 8
          , milestoneClosedIssues = 183
          , milestoneDescription =
              Just "Issues that are absolutely necessary for 1.5."
          , milestoneTitle = "1.5"
          , milestoneUrl =
              "https://api.github.com/repos/rethinkdb/rethinkdb/milestones/8"
          , milestoneCreatedAt = 2013 (-03) (-20) 02 : 06 : 44 UTC
          , milestoneState = "closed"
          }
  }