IssueComment
  { issueCommentUpdatedAt = 2016 (-06) (-14) 22 : 18 : 03 UTC
  , issueCommentUser =
      SimpleUser
        { simpleUserId = Id 505365
        , simpleUserLogin = N "danielmewes"
        , simpleUserAvatarUrl =
            "https://avatars.githubusercontent.com/u/505365?v=3"
        , simpleUserUrl = "https://api.github.com/users/danielmewes"
        , simpleUserType = OwnerUser
        }
  , issueCommentUrl =
      "https://api.github.com/repos/rethinkdb/rethinkdb/issues/comments/226033244"
  , issueCommentHtmlUrl =
      "https://github.com/rethinkdb/rethinkdb/issues/5856#issuecomment-226033244"
  , issueCommentCreatedAt = 2016 (-06) (-14) 22 : 18 : 03 UTC
  , issueCommentBody =
      "Hi @goors, is the server configured with swap? If it goes out of memory and then goes into swap, that could explain why the application can no longer access the DB, since it would become extremely slow.\r\n\r\nThe important question then of course still is why it's exhausting memory during the `rethinkdb dump`. Have you checked `htop` or a similar tool? Is the `rethinkdb` server itself using most of the 16 GB, or is it the `rethinkdb-dump` / `python` process of the dump utility (`rethinkdb dump` is implemented using Python underneath)?\r\n\r\nIt can sometimes help to run `rethinkdb dump` with the `--clients 1` option, which limits it to dumping one table at a time. By default, `rethinkdb dump` will backup up to three tables simultaneously to increase throughput."
  , issueCommentId = 226033244
  }