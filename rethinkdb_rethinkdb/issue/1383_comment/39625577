IssueComment
  { issueCommentUpdatedAt = 2014 (-04) (-05) 01 : 31 : 55 UTC
  , issueCommentUser =
      SimpleUser
        { simpleUserId = Id 48436
        , simpleUserLogin = N "coffeemug"
        , simpleUserAvatarUrl =
            "https://avatars.githubusercontent.com/u/48436?v=3"
        , simpleUserUrl = "https://api.github.com/users/coffeemug"
        , simpleUserType = OwnerUser
        }
  , issueCommentUrl =
      "https://api.github.com/repos/rethinkdb/rethinkdb/issues/comments/39625577"
  , issueCommentHtmlUrl =
      "https://github.com/rethinkdb/rethinkdb/issues/1383#issuecomment-39625577"
  , issueCommentCreatedAt = 2014 (-04) (-05) 01 : 31 : 55 UTC
  , issueCommentBody =
      "> As for when `depaginate=False`, we can still return a stream, as the data returned from the server may not happen all at once.  I believe we get callbacks from `libcurl` for each chunk of data, and we can parse json into objects to return in the stream.\r\n\r\nHmm, how would that work? Suppose you get the first chunk, and it's `[{'a': 1}, {'b`. We're not actually going to determine \"ah, it's an array and we only got one full object so far, let's dump it into a stream and get it to a user, and then wait for more\", are we? (I can think of a few reasons not to do that even if we can -- for example, what if we later discover that they don't have a closing bracket and the whole array is malformed?)"
  , issueCommentId = 39625577
  }