IssueComment
  { issueCommentUpdatedAt = 2014 (-10) (-23) 02 : 10 : 46 UTC
  , issueCommentUser =
      SimpleUser
        { simpleUserId = Id 505365
        , simpleUserLogin = N "danielmewes"
        , simpleUserAvatarUrl =
            "https://avatars.githubusercontent.com/u/505365?v=3"
        , simpleUserUrl = "https://api.github.com/users/danielmewes"
        , simpleUserType = OwnerUser
        }
  , issueCommentUrl =
      "https://api.github.com/repos/rethinkdb/rethinkdb/issues/comments/60183617"
  , issueCommentHtmlUrl =
      "https://github.com/rethinkdb/rethinkdb/issues/3232#issuecomment-60183617"
  , issueCommentCreatedAt = 2014 (-10) (-23) 02 : 10 : 46 UTC
  , issueCommentBody =
      "I'm not sure about orders of magnitude. But it would certainly reduce the network overhead by some factor in cases where the `between` and `filter` change streams are relatively selective like in the use case you mention. I guess this can be quite important for scalablity (the factor would be proportional to the number of nodes in the cluster through which change feed queries are being run I think).\r\n\r\nIf the current code for point change feeds can be easily extended to sending arbitrary filters to the primary, that sounds like it would be worth doing.\r\n\r\nGenerally as far as I can see `between().changes()` is just a special case of `filter().changes()`."
  , issueCommentId = 60183617
  }