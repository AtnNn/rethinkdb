IssueComment
  { issueCommentUpdatedAt = 2014 (-05) (-20) 00 : 54 : 05 UTC
  , issueCommentUser =
      SimpleUser
        { simpleUserId = Id 505365
        , simpleUserLogin = N "danielmewes"
        , simpleUserAvatarUrl =
            "https://avatars.githubusercontent.com/u/505365?v=3"
        , simpleUserUrl = "https://api.github.com/users/danielmewes"
        , simpleUserType = OwnerUser
        }
  , issueCommentUrl =
      "https://api.github.com/repos/rethinkdb/rethinkdb/issues/comments/43575793"
  , issueCommentHtmlUrl =
      "https://github.com/rethinkdb/rethinkdb/issues/2411#issuecomment-43575793"
  , issueCommentCreatedAt = 2014 (-05) (-20) 00 : 54 : 05 UTC
  , issueCommentBody =
      "Hi @PrakashThapa,\r\nI have two additional questions for better understanding the problem:\r\nHow large are the documents in the tables approximately? \r\nCan you check the RethinkDB log file for a line like\r\n```\r\nUsing cache size of 12529 MB\r\n```\r\nand tell me the value that is shown there as the cache size?\r\n\r\nI think what @Tryneus said is a plausible explanation of the effect. Especially if some of the data is out of memory (we don't know yet whether it might be or not, do we?)\r\n\r\n`count()` in RethinkDB is certainly not as optimized yet as in some other databases."
  , issueCommentId = 43575793
  }