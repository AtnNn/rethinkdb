IssueComment
  { issueCommentUpdatedAt = 2014 (-12) (-09) 14 : 38 : 58 UTC
  , issueCommentUser =
      SimpleUser
        { simpleUserId = Id 622337
        , simpleUserLogin = N "joaojeronimo"
        , simpleUserAvatarUrl =
            "https://avatars.githubusercontent.com/u/622337?v=3"
        , simpleUserUrl = "https://api.github.com/users/joaojeronimo"
        , simpleUserType = OwnerUser
        }
  , issueCommentUrl =
      "https://api.github.com/repos/rethinkdb/rethinkdb/issues/comments/66291570"
  , issueCommentHtmlUrl =
      "https://github.com/rethinkdb/rethinkdb/issues/3422#issuecomment-66291570"
  , issueCommentCreatedAt = 2014 (-12) (-09) 14 : 38 : 58 UTC
  , issueCommentBody =
      "Hi @danielmewes, perhaps you remember me from [this question on stackoverflow](http://stackoverflow.com/questions/27119268/how-to-exaust-a-machines-resources-with-rethinkdb/27135201#comment43121393_27135201).\r\n\r\nIt's still the same box from the question, a [Hetzner EX40-SSD](http://www.hetzner.de/en/hosting/produkte_rootserver/ex40ssd) so 32GB of RAM and 2x240GB SSDs that I have running with a RAID 0.\r\n\r\nI tried increasing the cache size to 20GB but it didn't increase in any way the insert throughput and because I was not doing so many \"select\" queries it didn't have any impact there too. So it means that for every write I have to read all the dataset, and if that fits in RAM it's fast but when it goes to disk is slower ? Great, didn't know that.\r\n\r\nGreat, I thought the database was giving me the timeouts :)\r\n\r\nWhere can I find this and more information like performance numbers ?"
  , issueCommentId = 66291570
  }