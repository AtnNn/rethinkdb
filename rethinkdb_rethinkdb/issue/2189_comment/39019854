IssueComment
  { issueCommentUpdatedAt = 2014 (-03) (-30) 07 : 45 : 55 UTC
  , issueCommentUser =
      SimpleUser
        { simpleUserId = Id 505365
        , simpleUserLogin = N "danielmewes"
        , simpleUserAvatarUrl =
            "https://avatars.githubusercontent.com/u/505365?v=3"
        , simpleUserUrl = "https://api.github.com/users/danielmewes"
        , simpleUserType = OwnerUser
        }
  , issueCommentUrl =
      "https://api.github.com/repos/rethinkdb/rethinkdb/issues/comments/39019854"
  , issueCommentHtmlUrl =
      "https://github.com/rethinkdb/rethinkdb/issues/2189#issuecomment-39019854"
  , issueCommentCreatedAt = 2014 (-03) (-30) 07 : 45 : 55 UTC
  , issueCommentBody =
      "Hmm, reconnecting sounds like a highly partial solution. It would have to completely restart at least the current table(s). And if they are sufficiently large, there's a chance that they would just timeout again after another 2 days.\r\nUnless we would make use of some implicit ordering guarantees and use a between to export only the remaining part after a reconnect?"
  , issueCommentId = 39019854
  }