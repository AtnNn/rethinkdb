Issue
  { issueClosedAt = Just 2015 (-08) (-27) 01 : 44 : 35 UTC
  , issueUpdatedAt = 2015 (-08) (-27) 01 : 44 : 38 UTC
  , issueEventsUrl =
      "https://api.github.com/repos/rethinkdb/rethinkdb/issues/2919/events"
  , issueHtmlUrl =
      Just "https://github.com/rethinkdb/rethinkdb/issues/2919"
  , issueClosedBy = Nothing
  , issueLabels =
      [ IssueLabel
          { labelColor = "e10c02"
          , labelUrl =
              "https://api.github.com/repos/rethinkdb/rethinkdb/labels/pr:high"
          , labelName = "pr:high"
          }
      , IssueLabel
          { labelColor = "444444"
          , labelUrl =
              "https://api.github.com/repos/rethinkdb/rethinkdb/labels/tp:performance"
          , labelName = "tp:performance"
          }
      ]
  , issueNumber = 2919
  , issueAssignee = Nothing
  , issueUser =
      SimpleUser
        { simpleUserId = Id 505365
        , simpleUserLogin = N "danielmewes"
        , simpleUserAvatarUrl =
            "https://avatars.githubusercontent.com/u/505365?v=3"
        , simpleUserUrl = "https://api.github.com/users/danielmewes"
        , simpleUserType = OwnerUser
        }
  , issueTitle = "Huge memory waste in Protobuf Terms"
  , issuePullRequest = Nothing
  , issueUrl =
      "https://api.github.com/repos/rethinkdb/rethinkdb/issues/2919"
  , issueCreatedAt = 2014 (-08) (-15) 03 : 58 : 05 UTC
  , issueBody =
      Just
        "Running a query like this\n\n```\nr.table('t').get('1234').update( {arr: r.row('arr').setUnion(largeArray) } )\n```\n\nwhere `largeArray` is a relatively large array (say 10000 entries) of small documents consumes ridiculous amounts of memory on the server (run ~150 of them at a time and you get into the tenths of GB).\n\nProfiling shows that this memory is used in Google Protocol buffer objects. It seems that we create a lot of copies of the query Term (some for backtraces, some for rewriting the update, possibly some for other reasons), and that furthermore the protocol buffer representation of arrays is extremely wasteful (_Update_: This might not be true to that extent, see the next comment regarding backtraces).\n\nThe problem can be worked around by writing\n\n```\nr.table('t').get('1234').update( {arr: r.row('arr').setUnion(r.json(JSON.stringify(largeArray))) } )\n```\n\nMy guess is that having a single string Term is a lot more memory efficient than having an array of nested Terms.\n\nMy impression is that the copying is also very slow (I got web UI timeouts).\n\nI'm not sure what the best way of fixing this is. Maybe we could get rid of protocol buffers inside the server and pass Terms and functions around in a different format that we have more control over.\n"
  , issueState = "closed"
  , issueId = Id 40321306
  , issueComments = 9
  , issueMilestone =
      Just
        Milestone
          { milestoneCreator =
              SimpleUser
                { simpleUserId = Id 706854
                , simpleUserLogin = N "AtnNn"
                , simpleUserAvatarUrl =
                    "https://avatars.githubusercontent.com/u/706854?v=3"
                , simpleUserUrl = "https://api.github.com/users/AtnNn"
                , simpleUserType = OwnerUser
                }
          , milestoneDueOn = Nothing
          , milestoneOpenIssues = 1
          , milestoneNumber = 17
          , milestoneClosedIssues = 595
          , milestoneDescription =
              Just
                "The scope of this issue is covered by another issue. The closing comment should link to the other issue."
          , milestoneTitle = "duplicate"
          , milestoneUrl =
              "https://api.github.com/repos/rethinkdb/rethinkdb/milestones/17"
          , milestoneCreatedAt = 2013 (-03) (-29) 20 : 23 : 12 UTC
          , milestoneState = "closed"
          }
  }