IssueComment
  { issueCommentUpdatedAt = 2014 (-04) (-09) 20 : 45 : 17 UTC
  , issueCommentUser =
      SimpleUser
        { simpleUserId = Id 258437
        , simpleUserLogin = N "srh"
        , simpleUserAvatarUrl =
            "https://avatars.githubusercontent.com/u/258437?v=3"
        , simpleUserUrl = "https://api.github.com/users/srh"
        , simpleUserType = OwnerUser
        }
  , issueCommentUrl =
      "https://api.github.com/repos/rethinkdb/rethinkdb/issues/comments/40014109"
  , issueCommentHtmlUrl =
      "https://github.com/rethinkdb/rethinkdb/issues/997#issuecomment-40014109"
  , issueCommentCreatedAt = 2014 (-04) (-09) 20 : 45 : 17 UTC
  , issueCommentBody =
      "> I'd have to think more about the specific implementation details. I think the buffering should be per-server-with-cursors so that when a changefeed requests more data there doesn't need to be intracluster traffic to fetch it.\r\n\r\n@mlucy: We still need information on who does what where for this first version, and we also need an end-game in mind to make sure that the first version makes actual progress toward the end version (and isn't merely and equal-effort alternative implementation).  Replicas going down is a side-show.  What we need to know is: will all change feeds go down when a single client does an insert workload?  Will all change feeds go down when two clients do an insert workload?  (Or if throttling happens, the questions transform: how badly will we throttle?) To answer this we need to know what messages are being sent across the cluster and to the client, and what responses are being sent, when, in both the first implementation and in terms of what the first implementation would have, the 1.13/1.14 goal, and the end goal."
  , issueCommentId = 40014109
  }