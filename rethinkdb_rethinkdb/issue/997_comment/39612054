IssueComment
  { issueCommentUpdatedAt = 2014 (-04) (-04) 21 : 13 : 28 UTC
  , issueCommentUser =
      SimpleUser
        { simpleUserId = Id 1777134
        , simpleUserLogin = N "mlucy"
        , simpleUserAvatarUrl =
            "https://avatars.githubusercontent.com/u/1777134?v=3"
        , simpleUserUrl = "https://api.github.com/users/mlucy"
        , simpleUserType = OwnerUser
        }
  , issueCommentUrl =
      "https://api.github.com/repos/rethinkdb/rethinkdb/issues/comments/39612054"
  , issueCommentHtmlUrl =
      "https://github.com/rethinkdb/rethinkdb/issues/997#issuecomment-39612054"
  , issueCommentCreatedAt = 2014 (-04) (-04) 21 : 12 : 45 UTC
  , issueCommentBody =
      "* I was thinking we would just send `{old_val: ..., new_val: ...}`.  `old_val` will be NULL for an insert, and `new_val` will be NULL for a delete.  This is easy to do, and gives people the same interface for `update` and `replace`, which is nice.  (The downside is that it's more network traffic.)  I'm not too attached to this if all the other changefeed interfaces do something different.\r\n* We'll never buffer a whole table; if we buffer too many changes in the server (say more than the array size limit) we'll discard them and any cursors which are too far behind will get an error.  (Alternatively, we could skip a few and give those cursors a warning.)\r\n* The reason buffering in the server is nice here is that if you have 1000 changefeeds open, and none of them have processed a row yet, that row will be stored once on the server, whereas if we buffered in the clients it would be stored 1000 times."
  , issueCommentId = 39612054
  }