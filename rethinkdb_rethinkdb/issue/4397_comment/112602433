IssueComment
  { issueCommentUpdatedAt = 2015 (-06) (-16) 23 : 32 : 58 UTC
  , issueCommentUser =
      SimpleUser
        { simpleUserId = Id 1777134
        , simpleUserLogin = N "mlucy"
        , simpleUserAvatarUrl =
            "https://avatars.githubusercontent.com/u/1777134?v=3"
        , simpleUserUrl = "https://api.github.com/users/mlucy"
        , simpleUserType = OwnerUser
        }
  , issueCommentUrl =
      "https://api.github.com/repos/rethinkdb/rethinkdb/issues/comments/112602433"
  , issueCommentHtmlUrl =
      "https://github.com/rethinkdb/rethinkdb/issues/4397#issuecomment-112602433"
  , issueCommentCreatedAt = 2015 (-06) (-16) 23 : 32 : 58 UTC
  , issueCommentBody =
      "> I'm not super fond of a solution where you have to recreate the whole table once you run out of key value space. That sounds like something that you can shoot yourself in the foot with quite easily.\r\n\r\nThe behavior when you run out of key space would be a moderate performance degradation (we'd just stop compressing new keys).  And if you're autogenerating millions of keys or whatever the compression performance probably won't be so amazing anyway.  So I don't think it would be all that bad.  (We could also have an advanced admin command to rebuild the key cache similar to rebuilding indexes.)\r\n\r\n> Actually I think having to specify the set of keys manually at table creation would be a better solution.\r\n\r\nThat would probably be reasonable for most use cases, although I would guess a lot of people don't know their schema when they first create the table."
  , issueCommentId = 112602433
  }