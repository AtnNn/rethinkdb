IssueComment
  { issueCommentUpdatedAt = 2016 (-07) (-11) 16 : 53 : 37 UTC
  , issueCommentUser =
      SimpleUser
        { simpleUserId = Id 7431361
        , simpleUserLogin = N "larkost"
        , simpleUserAvatarUrl =
            "https://avatars.githubusercontent.com/u/7431361?v=3"
        , simpleUserUrl = "https://api.github.com/users/larkost"
        , simpleUserType = OwnerUser
        }
  , issueCommentUrl =
      "https://api.github.com/repos/rethinkdb/rethinkdb/issues/comments/231794898"
  , issueCommentHtmlUrl =
      "https://github.com/rethinkdb/rethinkdb/issues/5934#issuecomment-231794898"
  , issueCommentCreatedAt = 2016 (-07) (-11) 16 : 53 : 37 UTC
  , issueCommentBody =
      "One of the ways this can happen is the out-of-memory-killer (OOM, an OS feature) decides that the system would be more stable if there was some free memory and kills the largest user (databases are large users for good reason). Unfortunately there is no catchable signal sent, so there is nothing we can put in our logs. But if this is the case, then there is probably an entry in the system log about the event. Usually they have the text `killed process` in the line, so should be easy to find.\r\n\r\n@bsharpe: can you check for that message? If it is there, then I would check your memory settings to make sure that RethinkDB's cache setting is not set to larger than, say 2/3rds the total memory size: `r.db('rethinkdb').table('server_config')` (looks for `cache_size_mb`). We default to half the available memory, but you can set that (usually in a config file) to anything you like (including nonsensical values)."
  , issueCommentId = 231794898
  }