IssueComment
  { issueCommentUpdatedAt = 2013 (-06) (-20) 00 : 55 : 22 UTC
  , issueCommentUser =
      SimpleUser
        { simpleUserId = Id 48436
        , simpleUserLogin = N "coffeemug"
        , simpleUserAvatarUrl =
            "https://avatars.githubusercontent.com/u/48436?v=3"
        , simpleUserUrl = "https://api.github.com/users/coffeemug"
        , simpleUserType = OwnerUser
        }
  , issueCommentUrl =
      "https://api.github.com/repos/rethinkdb/rethinkdb/issues/comments/19724975"
  , issueCommentHtmlUrl =
      "https://github.com/rethinkdb/rethinkdb/issues/1042#issuecomment-19724975"
  , issueCommentCreatedAt = 2013 (-06) (-20) 00 : 54 : 59 UTC
  , issueCommentBody =
      "I'm probably being completely uninformed since I don't know much about the code, but one high level option might be to load the binary data into a `datum_t` and only convert it to an `std::map` lazily when we actually need that (possibly even analyze the query and only convert the fields that we might need). Since a lot of times people don't actually need to do much evaluation on the data, even a naive solution would give a nice boost. A non-naive one would be even better.\r\n\r\n`std::map` is pretty fast, so I can't think of much else we can do to optimize that away."
  , issueCommentId = 19724975
  }