IssueComment
  { issueCommentUpdatedAt = 2015 (-06) (-17) 18 : 45 : 40 UTC
  , issueCommentUser =
      SimpleUser
        { simpleUserId = Id 505365
        , simpleUserLogin = N "danielmewes"
        , simpleUserAvatarUrl =
            "https://avatars.githubusercontent.com/u/505365?v=3"
        , simpleUserUrl = "https://api.github.com/users/danielmewes"
        , simpleUserType = OwnerUser
        }
  , issueCommentUrl =
      "https://api.github.com/repos/rethinkdb/rethinkdb/issues/comments/112911148"
  , issueCommentHtmlUrl =
      "https://github.com/rethinkdb/rethinkdb/issues/4379#issuecomment-112911148"
  , issueCommentCreatedAt = 2015 (-06) (-17) 18 : 45 : 40 UTC
  , issueCommentBody =
      "> And if I use the random generated IDs, apart from the performance impact during inserts (I doubt there will be updates, until and unless I go down the route of storing 10 min of data in one document which would help in improving reads), a read for the data for a particular sensor between a start and stop time, would go to all the shards.\r\n\r\nWith RethinkDB that's usually what you want actually. This is what allows queries to be parallelized over servers.\r\nInserts will also usually be faster if they cross multiple shards, because again that allows them to utilize more servers in parallel."
  , issueCommentId = 112911148
  }