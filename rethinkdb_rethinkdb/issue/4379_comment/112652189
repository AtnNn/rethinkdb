IssueComment
  { issueCommentUpdatedAt = 2015 (-06) (-17) 04 : 55 : 37 UTC
  , issueCommentUser =
      SimpleUser
        { simpleUserId = Id 985551
        , simpleUserLogin = N "neilunadkat"
        , simpleUserAvatarUrl =
            "https://avatars.githubusercontent.com/u/985551?v=3"
        , simpleUserUrl = "https://api.github.com/users/neilunadkat"
        , simpleUserType = OwnerUser
        }
  , issueCommentUrl =
      "https://api.github.com/repos/rethinkdb/rethinkdb/issues/comments/112652189"
  , issueCommentHtmlUrl =
      "https://github.com/rethinkdb/rethinkdb/issues/4379#issuecomment-112652189"
  , issueCommentCreatedAt = 2015 (-06) (-17) 04 : 55 : 37 UTC
  , issueCommentBody =
      "@deontologician @danielmewes sorry for a late reply.\r\nMy sensor id are also incremental (using a variation of the twitter snowflake algo). \r\nI just realised that with new devices being added, and the older ones still being out there sending the data, things might just become out of balance if I use the sensor id + timestamp.\r\n\r\nAnd if I use the random generated IDs, apart from the performance impact during inserts (I doubt there will be updates, until and unless I go down the route of storing 10 min of data in one document which would help in improving reads), a read for the data for a particular sensor between a start and stop time, would go to all the shards.  \r\nMy sharding philosophy should be dependant on the way I am going to consume the data right?\r\nWell, 90% of the time the data consumption will be a between certain time search, which will be on the latest data. This is going to be used by the algorithms, who will get certain information out of it and then store the results. And mostly, these results would be used for the algorithms ahead.\r\nAs of now I do not see this data to be consumed as is (because it would not necessarily make sense).\r\n\r\nSo based on this what route do you guys think I should follow?\r\n"
  , issueCommentId = 112652189
  }