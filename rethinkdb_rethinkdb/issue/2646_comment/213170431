IssueComment
  { issueCommentUpdatedAt = 2016 (-04) (-22) 00 : 23 : 32 UTC
  , issueCommentUser =
      SimpleUser
        { simpleUserId = Id 505365
        , simpleUserLogin = N "danielmewes"
        , simpleUserAvatarUrl =
            "https://avatars.githubusercontent.com/u/505365?v=3"
        , simpleUserUrl = "https://api.github.com/users/danielmewes"
        , simpleUserType = OwnerUser
        }
  , issueCommentUrl =
      "https://api.github.com/repos/rethinkdb/rethinkdb/issues/comments/213170431"
  , issueCommentHtmlUrl =
      "https://github.com/rethinkdb/rethinkdb/issues/2646#issuecomment-213170431"
  , issueCommentCreatedAt = 2016 (-04) (-22) 00 : 23 : 32 UTC
  , issueCommentBody =
      "@hungnt-me I'm not sure how useful that would be to be honest. LRU cache replacement should get fairly close to optimal cache allocation. A part of an index that's rarely used will be kicked out to free up space for more frequently required data, but frequently used indexes (or parts of indexes) will be kept in cache. That being said there might be optimizations to the pure LRU strategy that improve overall performance. It will likely depend on the type of workload which strategy works best. We could maybe allow some user-tuning of cache replacement strategies.\r\n\r\nWould you mind opening a new issue as a feature request for that?\r\n(Though I can't give a promise right now when we might get to this, since it's a very complex problem with uncertain pay-off in terms of performance.)"
  , issueCommentId = 213170431
  }