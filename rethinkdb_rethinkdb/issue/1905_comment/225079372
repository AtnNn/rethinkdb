IssueComment
  { issueCommentUpdatedAt = 2016 (-06) (-10) 02 : 29 : 44 UTC
  , issueCommentUser =
      SimpleUser
        { simpleUserId = Id 1430058
        , simpleUserLogin = N "ntquyen"
        , simpleUserAvatarUrl =
            "https://avatars.githubusercontent.com/u/1430058?v=3"
        , simpleUserUrl = "https://api.github.com/users/ntquyen"
        , simpleUserType = OwnerUser
        }
  , issueCommentUrl =
      "https://api.github.com/repos/rethinkdb/rethinkdb/issues/comments/225079372"
  , issueCommentHtmlUrl =
      "https://github.com/rethinkdb/rethinkdb/issues/1905#issuecomment-225079372"
  , issueCommentCreatedAt = 2016 (-06) (-10) 02 : 29 : 00 UTC
  , issueCommentBody =
      "Actually we had experienced this back in March, and then another one few days ago. The first time had happened after a few days deploying a bunch of rethinkdb proxies, each attached to one microservice in a kubernetes pod (that produced around 80 proxies), 5 clusters joined together, conflict database names... That's was like a disaster because it's on production... I didn't open issue because I thought that there was something wrong in our CI configuration that could made the rethinkdb proxies join different clusters and that was normal. But after the second time, I think this incident should be prevented as we never want one cluster join to another, because that's why we separate them.\r\n\r\nI don't know if the rethinkdb proxies caused this, just have a feeling that the using proxies is dangerous in this case."
  , issueCommentId = 225079372
  }