IssueComment
  { issueCommentUpdatedAt = 2012 (-11) (-20) 17 : 51 : 04 UTC
  , issueCommentUser =
      SimpleUser
        { simpleUserId = Id 43867
        , simpleUserLogin = N "jdoliner"
        , simpleUserAvatarUrl =
            "https://avatars.githubusercontent.com/u/43867?v=3"
        , simpleUserUrl = "https://api.github.com/users/jdoliner"
        , simpleUserType = OwnerUser
        }
  , issueCommentUrl =
      "https://api.github.com/repos/rethinkdb/rethinkdb/issues/comments/10565096"
  , issueCommentHtmlUrl =
      "https://github.com/rethinkdb/rethinkdb/issues/89#issuecomment-10565096"
  , issueCommentCreatedAt = 2012 (-11) (-20) 17 : 51 : 04 UTC
  , issueCommentBody =
      "I think this is fairly straightforward to do with the architecture we already have. Basically when a user wants to backup they run a command:\r\nrethinkdb backup -join ... -tables foo,bar...\r\nThis command then takes each table and calls backfillee to backfill the data in to the file. The logic for this fairly closes resembles that in reactor_be_secondary (with a lot of it removed of course).\r\n\r\nAlso if we find files from a previous invocation the logic already supports using the data that's in there. Incremental backup could be accomplished by just making a copy of the file in between runs of this. We could potentially make that a little bit more hand holdy."
  , issueCommentId = 10565096
  }