IssueComment
  { issueCommentUpdatedAt = 2014 (-07) (-29) 18 : 34 : 18 UTC
  , issueCommentUser =
      SimpleUser
        { simpleUserId = Id 505365
        , simpleUserLogin = N "danielmewes"
        , simpleUserAvatarUrl =
            "https://avatars.githubusercontent.com/u/505365?v=3"
        , simpleUserUrl = "https://api.github.com/users/danielmewes"
        , simpleUserType = OwnerUser
        }
  , issueCommentUrl =
      "https://api.github.com/repos/rethinkdb/rethinkdb/issues/comments/50518685"
  , issueCommentHtmlUrl =
      "https://github.com/rethinkdb/rethinkdb/issues/2750#issuecomment-50518685"
  , issueCommentCreatedAt = 2014 (-07) (-29) 18 : 34 : 18 UTC
  , issueCommentBody =
      "Thank you for setting everything up again @mping.\r\n\r\nA quick test shows that a query like `table.group({index: ...}).count()` loads and parses all documents in the table. You say you have about 3.8 million, so that probably explains why the query is so slow. Even if everything is in the cache, the parsing can take some time.\r\n\r\nWe have an optimization for `table.count()` which avoids loading and parsing the values, but it currently doesn't apply in case there's a `group` before the count.\r\n\r\n@mlucy Do you think we could enable that optimization for grouped queries too?"
  , issueCommentId = 50518685
  }