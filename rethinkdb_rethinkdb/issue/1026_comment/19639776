IssueComment
  { issueCommentUpdatedAt = 2013 (-06) (-18) 20 : 29 : 24 UTC
  , issueCommentUser =
      SimpleUser
        { simpleUserId = Id 646357
        , simpleUserLogin = N "wmrowan"
        , simpleUserAvatarUrl =
            "https://avatars.githubusercontent.com/u/646357?v=3"
        , simpleUserUrl = "https://api.github.com/users/wmrowan"
        , simpleUserType = OwnerUser
        }
  , issueCommentUrl =
      "https://api.github.com/repos/rethinkdb/rethinkdb/issues/comments/19639776"
  , issueCommentHtmlUrl =
      "https://github.com/rethinkdb/rethinkdb/issues/1026#issuecomment-19639776"
  , issueCommentCreatedAt = 2013 (-06) (-18) 20 : 29 : 24 UTC
  , issueCommentBody =
      "When I test just the C extension based serializer on a large deeply nested object I get much faster speedups (~130x for a ~1.8MB message with a nesting depth of 60). This is probably because the naive serializer is quadratic in nesting depth. In testing this though I found a problem with the C++ based deserializer. With the message format I tested, message depths greater than about 60 resulted in an error on deserialization. This could be the problem that bump referred to when @coffeemug talked to them about using the google protobuf library.\r\n\r\nI'm going to get the same test running with bump's library to see if it's any faster / can handle greater nesting depths."
  , issueCommentId = 19639776
  }