IssueComment
  { issueCommentUpdatedAt = 2014 (-04) (-14) 20 : 25 : 09 UTC
  , issueCommentUser =
      SimpleUser
        { simpleUserId = Id 48436
        , simpleUserLogin = N "coffeemug"
        , simpleUserAvatarUrl =
            "https://avatars.githubusercontent.com/u/48436?v=3"
        , simpleUserUrl = "https://api.github.com/users/coffeemug"
        , simpleUserType = OwnerUser
        }
  , issueCommentUrl =
      "https://api.github.com/repos/rethinkdb/rethinkdb/issues/comments/40413510"
  , issueCommentHtmlUrl =
      "https://github.com/rethinkdb/rethinkdb/issues/2119#issuecomment-40413510"
  , issueCommentCreatedAt = 2014 (-04) (-14) 20 : 24 : 34 UTC
  , issueCommentBody =
      "> If we are just routing everything to the master, the only way to increase throughput is to shard the table. \r\n\r\nYes, but that's not necessarily a bad architecture.\r\n\r\n> And every master of a shard becomes a point of failure too.\r\n\r\nSuppose you have a shard with N replicas. Under the current architecture, if a machine fails or slows down, the odds are 1/N that it's master (in which case the user has to fail over). If they set up acks/replicas correctly, a non-master failure will not affect writes, and will only effect 1/N reads.\r\n\r\nUnder the new proposal, if a copy machine fails or slows down, the probability that writes will be affected is 1. That's a significant problem."
  , issueCommentId = 40413510
  }