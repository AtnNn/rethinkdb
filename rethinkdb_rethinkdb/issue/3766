Issue
  { issueClosedAt = Just 2015 (-02) (-14) 02 : 05 : 33 UTC
  , issueUpdatedAt = 2015 (-02) (-14) 02 : 05 : 33 UTC
  , issueEventsUrl =
      "https://api.github.com/repos/rethinkdb/rethinkdb/issues/3766/events"
  , issueHtmlUrl =
      Just "https://github.com/rethinkdb/rethinkdb/issues/3766"
  , issueClosedBy = Nothing
  , issueLabels =
      [ IssueLabel
          { labelColor = "e10c02"
          , labelUrl =
              "https://api.github.com/repos/rethinkdb/rethinkdb/labels/pr:high"
          , labelName = "pr:high"
          }
      , IssueLabel
          { labelColor = "e102d8"
          , labelUrl =
              "https://api.github.com/repos/rethinkdb/rethinkdb/labels/tp:bug"
          , labelName = "tp:bug"
          }
      ]
  , issueNumber = 3766
  , issueAssignee =
      Just
        SimpleUser
          { simpleUserId = Id 552910
          , simpleUserLogin = N "Tryneus"
          , simpleUserAvatarUrl =
              "https://avatars.githubusercontent.com/u/552910?v=3"
          , simpleUserUrl = "https://api.github.com/users/Tryneus"
          , simpleUserType = OwnerUser
          }
  , issueUser =
      SimpleUser
        { simpleUserId = Id 552910
        , simpleUserLogin = N "Tryneus"
        , simpleUserAvatarUrl =
            "https://avatars.githubusercontent.com/u/552910?v=3"
        , simpleUserUrl = "https://api.github.com/users/Tryneus"
        , simpleUserType = OwnerUser
        }
  , issueTitle =
      "`limited_fifo_queue_t` uses a `adjustable_semaphore_t`, violating a NO_CORO_WAITING"
  , issuePullRequest = Nothing
  , issueUrl =
      "https://api.github.com/repos/rethinkdb/rethinkdb/issues/3766"
  , issueCreatedAt = 2015 (-02) (-12) 00 : 07 : 33 UTC
  , issueBody =
      Just
        "On `next`, ran a JS test using:\r\n\r\n```\r\nr.expr(1).run(conn, callback);\r\nr.expr(1).run(conn, callback);\r\nr.expr(1).run(conn, callback);\r\nr.expr(1).run(conn, callback);\r\nr.expr(1).run(conn, callback);\r\n...\r\n```\r\nThe idea being to cause a lot of concurrent queries and weed out any race conditions.\r\n\r\nGot the following crash:\r\n```\r\nVersion: rethinkdb 1.16.0-1-95-g6f9f6d (debug) (GCC 4.6.3)\r\nerror: Error in ../src/arch/runtime/coroutines.cc at line 289:\r\nerror: Assertion failed: [TLS_get_cglobals()->assert_no_coro_waiting_counter == 0] This code path is not supposed to use notify_now_deprecated() or spawn_now_dangerously().\r\nerror: Backtrace:\r\nerror: Wed Feb 11 15:35:21 2015\r\n\r\n       1: rethinkdb_backtrace(void**, int) at rethinkdb_backtrace.cc:101\r\n       2: backtrace_t::backtrace_t() at backtrace.cc:203\r\n       3: lazy_backtrace_formatter_t::lazy_backtrace_formatter_t() at backtrace.cc:283\r\n       4: format_backtrace(bool) at backtrace.cc:198\r\n       5: report_fatal_error(char const*, int, char const*, ...) at errors.cc:83\r\n       6: coro_t::notify_now_deprecated() at coroutines.cc:288\r\n       7: one_waiter_cond_t::pulse() at cond_var.cc:26\r\n       8: ../build/debug/rethinkdb() [0x167cd6e] at 0x167cd6e ()\r\n       9: adjustable_semaphore_t::lock_request_t::on_available() at semaphore.hpp:92\r\n       10: adjustable_semaphore_t::pump() at semaphore.cc:185\r\n       11: adjustable_semaphore_t::unlock(long) at semaphore.cc:145\r\n       12: limited_fifo_queue_t<ql::protob_t<Query>, std::list<ql::protob_t<Query>, std::allocator<ql::protob_t<Query> > > >::produce_next_value() at limited_fifo.hpp:53\r\n       13: passive_producer_t<ql::protob_t<Query> >::pop() at passive_producer.hpp:83\r\n       14: coro_pool_t<ql::protob_t<Query> >::worker_run(ql::protob_t<Query>, auto_drainer_t::lock_t) at coro_pool.hpp:70\r\n       15: std::_Mem_fn<void (coro_pool_t<ql::protob_t<Query> >::*)(ql::protob_t<Query>, auto_drainer_t::lock_t)>::operator()(coro_pool_t<ql::protob_t<Query> >*, ql::protob_t<Query>, auto_drainer_t::lock_t) const at functional:551\r\n       16: void std::_Bind<std::_Mem_fn<void (coro_pool_t<ql::protob_t<Query> >::*)(ql::protob_t<Query>, auto_drainer_t::lock_t)> (coro_pool_t<ql::protob_t<Query> >*, ql::protob_t<Query>, auto_drainer_t::lock_t)>::__call<void, , 0, 1, 2>(std::tuple<>&&, std::_Index_tuple<0, 1, 2>) at functional:1146\r\n       17: void std::_Bind<std::_Mem_fn<void (coro_pool_t<ql::protob_t<Query> >::*)(ql::protob_t<Query>, auto_drainer_t::lock_t)> (coro_pool_t<ql::protob_t<Query> >*, ql::protob_t<Query>, auto_drainer_t::lock_t)>::operator()<, void>() at functional:1206\r\n       18: callable_action_instance_t<std::_Bind<std::_Mem_fn<void (coro_pool_t<ql::protob_t<Query> >::*)(ql::protob_t<Query>, auto_drainer_t::lock_t)> (coro_pool_t<ql::protob_t<Query> >*, ql::protob_t<Query>, auto_drainer_t::lock_t)> >::run_action() at callable_action.hpp:31\r\n       19: callable_action_wrapper_t::run() at runtime_utils.cc:43\r\n       20: coro_t::run() at coroutines.cc:207\r\n       21: coro_t* coro_t::spawn_sometime<std::_Bind<std::_Mem_fn<void (coro_pool_t<ql::protob_t<Query> >::*)(ql::protob_t<Query>, auto_drainer_t::lock_t)> (coro_pool_t<ql::protob_t<Query> >*, ql::protob_t<Query>, auto_drainer_t::lock_t)> >(std::_Bind<std::_Mem_fn<void (coro_pool_t<ql::protob_t<Query> >::*)(ql::protob_t<Query>, auto_drainer_t::lock_t)> (coro_pool_t<ql::protob_t<Query> >*, ql::protob_t<Query>, auto_drainer_t::lock_t)>&&) at coroutines.hpp:58\r\n       22: coro_pool_t<ql::protob_t<Query> >::on_source_availability_changed() at coro_pool.hpp:86\r\n       23: availability_control_t::set_available(bool) at passive_producer.hpp:66\r\n       24: limited_fifo_queue_t<ql::protob_t<Query>, std::list<ql::protob_t<Query>, std::allocator<ql::protob_t<Query> > > >::push(ql::protob_t<Query> const&) at limited_fifo.hpp:35\r\n       25: void query_server_t::connection_loop<json_protocol_t>(linux_tcp_conn_t*, unsigned long, signal_t*, client_context_t*) at protob.cc:390\r\n       26: query_server_t::handle_conn(scoped_ptr_t<linux_tcp_conn_descriptor_t> const&, auto_drainer_t::lock_t) at protob.cc:311\r\n```\r\n\r\nIt appears that `limited_fifo_queue_t` inherits from `passive_producer_t`.  `passive_producer_t::pop()` has an `ASSERT_NO_CORO_WAITING`.  This is a problem, because `limited_fifo_queue_t` uses `adjustable_semaphore_t`, which uses a `one_waiter_cond_t`, which uses `coro_t::notify_now_deprecated()`.\r\n\r\nIt seems it would be easy to change `one_waiter_cond_t` to use `notify_sometime`.  However, I'm hesitant to change any of the underlying synchronization primitives because they're used in so many places, some of which may depend on the current behavior.  `limited_fifo_queue_t` is only used in the `connection_loop` function for ReQL TCP connections, and maybe can be fixed without disrupting anything else.  Ideally, `limited_fifo_queue_t` would use `new_semaphore_t` instead of `adjustable_semaphore_t`, although that raises some RAII problems."
  , issueState = "closed"
  , issueId = Id 57397949
  , issueComments = 2
  , issueMilestone =
      Just
        Milestone
          { milestoneCreator =
              SimpleUser
                { simpleUserId = Id 505365
                , simpleUserLogin = N "danielmewes"
                , simpleUserAvatarUrl =
                    "https://avatars.githubusercontent.com/u/505365?v=3"
                , simpleUserUrl = "https://api.github.com/users/danielmewes"
                , simpleUserType = OwnerUser
                }
          , milestoneDueOn = Nothing
          , milestoneOpenIssues = 0
          , milestoneNumber = 89
          , milestoneClosedIssues = 117
          , milestoneDescription = Just ""
          , milestoneTitle = "2.0"
          , milestoneUrl =
              "https://api.github.com/repos/rethinkdb/rethinkdb/milestones/89"
          , milestoneCreatedAt = 2015 (-01) (-26) 07 : 45 : 17 UTC
          , milestoneState = "closed"
          }
  }