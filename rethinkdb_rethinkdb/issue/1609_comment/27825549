IssueComment
  { issueCommentUpdatedAt = 2013 (-11) (-05) 23 : 48 : 16 UTC
  , issueCommentUser =
      SimpleUser
        { simpleUserId = Id 505365
        , simpleUserLogin = N "danielmewes"
        , simpleUserAvatarUrl =
            "https://avatars.githubusercontent.com/u/505365?v=3"
        , simpleUserUrl = "https://api.github.com/users/danielmewes"
        , simpleUserType = OwnerUser
        }
  , issueCommentUrl =
      "https://api.github.com/repos/rethinkdb/rethinkdb/issues/comments/27825549"
  , issueCommentHtmlUrl =
      "https://github.com/rethinkdb/rethinkdb/issues/1609#issuecomment-27825549"
  , issueCommentCreatedAt = 2013 (-11) (-05) 23 : 48 : 16 UTC
  , issueCommentBody =
      "@wojons: As a work-around, would it be an option to divide the delete into smaller batches from the application side? For example you could run something like `r.table(...).between(...).limit(50).delete()` repeatedly until the `deleted` field of the result is 0. We will hopefully find a proper solution to the problem eventually, but my impression right now is that it could take a little while for us to completely fix this."
  , issueCommentId = 27825549
  }