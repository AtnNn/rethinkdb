IssueComment
  { issueCommentUpdatedAt = 2014 (-09) (-04) 23 : 42 : 04 UTC
  , issueCommentUser =
      SimpleUser
        { simpleUserId = Id 17789
        , simpleUserLogin = N "gchpaco"
        , simpleUserAvatarUrl =
            "https://avatars.githubusercontent.com/u/17789?v=3"
        , simpleUserUrl = "https://api.github.com/users/gchpaco"
        , simpleUserType = OwnerUser
        }
  , issueCommentUrl =
      "https://api.github.com/repos/rethinkdb/rethinkdb/issues/comments/54560852"
  , issueCommentHtmlUrl =
      "https://github.com/rethinkdb/rethinkdb/issues/3009#issuecomment-54560852"
  , issueCommentCreatedAt = 2014 (-09) (-04) 23 : 42 : 04 UTC
  , issueCommentBody =
      "As far as larger divergence, IEEE 754 mandates a number of highly precise operations, but generally the least significant digit is considered \"junk\" and the 2nd least significant digit highly suspect.  It also mandates a lot of really weird things like NaN, infinities and signed zeroes that have, in the past, been inconsistently implemented (although I believe things have been generally good for the last ten years or so).  As @mlucy says we aren't really a scientific data processing product, so I'm not overly concerned about exposing all of these headaches, but they *do* create divergence.  William Kahn is the go-to source for this if you're curious but it's not a casual read.\r\n\r\nTypical sources of divergence come from transcendental functions like `sin` and `cos`, which are usually implemented as linear interpolation in a lookup table and obviously the size and precision of the lookup table causes strong variation in the result.\r\n\r\nAs far as chip vendors, Intel is generally pretty anal about this, and good on them.  `icc` has flags to accommodate various weirdness across generations of Intel CPUs."
  , issueCommentId = 54560852
  }