IssueComment
  { issueCommentUpdatedAt = 2016 (-06) (-14) 23 : 01 : 52 UTC
  , issueCommentUser =
      SimpleUser
        { simpleUserId = Id 7431361
        , simpleUserLogin = N "larkost"
        , simpleUserAvatarUrl =
            "https://avatars.githubusercontent.com/u/7431361?v=3"
        , simpleUserUrl = "https://api.github.com/users/larkost"
        , simpleUserType = OwnerUser
        }
  , issueCommentUrl =
      "https://api.github.com/repos/rethinkdb/rethinkdb/issues/comments/226041896"
  , issueCommentHtmlUrl =
      "https://github.com/rethinkdb/rethinkdb/issues/5147#issuecomment-226041896"
  , issueCommentCreatedAt = 2016 (-06) (-14) 23 : 01 : 52 UTC
  , issueCommentBody =
      "The experiment for 1 has run its course. The idea was to combine the reader and writer into a single process, and then run multiple of them against a file simultaneously. While only one of them could read the file at a single time, hopefully the time spent processing and uploading the information could overlap with others. Sadly it looks like the reading of the file takes too much time at the moment (we have to process JSON in doing it), so we don't wind up with enough overlap to make this approach worth it.\r\n\r\nOn my (very simple) test set this approach only wound up with near-parity (a couple of percent slower) after a bit of tuning for the machines I was running on. Since this does not get near the bar of performing significantly faster I am pulling the plug on the experiment.\r\n\r\nSince it is possible that I have messed up something killing my performance, or that something could change in this calculus in the future, I am saving the branch as `larkost/5147-worker-test`."
  , issueCommentId = 226041896
  }