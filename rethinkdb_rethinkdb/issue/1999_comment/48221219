IssueComment
  { issueCommentUpdatedAt = 2014 (-07) (-07) 18 : 36 : 07 UTC
  , issueCommentUser =
      SimpleUser
        { simpleUserId = Id 505365
        , simpleUserLogin = N "danielmewes"
        , simpleUserAvatarUrl =
            "https://avatars.githubusercontent.com/u/505365?v=3"
        , simpleUserUrl = "https://api.github.com/users/danielmewes"
        , simpleUserType = OwnerUser
        }
  , issueCommentUrl =
      "https://api.github.com/repos/rethinkdb/rethinkdb/issues/comments/48221219"
  , issueCommentHtmlUrl =
      "https://github.com/rethinkdb/rethinkdb/issues/1999#issuecomment-48221219"
  , issueCommentCreatedAt = 2014 (-07) (-07) 18 : 36 : 07 UTC
  , issueCommentBody =
      "> From what I've heard (I never read the code), we somehow recurse in the Btree, and give an estimate of the number of blocks left to copy by keeping an avarage branching factor.\r\n\r\nYes. We don't always increase the denominator though, but start with an estimate for the total number of blocks that gets refined during backfilling.\r\n\r\nI just wonder which part of this is the actual problem.\r\n\r\nMaking the block count precise isn't that easy (in the presence of resharding). It is essentially the same problem as keeping track of the number of documents in a certain range of the tree https://github.com/rethinkdb/rethinkdb/issues/152 ."
  , issueCommentId = 48221219
  }