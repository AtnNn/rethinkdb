Issue
  { issueClosedAt = Just 2015 (-07) (-28) 00 : 57 : 35 UTC
  , issueUpdatedAt = 2015 (-07) (-28) 00 : 57 : 35 UTC
  , issueEventsUrl =
      "https://api.github.com/repos/rethinkdb/rethinkdb/issues/4279/events"
  , issueHtmlUrl =
      Just "https://github.com/rethinkdb/rethinkdb/issues/4279"
  , issueClosedBy = Nothing
  , issueLabels =
      [ IssueLabel
          { labelColor = "e102d8"
          , labelUrl =
              "https://api.github.com/repos/rethinkdb/rethinkdb/labels/tp:bug"
          , labelName = "tp:bug"
          }
      ]
  , issueNumber = 4279
  , issueAssignee =
      Just
        SimpleUser
          { simpleUserId = Id 505365
          , simpleUserLogin = N "danielmewes"
          , simpleUserAvatarUrl =
              "https://avatars.githubusercontent.com/u/505365?v=3"
          , simpleUserUrl = "https://api.github.com/users/danielmewes"
          , simpleUserType = OwnerUser
          }
  , issueUser =
      SimpleUser
        { simpleUserId = Id 316661
        , simpleUserLogin = N "timmaxw"
        , simpleUserAvatarUrl =
            "https://avatars.githubusercontent.com/u/316661?v=3"
        , simpleUserUrl = "https://api.github.com/users/timmaxw"
        , simpleUserType = OwnerUser
        }
  , issueTitle = "Metadata writes are very slow on rotational drives"
  , issuePullRequest = Nothing
  , issueUrl =
      "https://api.github.com/repos/rethinkdb/rethinkdb/issues/4279"
  , issueCreatedAt = 2015 (-05) (-25) 20 : 47 : 21 UTC
  , issueBody =
      Just
        "The `metadata_file_t` often writes in the following pattern: Start a `txn_t` in hard durability mode and do some writes. Call `~txn_t`, but before it finishes, start another `txn_t` in hard durability mode and do some writes. Repeat.\n\nWhen this happens, the storage engine is apparently doing all of the writes serially; it waits for each write to completely commit before starting the next one. I've observed `~txn_t` taking more than five seconds to return on rotational drives.\n\n@danielmewes, I think you mentioned that this is a known flaw in the buffer cache. Is it practical to fix? If not, we could work around it by running the transactions themselves in soft durability mode and then using a `pump_coro_t` to flush them.\n"
  , issueState = "closed"
  , issueId = Id 80663089
  , issueComments = 9
  , issueMilestone =
      Just
        Milestone
          { milestoneCreator =
              SimpleUser
                { simpleUserId = Id 316661
                , simpleUserLogin = N "timmaxw"
                , simpleUserAvatarUrl =
                    "https://avatars.githubusercontent.com/u/316661?v=3"
                , simpleUserUrl = "https://api.github.com/users/timmaxw"
                , simpleUserType = OwnerUser
                }
          , milestoneDueOn = Nothing
          , milestoneOpenIssues = 0
          , milestoneNumber = 95
          , milestoneClosedIssues = 217
          , milestoneDescription =
              Just "To-do list before shipping auto-failover"
          , milestoneTitle = "2.1"
          , milestoneUrl =
              "https://api.github.com/repos/rethinkdb/rethinkdb/milestones/95"
          , milestoneCreatedAt = 2015 (-03) (-04) 21 : 09 : 42 UTC
          , milestoneState = "closed"
          }
  }