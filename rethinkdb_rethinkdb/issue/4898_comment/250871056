IssueComment
  { issueCommentUpdatedAt = 2016 (-09) (-30) 22 : 57 : 56 UTC
  , issueCommentUser =
      SimpleUser
        { simpleUserId = Id 1441929
        , simpleUserLogin = N "jlhawn"
        , simpleUserAvatarUrl =
            "https://avatars.githubusercontent.com/u/1441929?v=3"
        , simpleUserUrl = "https://api.github.com/users/jlhawn"
        , simpleUserType = OwnerUser
        }
  , issueCommentUrl =
      "https://api.github.com/repos/rethinkdb/rethinkdb/issues/comments/250871056"
  , issueCommentHtmlUrl =
      "https://github.com/rethinkdb/rethinkdb/issues/4898#issuecomment-250871056"
  , issueCommentCreatedAt = 2016 (-09) (-30) 22 : 57 : 56 UTC
  , issueCommentBody =
      "@danielmewes Is there a doc/article anywhere which goes into detail on how the data in some systems tables is replicated to all of the nodes in the cluster? This article on [Systems Tables](https://www.rethinkdb.com/docs/system-tables/) also mentions that writes to systems tables are non-atomic and that I should avoid writing from multiple clients concurrently.\r\n\r\nMore specifically, my question is how do I know when it is safe to create a database/table. I have a script which I had hoped would be idempotent:\r\n\r\n- Attempt to create a database. Ignore \"already exists\" error.\r\n- Attempt to create some tables. Ignore any \"already exists\" errors.\r\n- Reconfigure the table to have 1 shard with N replicas (where N is equal to some given value equal to the number of servers for which you want replicas).\r\n- Wait for the tables to be ready.\r\n- Attempt to create some secondary indexes. Ignore any \"already exists\" errors.\r\n- Wait for all indexes to be ready.\r\n\r\nIt's nice to be able to run this at any time to get to the desired configuration of the database, and I have been able to use this do do a number of different things:\r\n\r\n- Initialize the database, tables, and indexes.\r\n- Scale the number of replicas up or down.\r\n- Add any new tables or indexes introduced with new application versions.\r\n\r\n\r\nThe script connects to a server which had been just added to the cluster. I have noticed that sometimes (though very rarely) this will result in a duplicate database name or a duplicate table name which causes the rest of the script to crash with ambiguous db/table name errors. This script only runs on one client.\r\n\r\nIs there any kind of `Wait()` action I can do to ensure that the server I'm connected to has all of the `db_config` and `table_config` entries replicated to it? I'm guessing that this is the reason why it ends up creating duplicate databases and tables.\r\n\r\nI have read your suggestion:\r\n\r\n> Route every eventually consistent meta operation to the currently connected server with the lowest UUID, and have that server perform the operation.\r\n\r\nI think the problem with this is that a new server could come along at any moment with a lower ID and not yet have a consistent view of `db_config` and `table_config` if you try to immediately do these kinds operations against it. In this hypothetical protocol, would this new node block until it has told the 2nd-lowest UUID server that it's taking over?\r\n\r\nI've been thinking about how I could do this from a client's perspective and have considered using the `server_status` table to determine the server which has been connected for the longest period of time (by inspecting `network. time_connected`) and then connect to *that* server for the `dbCreate()` and `tableCreate()` operations. The idea is that the \"oldest\" server in the cluster acts as a de facto \"leader\" for these things and should have the most consistent view.  However the problem with this is that I'm unsure that there is any guarantee that the server I connect to for reading `server_status` actually has that data. And in a network partition there could be separate ideas for which server is the oldest.\r\n\r\nThis leads to another question: I have noticed that when I provide `--join` arguments to the server it appears to not begin listening for client connections until it has made peer connections. Is this the case? If so, does it only need to connect to a single peer if I provide more than one `--join` arg? Does it attempt to get up-to-date system table data from the peers before accepting client queries?\r\n\r\nIf I can guarantee that the `server_status` table will have all of the servers in it when connected to a server which has just joined the cluster then I can change the logic in my script to reconnect to the \"oldest\" node it the cluster before running any other operations."
  , issueCommentId = 250871056
  }