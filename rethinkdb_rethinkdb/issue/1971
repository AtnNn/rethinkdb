Issue
  { issueClosedAt = Just 2014 (-02) (-21) 21 : 21 : 40 UTC
  , issueUpdatedAt = 2014 (-02) (-27) 22 : 26 : 54 UTC
  , issueEventsUrl =
      "https://api.github.com/repos/rethinkdb/rethinkdb/issues/1971/events"
  , issueHtmlUrl =
      Just "https://github.com/rethinkdb/rethinkdb/issues/1971"
  , issueClosedBy = Nothing
  , issueLabels =
      [ IssueLabel
          { labelColor = "444444"
          , labelUrl =
              "https://api.github.com/repos/rethinkdb/rethinkdb/labels/tp:performance"
          , labelName = "tp:performance"
          }
      ]
  , issueNumber = 1971
  , issueAssignee =
      Just
        SimpleUser
          { simpleUserId = Id 505365
          , simpleUserLogin = N "danielmewes"
          , simpleUserAvatarUrl =
              "https://avatars.githubusercontent.com/u/505365?v=3"
          , simpleUserUrl = "https://api.github.com/users/danielmewes"
          , simpleUserType = OwnerUser
          }
  , issueUser =
      SimpleUser
        { simpleUserId = Id 505365
        , simpleUserLogin = N "danielmewes"
        , simpleUserAvatarUrl =
            "https://avatars.githubusercontent.com/u/505365?v=3"
        , simpleUserUrl = "https://api.github.com/users/danielmewes"
        , simpleUserType = OwnerUser
        }
  , issueTitle =
      "Backfill performance: Use batches for sending/inserting data"
  , issuePullRequest = Nothing
  , issueUrl =
      "https://api.github.com/repos/rethinkdb/rethinkdb/issues/1971"
  , issueCreatedAt = 2014 (-02) (-20) 03 : 02 : 58 UTC
  , issueBody =
      Just
        "Backfilling works by sending `backfill_chunk_t`s over the network. Despite the name, those currently contain only a single key/value pair each. Delivering all these small messages is inefficient.\n\nOn the receiving node, each key/value pair is then inserted in a transaction of its own. That's even more inefficient.\n\nI've started working on code that sends all key/values of a given Btree leaf node at once (branch daniel_backfilling_chunks). When backfilling 400 byte documents from one machine with rotational drives to a second one with rotational drives, this improved the backfilling throughput from ~80 documents/s to 300-400 documents per second.\n\nI would hope that we can still ship this as part of 1.12, because users are actually running into problems with slow backfills (#1885). If not, we could ship it in a point release soon after.\n"
  , issueState = "closed"
  , issueId = Id 27932768
  , issueComments = 5
  , issueMilestone =
      Just
        Milestone
          { milestoneCreator =
              SimpleUser
                { simpleUserId = Id 48436
                , simpleUserLogin = N "coffeemug"
                , simpleUserAvatarUrl =
                    "https://avatars.githubusercontent.com/u/48436?v=3"
                , simpleUserUrl = "https://api.github.com/users/coffeemug"
                , simpleUserType = OwnerUser
                }
          , milestoneDueOn = Just 2014 (-03) (-13) 07 : 00 : 00 UTC
          , milestoneOpenIssues = 0
          , milestoneNumber = 53
          , milestoneClosedIssues = 203
          , milestoneDescription = Just ""
          , milestoneTitle = "1.12"
          , milestoneUrl =
              "https://api.github.com/repos/rethinkdb/rethinkdb/milestones/53"
          , milestoneCreatedAt = 2013 (-11) (-19) 09 : 47 : 10 UTC
          , milestoneState = "closed"
          }
  }