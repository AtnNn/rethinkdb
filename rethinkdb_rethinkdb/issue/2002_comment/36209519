IssueComment
  { issueCommentUpdatedAt = 2014 (-02) (-27) 04 : 33 : 56 UTC
  , issueCommentUser =
      SimpleUser
        { simpleUserId = Id 316661
        , simpleUserLogin = N "timmaxw"
        , simpleUserAvatarUrl =
            "https://avatars.githubusercontent.com/u/316661?v=3"
        , simpleUserUrl = "https://api.github.com/users/timmaxw"
        , simpleUserType = OwnerUser
        }
  , issueCommentUrl =
      "https://api.github.com/repos/rethinkdb/rethinkdb/issues/comments/36209519"
  , issueCommentHtmlUrl =
      "https://github.com/rethinkdb/rethinkdb/issues/2002#issuecomment-36209519"
  , issueCommentCreatedAt = 2014 (-02) (-27) 04 : 33 : 56 UTC
  , issueCommentBody =
      "I agree with the diagnosis, but not the proposed solution.\r\n\r\nI'd like to begin by providing a more detailed description of what's going on:\r\n\r\nThe metainfo block associates a `version_range_t` with each range of keys on disk. The `version_range_t` consists of two `version_t`s. In normal operation, the two `version_t`s are equal, and they indicate whatever version of the data is currently present on the disk. During a backfill, the first `version_t`s is set to the version that we started the backfill from, and the second one is set to the version that the backfill ends at. When the two `version_t`s differ, the `version_range_t` is said to be \"incoherent\". In normal operation, they will both be set to the later `version_t` as soon as the backfill is over, and then things will proceed as normal.\r\n\r\nIn this situation, the backfill is interrupted, so the data on disk is a partial copy of the data that the dead primary had. The `version_range_t` in the metainfo is left incoherent; its first `version_t` is the \"zero\" `version_t`, and its second `version_t` is the `version_t` that the former primary was at when the secondary began backfilling.\r\n\r\nWhen a node is trying to become primary, it determines the most recent version of the data, then tries to find a coherent copy of that most recent version. If it doesn't find one, then it blocks, as Michel discovered. This is intentional; we assumed something else would resolve the situation and allow the reactor to proceed. There are two ways for the cluster to resolve this situation, and neither is ideal:\r\n\r\n1. We can rewind to the last version for which a coherent copy is available. In practice, we would implement this by determining which version that is, and then blowing away any incoherent versions for which the second `version_t` is after the coherent version we are rewinding to. After the data is blown away, the coherent version will be the most recent version visible to the cluster, so the cluster will happily backfill from it and then proceed as normal.\r\n\r\n    The obvious problem with this is that it destroys data. For example, in the particular situation that prompted this bug report, this would mean deleting all of the data.\r\n\r\n2. We can take whatever data is currently available, and declare it to be valid. In practice, we would implement this by constructing a new `version_t` that is the successor to the second `version_t` of the incoherent `version_range_t`, and then re-tagging whatever data that we have with that `version_t`. This will make it both coherent and a successor to every other version available, so the cluster will proceed normally.\r\n\r\n    If we resolve the problem this way, we get to keep whatever data was successfully backfilled. But even so, we will lose some data. Also, we lose ordering guarantees. Normally, if a client makes a write, waits for an ack, then makes a second write, then it's impossible for the second write to be visible and the first not visible. But this re-tagging will break that guarantee, which might confuse some applications. So this method is not strictly better than the other for some applications; in particular, keep in mind that the most recent coherent version might only be a tiny bit out of data.\r\n\r\nSince we can't recover the data perfectly by either method, and neither method of recovery is strictly better than the other, I think we should require admin intervention. In fact, this is what we originally planned to implement, if I recall correctly; there are comments in `reactor_t` saying that the administrator should intervene if this happens.\r\n\r\nHere's how we would implement it: Any node can determine that there is a deadlock by examining the directory. It should then display an issue in the web UI. The admin should see an explanation of the problem. They should be able to choose between the two options above. We can show a message of the form, \"If you choose to return to the most recent coherent version, you will lose the most recent X writes out of Y writes total.\" (X and Y can be computed by looking at the `version_t`s.) When the admin clicks the button, the node that is running the admin UI will send a message to the node(s) that need to blow away or re-tag their data. We could send this message via a mailbox in the `reactor_business_card_t`; or, there might be a way to send the message via the semilattices. The nodes react to the message by blowing away or re-tagging their data. When these changes are made, they are announced via the directory, so every machine can see that the problem has been resolved. Then the issue in the web UI goes away, the `reactor_t` unblocks itself, and the cluster proceeds as normal."
  , issueCommentId = 36209519
  }