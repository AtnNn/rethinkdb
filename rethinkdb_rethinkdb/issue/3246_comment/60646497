IssueComment
  { issueCommentUpdatedAt = 2014 (-10) (-27) 18 : 37 : 39 UTC
  , issueCommentUser =
      SimpleUser
        { simpleUserId = Id 505365
        , simpleUserLogin = N "danielmewes"
        , simpleUserAvatarUrl =
            "https://avatars.githubusercontent.com/u/505365?v=3"
        , simpleUserUrl = "https://api.github.com/users/danielmewes"
        , simpleUserType = OwnerUser
        }
  , issueCommentUrl =
      "https://api.github.com/repos/rethinkdb/rethinkdb/issues/comments/60646497"
  , issueCommentHtmlUrl =
      "https://github.com/rethinkdb/rethinkdb/issues/3246#issuecomment-60646497"
  , issueCommentCreatedAt = 2014 (-10) (-27) 18 : 37 : 39 UTC
  , issueCommentBody =
      "Generally everytime you bring a node back up it will go through a very short backfill stage (I think) because it doesn't know that it's still up to date.\r\n\r\nThis is usually very fast, but if there are other longer running backfills it might get throttled and wait for the other tables to finish backfilling first (also see your other issue https://github.com/rethinkdb/rethinkdb/issues/2732).\r\n\r\nWe might be able to do backfill throttling differently to avoid such cases, or even just add a special detection for cases like this where there have been no changes to bypass the throttling.\r\nThere could be an opportunity for doing that when implementing https://github.com/rethinkdb/rethinkdb/issues/1944, but I'm not sure if they are really related."
  , issueCommentId = 60646497
  }