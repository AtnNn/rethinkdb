IssueComment
  { issueCommentUpdatedAt = 2013 (-08) (-27) 23 : 54 : 32 UTC
  , issueCommentUser =
      SimpleUser
        { simpleUserId = Id 646357
        , simpleUserLogin = N "wmrowan"
        , simpleUserAvatarUrl =
            "https://avatars.githubusercontent.com/u/646357?v=3"
        , simpleUserUrl = "https://api.github.com/users/wmrowan"
        , simpleUserType = OwnerUser
        }
  , issueCommentUrl =
      "https://api.github.com/repos/rethinkdb/rethinkdb/issues/comments/23380561"
  , issueCommentHtmlUrl =
      "https://github.com/rethinkdb/rethinkdb/issues/1043#issuecomment-23380561"
  , issueCommentCreatedAt = 2013 (-08) (-27) 23 : 54 : 32 UTC
  , issueCommentBody =
      "I fixed a memory issue where we were allocating several very large buffers per shard for possible backfill operations. We now allocate those on demand (that is, on backfill). There are a number of other performance issues that scale with the number of hash shards though.\r\n\r\nIn particular, when @danielmewes and I were investigating possible performance issues we discovered that all queries (even read queries) suffer a substantial slowdown proportional to the number of total shards (tables * range shards * hash shard factor) in the database. We \"fixed\" this problem, among others, simply by reducing the hash shard factor. To bump this up again we'll have to address this bottleneck."
  , issueCommentId = 23380561
  }