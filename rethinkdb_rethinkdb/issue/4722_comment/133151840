IssueComment
  { issueCommentUpdatedAt = 2015 (-08) (-20) 19 : 50 : 00 UTC
  , issueCommentUser =
      SimpleUser
        { simpleUserId = Id 505365
        , simpleUserLogin = N "danielmewes"
        , simpleUserAvatarUrl =
            "https://avatars.githubusercontent.com/u/505365?v=3"
        , simpleUserUrl = "https://api.github.com/users/danielmewes"
        , simpleUserType = OwnerUser
        }
  , issueCommentUrl =
      "https://api.github.com/repos/rethinkdb/rethinkdb/issues/comments/133151840"
  , issueCommentHtmlUrl =
      "https://github.com/rethinkdb/rethinkdb/issues/4722#issuecomment-133151840"
  , issueCommentCreatedAt = 2015 (-08) (-20) 19 : 50 : 00 UTC
  , issueCommentBody =
      "I think 1 second for reading 64,000 documents isn't totally unreasonable, depending on the CPU performance of the servers (2 cores isn't that much), the network bandwidth, and the performance of the client used.\r\n\r\n@nodesocket could you check CPU usage on both the servers (ideally on the one that the client is connecting to), and on the client as well?\r\n\r\nWhat do the documents in the table look like? In particular, what's their average size and how many fields do they have?\r\nWhich client are you using?"
  , issueCommentId = 133151840
  }