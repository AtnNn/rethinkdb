IssueComment
  { issueCommentUpdatedAt = 2015 (-09) (-16) 11 : 42 : 34 UTC
  , issueCommentUser =
      SimpleUser
        { simpleUserId = Id 6009682
        , simpleUserLogin = N "stephanbuys"
        , simpleUserAvatarUrl =
            "https://avatars.githubusercontent.com/u/6009682?v=3"
        , simpleUserUrl = "https://api.github.com/users/stephanbuys"
        , simpleUserType = OwnerUser
        }
  , issueCommentUrl =
      "https://api.github.com/repos/rethinkdb/rethinkdb/issues/comments/140715601"
  , issueCommentHtmlUrl =
      "https://github.com/rethinkdb/rethinkdb/issues/4828#issuecomment-140715601"
  , issueCommentCreatedAt = 2015 (-09) (-16) 11 : 42 : 34 UTC
  , issueCommentBody =
      "Hi @danielmewes,\r\n\r\nThanks very much for the response. Do you have any numbers to share wrt table size, etc. Are there any special considerations when it comes to 'analytics' data? You mention a memory overhead, I'm not sure how that will be triggered? \r\n\r\nI'm under the impression that Elasticsearch is deprecating the 'rivers' plugins in favour of just ingesting data using Logstash. That said I image it would be easy to integrate RethinkDB with something like RabbitMQ to publish any changes (as per some sort of ReQL query), and then push those to Elasticsearch via Logstash (consuming form RabbitMQ or Kafka)?\r\n\r\n "
  , issueCommentId = 140715601
  }