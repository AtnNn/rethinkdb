IssueComment
  { issueCommentUpdatedAt = 2014 (-12) (-01) 19 : 00 : 57 UTC
  , issueCommentUser =
      SimpleUser
        { simpleUserId = Id 505365
        , simpleUserLogin = N "danielmewes"
        , simpleUserAvatarUrl =
            "https://avatars.githubusercontent.com/u/505365?v=3"
        , simpleUserUrl = "https://api.github.com/users/danielmewes"
        , simpleUserType = OwnerUser
        }
  , issueCommentUrl =
      "https://api.github.com/repos/rethinkdb/rethinkdb/issues/comments/65115972"
  , issueCommentHtmlUrl =
      "https://github.com/rethinkdb/rethinkdb/issues/3380#issuecomment-65115972"
  , issueCommentCreatedAt = 2014 (-12) (-01) 19 : 00 : 57 UTC
  , issueCommentBody =
      "Hi @pzol , thank you for opening a report here.\r\n\r\nTo copy from my response on the mailing list:\r\n\r\n> such a slow insert throughput is indeed odd. It's possible that `rethinkdb import` doesn't chose the batch size very well. Can you try increasing the number of concurrent clients for `rethinkdb import` through the `--clients NUM_CLIENTS` command line option? 64 might be a good value to try.\r\nIf this doesn't help, there might be something else wrong with either `rethinkdb import` or the server. We would have to investigate that.\r\n> \r\n> Another thing worth checking is the server's cache size. If you go to the web UI and the \"Logs\" page, you will find an entry such as \"Using cache size of ... MB\". RethinkDB by default configures its cache size based on the available RAM on the machine when it is started, but that's not always reliable. You might get better results by increasing the cache size through the `--cache-size <MB>` parameter to the RethinkDB server. Good values are in the range of half the amount of RAM in your machine.\r\n> \r\n> A small cache could also explain the slow count, as it might have been necessary to load a lot of data from the SSD for the query."
  , issueCommentId = 65115972
  }