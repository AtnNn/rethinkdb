Issue
  { issueClosedAt = Nothing
  , issueUpdatedAt = 2016 (-04) (-07) 17 : 54 : 23 UTC
  , issueEventsUrl =
      "https://api.github.com/repos/rethinkdb/rethinkdb/issues/4271/events"
  , issueHtmlUrl =
      Just "https://github.com/rethinkdb/rethinkdb/issues/4271"
  , issueClosedBy = Nothing
  , issueLabels =
      [ IssueLabel
          { labelColor = "e10c02"
          , labelUrl =
              "https://api.github.com/repos/rethinkdb/rethinkdb/labels/pr:high"
          , labelName = "pr:high"
          }
      , IssueLabel
          { labelColor = "444444"
          , labelUrl =
              "https://api.github.com/repos/rethinkdb/rethinkdb/labels/tp:performance"
          , labelName = "tp:performance"
          }
      ]
  , issueNumber = 4271
  , issueAssignee =
      Just
        SimpleUser
          { simpleUserId = Id 1777134
          , simpleUserLogin = N "mlucy"
          , simpleUserAvatarUrl =
              "https://avatars.githubusercontent.com/u/1777134?v=3"
          , simpleUserUrl = "https://api.github.com/users/mlucy"
          , simpleUserType = OwnerUser
          }
  , issueUser =
      SimpleUser
        { simpleUserId = Id 328614
        , simpleUserLogin = N "bcantrill"
        , simpleUserAvatarUrl =
            "https://avatars.githubusercontent.com/u/328614?v=3"
        , simpleUserUrl = "https://api.github.com/users/bcantrill"
        , simpleUserType = OwnerUser
        }
  , issueTitle =
      "datum_t::get_field() exhibits pathological performance on missing attributes"
  , issuePullRequest = Nothing
  , issueUrl =
      "https://api.github.com/repos/rethinkdb/rethinkdb/issues/4271"
  , issueCreatedAt = 2015 (-05) (-23) 02 : 54 : 46 UTC
  , issueBody =
      Just
        "I have a database that consists of ~200,000 JSON documents.  I have noticed vast differences on query time depending on the presence of a property.  For example, here is a query that looks for a match on a property named \"node\".  This property is present in all documents, and the filter returns a selection of 116 of them: \n\n```\n$ time rql 'r.table(\"dumps\").filter({\"node\": \"486Y9R1\"}).pluck(\"dump\")'\n\nreal    0m0.710s\nuser    0m0.121s\nsys     0m0.051s\n```\n\nConsidering that this property is unindexed, this performance is great.  If, however, the query is on a property that is present in many fewer of the documents, the query time is increased by an order of magnitude.  This is a query of a property that is only present in ~12,000 of the documents: \n\n```\n$ time rql 'r.table(\"dumps\").filter({\"ticket\": \"OS-1028\"}).pluck(\"dump\")'\n\nreal    0m15.891s\nuser    0m0.125s\nsys     0m0.054s\n```\n\nAnd if the filter is phrased as a function, the performance degrades by another order of magnitude:\n\n```\n$ time rql 'r.table(\"dumps\").filter(lambda dump: dump[\"ticket\"] == \"OS-1028\").pluck(\"dump\")'\n\nreal    3m8.122s\nuser    0m0.090s\nsys     0m0.038s\n```\n\nNote that this cannot simply be explained by the additional overhead of executing an arbitrary function; returning to the first query but rephrasing it in terms of a function results in a much more modest hit: \n\n```\n$ time rql 'r.table(\"dumps\").filter(lambda dump: dump[\"node\"] == \"486Y9R1\").pluck(\"dump\")'\n\nreal    0m1.314s\nuser    0m0.120s\nsys     0m0.050s\n```\n\nI am running this on a DTrace-capable Linux platform (namely, a Linux container on [the Triton stack](http://dtrace.org/blogs/bmc/2015/03/24/triton-docker-and-the-best-of-all-worlds/)); looking into this with DTrace reveals that in the most pathological case, we're spending a significant amount of time in vfprintf(): \n\n```\n# dtrace -n profile-1234hz'/arg1 != NULL && execname == \"rethinkdb\"/{@[usym(arg1)] = count()}' -n tick-1sec'/++i == 10/{trunc(@, 30); printa(\"%10@d %A\\n\", @); exit(0)}' -q\n       195 libc.so.6`0x7ffffbc86e5f\n       210 rethinkdb`0x972d10\n       210 rethinkdb`_Z10force_readP13read_stream_tPvl\n       220 rethinkdb`_ZN2ql7datum_t14data_wrapper_t11assign_copyERKS1_\n       233 rethinkdb`cJSON_CreateStringN\n       289 libc.so.6`0x7ffffbc86ea6\n       299 rethinkdb`_ZN2ql20datum_get_array_sizeERK16shared_buf_ref_tIcE\n       322 libpthread.so.0`__lll_unlock_wake\n       325 rethinkdb`_ZN2ql31datum_deserialize_pair_from_bufERK16shared_buf_ref_tIcEm\n       328 rethinkdb`_ZNK2ql7datum_t11as_json_rawEv\n       369 libc.so.6`__printf_fp\n       382 libpthread.so.0`pthread_mutex_unlock\n       417 libc.so.6`0x7ffffbc724a8\n       436 libc.so.6`0x7ffffbc724f8\n       438 libc.so.6`0x7ffffbc724b7\n       449 libc.so.6`0x7ffffbc724f0\n       466 rethinkdb`_ZN2ql26datum_deserialize_from_bufERK16shared_buf_ref_tIcEm\n       480 libstdc++.so.6`__gxx_personality_v0\n       487 libpthread.so.0`__lll_lock_wait\n       559 rethinkdb`_ZN2ql24datum_get_element_offsetERK16shared_buf_ref_tIcEm\n       583 rethinkdb`_ZN2ql7datum_t14data_wrapper_t8destructEv\n       637 libc.so.6`0x7ffffbc86ea2\n       642 libpthread.so.0`pthread_mutex_lock\n       841 rethinkdb`_ZNK14datum_string_t4sizeEv\n       861 libc.so.6`strlen\n      1068 libc.so.6`0x7ffffbc724a0\n      1443 libc.so.6`_IO_default_xsputn\n      1652 rethinkdb`malloc\n      1666 rethinkdb`free\n      2408 libc.so.6`vfprintf\n```\n\nHere's where those calls are coming from:\n\n```\n# dtrace -n pid14912::vfprintf:entry'{@[usym(ucaller)] = count()}'\ndtrace: description 'pid14912::vfprintf:entry' matched 2 probes\n^C\n\n  libc.so.6`__vsnprintf_chk                                    142145\n  libc.so.6`__vasprintf_chk                                    370300\n```\n\nDigging into where these are coming from:\n\n```\n#pragma D option strsize=128\n\npid$target::__vsnprintf_chk:entry\n{\n    self->buf = arg0;\n}\n\npid$target::__vsnprintf_chk:return\n/self->buf/\n{\n    @[copyinstr(self->buf)] = count();\n    self->buf = NULL;\n}\n\nEND\n{\n    trunc(@, 10);\n}\n```\n\nHere's the output running for a few seconds on the pathological query:\n\n```\n$ dtrace -s ./re-snprintf.d -p 14912\ndtrace: script './re.d' matched 3 probes\n^C\nCPU     ID                    FUNCTION:NAME\n  2      2                             :END \n\n  No attribute `ticket` in object:\n{\n    \"cmd\":  \"zabbix_sender\",\n    \"dump\": \"/thoth/stor/thoth/b811bc0736b2cf885d700ec47d33821f/core.z               28\n  No attribute `ticket` in object:\n{\n    \"cmd\":  \"zabbix_sender\",\n    \"dump\": \"/thoth/stor/thoth/b86a105f641545827b96ade8977c8753/core.z               28\n  No attribute `ticket` in object:\n{\n    \"cmd\":  \"zdb\",\n    \"dump\": \"/thoth/stor/thoth/b795da70280bccb539826e4555ce1354/core.zdb.87172\",               28\n  No attribute `ticket` in object:\n{\n    \"cmd\":  \"zdb\",\n    \"dump\": \"/thoth/stor/thoth/b890ccbbd943a35c76753f3f5c4c049c/core.zdb.54093\",               28\n  No attribute `ticket` in object:\n{\n    \"dump\": \"/thoth/stor/thoth/b80c1a837b2faf8ae44b5e77dda9831e/vmcore.0\",\n    \"id\":   \"b80c1a837b2f               28\n  Evaluating pluck.                                                40\n  Evaluating bracket.                                          175367\n  Evaluating EQ.                                               175368\n  Evaluating var.                                              175407\n  Evaluating datum.                                            185719\n```\n\nIf it isn't clear, the objects themselves that lack the specified property are clearly be snprintf()'d in a human-readable way!  Looking for the \"No attribute\" string in the source reveals the source: \n\n```\ndatum_t datum_t::get_field(const datum_string_t &key, throw_bool_t throw_bool) const {\n    // Use binary search on top of unchecked_get_pair()\n    size_t range_beg = 0;\n    // The obj_size() also makes sure that this has the right type (R_OBJECT)\n    size_t range_end = obj_size();\n    while (range_beg < range_end) {\n        const size_t center = range_beg + ((range_end - range_beg) / 2);\n        auto center_pair = unchecked_get_pair(center);\n        const int cmp = key.compare(center_pair.first);\n        if (cmp == 0) {\n            // Found it\n            return center_pair.second;\n        } else if (cmp < 0) {\n            range_end = center;\n        } else {\n            range_beg = center + 1;\n        }\n        rassert(range_beg <= range_end);\n    }\n\n    // Didn't find it\n    if (throw_bool == THROW) {\n        rfail(base_exc_t::NON_EXISTENCE,\n              \"No attribute `%s` in object:\\n%s\", key.to_std().c_str(), print().c_str());\n    }\n    return datum_t();\n}\n```\n\nHere's a script which explores the amount of time we're actually spending in datum_t::get_field() for missing properties:\n\n```\n#pragma D option quiet\n\nBEGIN\n{\n    start = timestamp;\n}\n\npid$target::_ZNK2ql7datum_t9get_fieldERK14datum_string_tNS_12throw_bool_tE:entry\n{\n    self->ts = vtimestamp;\n    @ttl = count();\n}\n\npid$target::__cxa_throw:entry\n/self->ts/\n{\n    @missing = sum(vtimestamp - self->ts);\n    @ttlmissing = count();\n    self->ts = 0;\n}\n\npid$target::_ZNK2ql7datum_t9get_fieldERK14datum_string_tNS_12throw_bool_tE:return\n/self->ts/\n{\n    @found = sum(vtimestamp - self->ts);\n    @ttlfound = count();\n    self->ts = 0;\n}\n\nsched:::on-cpu\n/pid == $target/\n{\n    self->on = vtimestamp;\n}\n\nsched:::off-cpu\n/pid == $target && self->on/\n{\n    @alltime = sum(vtimestamp - self->on);\n}\n\ntick-100ms\n/timestamp - start > 60 * 1000000000/\n{\n    normalize(@found, 1000000);\n    normalize(@missing, 1000000);\n    normalize(@alltime, 1000000);\n\n    printf(\"%10d => wall clock ms\\n\", (timestamp - start) / 1000000);\n    printa(\"%10@d => total CPU ms\\n\\n\", @alltime);\n    printa(\"%10@d => total calls to datum_t::get_field()\\n\", @ttl);\n    printa(\"%10@d => calls on found attributes\\n\", @ttlfound);\n    printa(\"%10@d => calls on missing attributes\\n\\n\", @ttlmissing);\n    printa(\"%10@d => total CPU ms on found attributes\\n\", @found);\n    printa(\"%10@d => total CPU ms on missing attributes\\n\", @missing);\n    exit(0);\n}\n```\n\nRunning this for one of the (several) minutes that the pathological query is running yields:\n\n```\n     60081 => wall clock ms\n    239799 => total CPU ms\n\n    316125 => total calls to datum_t::get_field()\n     19194 => calls on found attributes\n    296931 => calls on missing attributes\n\n       103 => total CPU ms on found attributes\n    112481 => total CPU ms on missing attributes\n```\n\nThis is telling us that at least half of our CPU time is being spent in datum_t::get_field() on missing attributes -- with a whopping ~380 usecs per call.  Further, it seems quite possible (if not likely) that the other half of our CPU time is being spent on the mechanics of throwing and then (presumably) discarding the exception.  It seems at the very, very least datum_t::get_field() should not be printing an entire verbatim, human-readable copy of the object before it throws that an attribute is missing.  Beyond that, it seems likely that performance could be substantially improved by using (or introducing, as necessary) a method that would get a property without throwing an exception on its absence (that is, returning failure instead of throwing an exception).  \n"
  , issueState = "open"
  , issueId = Id 79702687
  , issueComments = 16
  , issueMilestone =
      Just
        Milestone
          { milestoneCreator =
              SimpleUser
                { simpleUserId = Id 48436
                , simpleUserLogin = N "coffeemug"
                , simpleUserAvatarUrl =
                    "https://avatars.githubusercontent.com/u/48436?v=3"
                , simpleUserUrl = "https://api.github.com/users/coffeemug"
                , simpleUserType = OwnerUser
                }
          , milestoneDueOn = Nothing
          , milestoneOpenIssues = 268
          , milestoneNumber = 41
          , milestoneClosedIssues = 0
          , milestoneDescription =
              Just
                "Issues in this milestone will be revisited after each major release during the planning stage for the major release after it. They will be moved to a specific release milestone if chosen for that release."
          , milestoneTitle = "subsequent"
          , milestoneUrl =
              "https://api.github.com/repos/rethinkdb/rethinkdb/milestones/41"
          , milestoneCreatedAt = 2013 (-06) (-30) 07 : 32 : 52 UTC
          , milestoneState = "open"
          }
  }