IssueComment
  { issueCommentUpdatedAt = 2013 (-04) (-03) 05 : 38 : 50 UTC
  , issueCommentUser =
      SimpleUser
        { simpleUserId = Id 48436
        , simpleUserLogin = N "coffeemug"
        , simpleUserAvatarUrl =
            "https://avatars.githubusercontent.com/u/48436?v=3"
        , simpleUserUrl = "https://api.github.com/users/coffeemug"
        , simpleUserType = OwnerUser
        }
  , issueCommentUrl =
      "https://api.github.com/repos/rethinkdb/rethinkdb/issues/comments/15819298"
  , issueCommentHtmlUrl =
      "https://github.com/rethinkdb/rethinkdb/issues/505#issuecomment-15819298"
  , issueCommentCreatedAt = 2013 (-04) (-03) 05 : 38 : 50 UTC
  , issueCommentBody =
      "@mlucy -- what concerns me here is that `filter` isn't a strict operation, so even if things like datums are 3x as big, the entire system still shouldn't use nearly as much as 3x as much RAM. Theoretically, this should be the size of our buffers (1000 rows?) time the memory increase, not the entire table times the memory increase."
  , issueCommentId = 15819298
  }