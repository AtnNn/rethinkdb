Issue
  { issueClosedAt = Nothing
  , issueUpdatedAt = 2016 (-07) (-11) 22 : 24 : 38 UTC
  , issueEventsUrl =
      "https://api.github.com/repos/rethinkdb/rethinkdb/issues/5913/events"
  , issueHtmlUrl =
      Just "https://github.com/rethinkdb/rethinkdb/issues/5913"
  , issueClosedBy = Nothing
  , issueLabels =
      [ IssueLabel
          { labelColor = "e10c02"
          , labelUrl =
              "https://api.github.com/repos/rethinkdb/rethinkdb/labels/pr:high"
          , labelName = "pr:high"
          }
      , IssueLabel
          { labelColor = "e102d8"
          , labelUrl =
              "https://api.github.com/repos/rethinkdb/rethinkdb/labels/tp:bug"
          , labelName = "tp:bug"
          }
      ]
  , issueNumber = 5913
  , issueAssignee = Nothing
  , issueUser =
      SimpleUser
        { simpleUserId = Id 7917
        , simpleUserLogin = N "bsharpe"
        , simpleUserAvatarUrl =
            "https://avatars.githubusercontent.com/u/7917?v=3"
        , simpleUserUrl = "https://api.github.com/users/bsharpe"
        , simpleUserType = OwnerUser
        }
  , issueTitle = "Exited with Errors also..."
  , issuePullRequest = Nothing
  , issueUrl =
      "https://api.github.com/repos/rethinkdb/rethinkdb/issues/5913"
  , issueCreatedAt = 2016 (-07) (-04) 05 : 21 : 52 UTC
  , issueBody =
      Just
        "```\r\n2016-07-04T04:44:12.495253553 181.567158s error: Error in src/btree/leaf_node.cc at line 1086:\r\n2016-07-04T04:44:12.495336021 181.567239s error: Guarantee failed: [node_weight < sibling_weight] \r\n2016-07-04T04:44:12.495352028 181.567255s error: Backtrace:\r\n2016-07-04T04:44:13.027721426 182.099628s error: Mon Jul  4 04:44:12 2016\\n\\n1 [0xabb110]: backtrace_t::backtrace_t() at ??:?\\n2 [0xabb4a3]: format_backtrace(bool) at ??:?\\n3 [0xd3e78d]: report_fatal_error(char const*, int, char const*, ...) at ??:?\\n4 [0xa43496]: leaf::level(value_sizer_t*, int, leaf_node_t*, leaf_node_t*, btree_key_t*, std::vector<void const*, std::allocator<void const*> >*) at ??:?\\n5 [0xa4ed1a]: check_and_handle_underfull(value_sizer_t*, buf_lock_t*, buf_lock_t*, superblock_t*, btree_key_t const*, value_deleter_t const*) at ??:?\\n6 [0xa4f096]: apply_keyvalue_change(value_sizer_t*, keyvalue_location_t*, btree_key_t const*, repli_timestamp_t, value_deleter_t const*, key_modification_callback_t*, delete_mode_t) at ??:?\\n7 [0x80bc91]: kv_location_set(keyvalue_location_t*, store_key_t const&, std::vector<char, std::allocator<char> > const&, repli_timestamp_t, deletion_context_t const*) at ??:?\\n8 [0x810232]: rdb_update_single_sindex(store_t*, store_t::sindex_access_t const*, deletion_context_t const*, rdb_modification_report_t const*, unsigned long*, auto_drainer_t::lock_t, cond_t*, std::vector<std::pair<ql::datum_t, std::string>, std::allocator<std::pair<ql::datum_t, std::string> > >*, std::vector<std::pair<ql::datum_t, std::string>, std::allocator<std::pair<ql::datum_t, std::string> > >*) at ??:?\\n9 [0x8173d6]: callable_action_instance_t<std::_Bind<void (*(store_t*, store_t::sindex_access_t*, deletion_context_t const*, rdb_modification_report_t const*, unsigned long*, auto_drainer_t::lock_t, cond_t*, std::vector<std::pair<ql::datum_t, std::string>, std::allocator<std::pair<ql::datum_t, std::string> > >*, std::vector<std::pair<ql::datum_t, std::string>, std::allocator<std::pair<ql::datum_t, std::string> > >*))(store_t*, store_t::sindex_access_t const*, deletion_context_t const*, rdb_modification_report_t const*, unsigned long*, auto_drainer_t::lock_t, cond_t*, std::vector<std::pair<ql::datum_t, std::string>, std::allocator<std::pair<ql::datum_t, std::string> > >*, std::vector<std::pair<ql::datum_t, std::string>, std::allocator<std::pair<ql::datum_t, std::string> > >*)> >::run_action() at ??:?\\n10 [0x9dab27]: coro_t::run() at ??:?\r\n2016-07-04T04:44:13.027875285 182.099779s error: Exiting.\r\n```\r\nSame node exits every time with same message.   Ended up removing it from the cluster until it can be resolved.  Our cluster has 3 nodes and 33 tables all set to 3shards/3replicas.\r\n\r\nso... we had to drop our 3rd node and all it's shards and replicas...  we resharded to 2 shards/ 2 replicas on nodes 1 & 2 -- which seemed to work fine for a while.\r\n\r\nerased the database file on db-3 -- relaunched db-3 and db-2 started to exit with the same error.\r\n\r\nwaiting to hear from you guys on how to proceed to build our cluster back to full strength..."
  , issueState = "open"
  , issueId = Id 163604649
  , issueComments = 14
  , issueMilestone =
      Just
        Milestone
          { milestoneCreator =
              SimpleUser
                { simpleUserId = Id 505365
                , simpleUserLogin = N "danielmewes"
                , simpleUserAvatarUrl =
                    "https://avatars.githubusercontent.com/u/505365?v=3"
                , simpleUserUrl = "https://api.github.com/users/danielmewes"
                , simpleUserType = OwnerUser
                }
          , milestoneDueOn = Nothing
          , milestoneOpenIssues = 54
          , milestoneNumber = 119
          , milestoneClosedIssues = 8
          , milestoneDescription = Nothing
          , milestoneTitle = "2.3.x"
          , milestoneUrl =
              "https://api.github.com/repos/rethinkdb/rethinkdb/milestones/119"
          , milestoneCreatedAt = 2016 (-04) (-06) 18 : 05 : 18 UTC
          , milestoneState = "open"
          }
  }