IssueComment
  { issueCommentUpdatedAt = 2013 (-08) (-22) 17 : 40 : 15 UTC
  , issueCommentUser =
      SimpleUser
        { simpleUserId = Id 1461947
        , simpleUserLogin = N "neumino"
        , simpleUserAvatarUrl =
            "https://avatars.githubusercontent.com/u/1461947?v=3"
        , simpleUserUrl = "https://api.github.com/users/neumino"
        , simpleUserType = OwnerUser
        }
  , issueCommentUrl =
      "https://api.github.com/repos/rethinkdb/rethinkdb/issues/comments/23110641"
  , issueCommentHtmlUrl =
      "https://github.com/rethinkdb/rethinkdb/issues/1344#issuecomment-23110641"
  , issueCommentCreatedAt = 2013 (-08) (-22) 17 : 40 : 15 UTC
  , issueCommentBody =
      "Yes, their core is about providing estimates, so things are optimized for that. From what I read (I haven't read a lot, so I may be wrong), but they keep some samples in memory that they periodically adjust. \r\nI am not sure RethinkDB will keep some samples in memory, not that because it's impossible or hard to do, but because I would tend to think of estimates as an edge case.\r\n\r\nTypically, if you are a social network, you cannot compute the number of friends of someone just based on a sample because the data is too skewed.\r\n\r\nIncremental map/reduce (https://github.com/rethinkdb/rethinkdb/issues/1118) and triggers (https://github.com/rethinkdb/rethinkdb/issues/997) can probably be an efficient solution/workaround to compute estimates.\r\n"
  , issueCommentId = 23110641
  }