IssueComment
  { issueCommentUpdatedAt = 2014 (-10) (-10) 22 : 18 : 48 UTC
  , issueCommentUser =
      SimpleUser
        { simpleUserId = Id 505365
        , simpleUserLogin = N "danielmewes"
        , simpleUserAvatarUrl =
            "https://avatars.githubusercontent.com/u/505365?v=3"
        , simpleUserUrl = "https://api.github.com/users/danielmewes"
        , simpleUserType = OwnerUser
        }
  , issueCommentUrl =
      "https://api.github.com/repos/rethinkdb/rethinkdb/issues/comments/58723339"
  , issueCommentHtmlUrl =
      "https://github.com/rethinkdb/rethinkdb/issues/152#issuecomment-58723339"
  , issueCommentCreatedAt = 2014 (-10) (-10) 22 : 18 : 44 UTC
  , issueCommentBody =
      "I think resharding without losing availability is independent from incremental backfilling. If we do something like this https://github.com/rethinkdb/rethinkdb/issues/1774#issuecomment-33448169 , we can implement it on top of the current backfilling logic. That solution also relies on splitting shards on a single machine, though it's followed up by a backfill so I suppose we could then still count the documents while backfilling. It sounds like it would introduce loads of corner cases though. What if a node goes down and the backfilling never completes? Then we would have to roll back the local shard split to ensure count() queries keep working.\r\n\r\nThere's definitely a way to make everything work, but my impression is that it wouldn't come cheap."
  , issueCommentId = 58723339
  }