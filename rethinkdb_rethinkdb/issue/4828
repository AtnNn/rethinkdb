Issue
  { issueClosedAt = Just 2016 (-02) (-05) 21 : 14 : 39 UTC
  , issueUpdatedAt = 2016 (-02) (-05) 21 : 14 : 39 UTC
  , issueEventsUrl =
      "https://api.github.com/repos/rethinkdb/rethinkdb/issues/4828/events"
  , issueHtmlUrl =
      Just "https://github.com/rethinkdb/rethinkdb/issues/4828"
  , issueClosedBy = Nothing
  , issueLabels = []
  , issueNumber = 4828
  , issueAssignee = Nothing
  , issueUser =
      SimpleUser
        { simpleUserId = Id 6009682
        , simpleUserLogin = N "stephanbuys"
        , simpleUserAvatarUrl =
            "https://avatars.githubusercontent.com/u/6009682?v=3"
        , simpleUserUrl = "https://api.github.com/users/stephanbuys"
        , simpleUserType = OwnerUser
        }
  , issueTitle = "Analytics use-cases, and full text search"
  , issuePullRequest = Nothing
  , issueUrl =
      "https://api.github.com/repos/rethinkdb/rethinkdb/issues/4828"
  , issueCreatedAt = 2015 (-09) (-11) 06 : 06 : 06 UTC
  , issueBody =
      Just
        "Hi,\n\nI'm very interested in trying RethinkDB for some analytics use-cases, but also possibly search. We have a long history of using Splunk (commercial time-series db), and the similarities between Splunk's SPL (query language) and the ReQL paradigm which makes RethinkDB incredible compelling. We've been using Elasticsearch extensively as it allows for full-text search across massive datasets (its not unheard off to have millions or billions events - think authentication logs in large business) and supports \"aggregations\", the ability to roll up certain columns (sum, avg, max, etc).\n\nI would love to try Rethink and get going with ReQL, as it seems very intuitive and powerful, so my questions are:\n\n1) Can RethinkDB handle massive time-series datasets? Other DBs such as MySQL and Postrgresql often start struggling when tables get massive and index-updating-time starts to hinder inserts.\n2) Can RethinkDB be configured to be an efficient 'search engine'? One of the great things of Elasticsearch is that it indexes everything by default which makes investigating massive event datasets feasible.\n\nWould be awesome to hear from the minds behind RethinkDB as to the feasibility of these use-cases.\n\nCheers!\n"
  , issueState = "closed"
  , issueId = Id 105950587
  , issueComments = 6
  , issueMilestone =
      Just
        Milestone
          { milestoneCreator =
              SimpleUser
                { simpleUserId = Id 706854
                , simpleUserLogin = N "AtnNn"
                , simpleUserAvatarUrl =
                    "https://avatars.githubusercontent.com/u/706854?v=3"
                , simpleUserUrl = "https://api.github.com/users/AtnNn"
                , simpleUserType = OwnerUser
                }
          , milestoneDueOn = Nothing
          , milestoneOpenIssues = 0
          , milestoneNumber = 26
          , milestoneClosedIssues = 316
          , milestoneDescription =
              Just
                "These issues are neither bugs nor feature requests. Spam, user questions and accidentally created issues end up here."
          , milestoneTitle = "invalid"
          , milestoneUrl =
              "https://api.github.com/repos/rethinkdb/rethinkdb/milestones/26"
          , milestoneCreatedAt = 2013 (-04) (-05) 01 : 37 : 20 UTC
          , milestoneState = "closed"
          }
  }