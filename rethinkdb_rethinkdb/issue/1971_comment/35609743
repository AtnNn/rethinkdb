IssueComment
  { issueCommentUpdatedAt = 2014 (-02) (-20) 11 : 06 : 54 UTC
  , issueCommentUser =
      SimpleUser
        { simpleUserId = Id 139396
        , simpleUserLogin = N "wojons"
        , simpleUserAvatarUrl =
            "https://avatars.githubusercontent.com/u/139396?v=3"
        , simpleUserUrl = "https://api.github.com/users/wojons"
        , simpleUserType = OwnerUser
        }
  , issueCommentUrl =
      "https://api.github.com/repos/rethinkdb/rethinkdb/issues/comments/35609743"
  , issueCommentHtmlUrl =
      "https://github.com/rethinkdb/rethinkdb/issues/1971#issuecomment-35609743"
  , issueCommentCreatedAt = 2014 (-02) (-20) 11 : 06 : 54 UTC
  , issueCommentBody =
      "I think this would be fine as a point release dont get me wrong its imporant but the system is still working and running. And something like this on the size of batches should be something that is really well tuned and not picking random numbers from a hat. And if that means it will be in a point release that would be good. But this should be before an LTS\r\n\r\nOne idea for something like this is take into a fact on how tcp knows to send more or less backets by how fast it responds. Pretty much if the host machine sends 100 bytes worth of data and the recivving node responds back in 2 seconds. Then the host may send 200 bytes and if the recving node returns back in 3 seconds it will keep getting faster since the rate the docs are being written to is faster. If it gets slower then it will send less data. Of course this number will never sit still but it will also allow for someone that has SSD drives that may be under hevey load for a moment to get data at a slower rate and then for it to pick up once there is more IO avaiable."
  , issueCommentId = 35609743
  }