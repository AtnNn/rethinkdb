IssueComment
  { issueCommentUpdatedAt = 2013 (-02) (-09) 09 : 20 : 09 UTC
  , issueCommentUser =
      SimpleUser
        { simpleUserId = Id 48436
        , simpleUserLogin = N "coffeemug"
        , simpleUserAvatarUrl =
            "https://avatars.githubusercontent.com/u/48436?v=3"
        , simpleUserUrl = "https://api.github.com/users/coffeemug"
        , simpleUserType = OwnerUser
        }
  , issueCommentUrl =
      "https://api.github.com/repos/rethinkdb/rethinkdb/issues/comments/13328510"
  , issueCommentHtmlUrl =
      "https://github.com/rethinkdb/rethinkdb/issues/310#issuecomment-13328510"
  , issueCommentCreatedAt = 2013 (-02) (-09) 09 : 19 : 41 UTC
  , issueCommentBody =
      "Thank you for reporting this! We've been thinking about compression for some time, but there have been no concrete plans to implement it yet. The real issue here isn't about compression though. What happens with RethinkDB is that the storage engine garbage collector cleans up old blocks, but doesn't reduce the file size. This is something that we're likely to fix in the next two - three months. One way to test if this is actually the issue is to try to insert some data, then stop and let the garbage collector catch up, then insert some more data. It's likely that with this workload RethinkDB will result in much better space utilization. (This is of course no excuse for the behavior you're observing, just an explanation of the current limitations of the system).\r\n\r\nWe're going to get to this soon, but it would be incredibly helpful if you described a little more precisely what you did and how you got to this space utilization. When Rethink hits production ready state in the next few months, space utilization issues will of course be worked out. A minimum example of poor space utilization would be very helpful for us to work this out ASAP.\r\n\r\n"
  , issueCommentId = 13328510
  }