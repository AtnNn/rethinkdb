IssueComment
  { issueCommentUpdatedAt = 2016 (-06) (-13) 20 : 41 : 20 UTC
  , issueCommentUser =
      SimpleUser
        { simpleUserId = Id 614929
        , simpleUserLogin = N "RubenKelevra"
        , simpleUserAvatarUrl =
            "https://avatars.githubusercontent.com/u/614929?v=3"
        , simpleUserUrl = "https://api.github.com/users/RubenKelevra"
        , simpleUserType = OwnerUser
        }
  , issueCommentUrl =
      "https://api.github.com/repos/rethinkdb/rethinkdb/issues/comments/225701713"
  , issueCommentHtmlUrl =
      "https://github.com/rethinkdb/rethinkdb/issues/5852#issuecomment-225701713"
  , issueCommentCreatedAt = 2016 (-06) (-13) 20 : 41 : 07 UTC
  , issueCommentBody =
      "Great, thank you for your fast response. :)\r\n\r\nI think high RTTs on interconnections are inevitable in multi datacenter environments. While we use tcp for all intercluster communications, one lost packet will effect all queries at the same time, because the receiving tcp-stack will wait until the tcp retransmission is arrived, before all remaining data is available for the application on the socket.\r\n\r\nSo a usual RTT of about 60ms and some packets being lost per second, caused by a full link and an red-qdisc, the cluster performance would be decreased immediately, even if the lost packets belong to a bulk data transfer which in itself isn't time critical. \r\n\r\n> Prioritization of messages would be very interesting though to optimize the allocation of network bandwidth!\r\n\r\nWell ... intra-connection QoS does not help increase the network bandwidth, but gonna help on bulk-transfers like cluster-reorderings or bulk write operations to perform in background while heartbeats, write acks and other retain at low latency."
  , issueCommentId = 225701713
  }