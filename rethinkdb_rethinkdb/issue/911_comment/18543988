IssueComment
  { issueCommentUpdatedAt = 2013 (-05) (-28) 11 : 09 : 09 UTC
  , issueCommentUser =
      SimpleUser
        { simpleUserId = Id 229209
        , simpleUserLogin = N "Plasma"
        , simpleUserAvatarUrl =
            "https://avatars.githubusercontent.com/u/229209?v=3"
        , simpleUserUrl = "https://api.github.com/users/Plasma"
        , simpleUserType = OwnerUser
        }
  , issueCommentUrl =
      "https://api.github.com/repos/rethinkdb/rethinkdb/issues/comments/18543988"
  , issueCommentHtmlUrl =
      "https://github.com/rethinkdb/rethinkdb/issues/911#issuecomment-18543988"
  , issueCommentCreatedAt = 2013 (-05) (-28) 11 : 09 : 09 UTC
  , issueCommentBody =
      "Thank's for considering this feature, as I mentioned on IRC to neumino (thank you for listening!) I like where this project is headed and the work you put into features and careful consideration to their design.\r\n\r\nAn example I gave for wanting this feature was for scaling/data locality purposes.\r\n\r\nIf I have a note taking app with 10m users, 10 shards, and a table of \"Note\" (Id, CustomerId, Text), by default each users notes are spanned across each shard - they are spanned across by Primary Key, instead of (ideally) CustomerId in this particular case.\r\n\r\nIf we hit 100m users, adding more shards does not help reduce query volume to each shard, because each customer query still needs to reach each shard. If I could partition by CustomerId then I could theoretically just keep adding shards for more customers as lookups would be routed to a single shard instead of all of them."
  , issueCommentId = 18543988
  }