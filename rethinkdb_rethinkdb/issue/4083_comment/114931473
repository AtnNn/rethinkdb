IssueComment
  { issueCommentUpdatedAt = 2015 (-06) (-24) 16 : 24 : 47 UTC
  , issueCommentUser =
      SimpleUser
        { simpleUserId = Id 54934
        , simpleUserLogin = N "wmertens"
        , simpleUserAvatarUrl =
            "https://avatars.githubusercontent.com/u/54934?v=3"
        , simpleUserUrl = "https://api.github.com/users/wmertens"
        , simpleUserType = OwnerUser
        }
  , issueCommentUrl =
      "https://api.github.com/repos/rethinkdb/rethinkdb/issues/comments/114931473"
  , issueCommentHtmlUrl =
      "https://github.com/rethinkdb/rethinkdb/issues/4083#issuecomment-114931473"
  , issueCommentCreatedAt = 2015 (-06) (-24) 16 : 24 : 47 UTC
  , issueCommentBody =
      "For future interested readers: [This is a great explanation of events-first app data](http://blog.confluent.io/2015/03/04/turning-the-database-inside-out-with-apache-samza/) (AKA event sourcing).\r\n\r\nBasically you need a strictly ordered event log and then calculate the application data from that log, storing it into a database of choice.\r\n\r\nI think RethinkDB could be used for this but indeed using timestamps as primary or secondary keys has some tradeoffs. The derived data could also be stored in RethinkDB, and change feeds would make it all great.\r\n\r\nCertainly a nicer solution than having multiple database products to maintain, and it seems like this would  easily scale from a single host to many? For a small app, using generated keys and a secondary timestamp index looks like the correct choice."
  , issueCommentId = 114931473
  }