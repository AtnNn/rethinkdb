IssueComment
  { issueCommentUpdatedAt = 2013 (-09) (-19) 02 : 29 : 34 UTC
  , issueCommentUser =
      SimpleUser
        { simpleUserId = Id 1461947
        , simpleUserLogin = N "neumino"
        , simpleUserAvatarUrl =
            "https://avatars.githubusercontent.com/u/1461947?v=3"
        , simpleUserUrl = "https://api.github.com/users/neumino"
        , simpleUserType = OwnerUser
        }
  , issueCommentUrl =
      "https://api.github.com/repos/rethinkdb/rethinkdb/issues/comments/24713611"
  , issueCommentHtmlUrl =
      "https://github.com/rethinkdb/rethinkdb/issues/1459#issuecomment-24713611"
  , issueCommentCreatedAt = 2013 (-09) (-19) 02 : 29 : 18 UTC
  , issueCommentBody =
      "Hum, so I think I figured out what's wrong (well, a part of it).\r\n\r\nBasically the protobuf library that the data explorer uses is very slow and is killing v8.\r\n\r\nWith a release binary, if I'm not mistaken, we send batch of 1000 documents, and that's a little too much for the library to parse. Running a debug binary works fine (at least it's better) since we send back batch of 5 documents --- so I end up retrieving and parsing just 40 documents.\r\n\r\nI'm going to take a look at the protobuf library we use in the data explorer and see if there are some easy optimizations to do.\r\nIf not, could we let the driver specify the size of the batch? How hard would it be for the server to have such parameter?"
  , issueCommentId = 24713611
  }