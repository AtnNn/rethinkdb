IssueComment
  { issueCommentUpdatedAt = 2014 (-06) (-13) 21 : 07 : 51 UTC
  , issueCommentUser =
      SimpleUser
        { simpleUserId = Id 48436
        , simpleUserLogin = N "coffeemug"
        , simpleUserAvatarUrl =
            "https://avatars.githubusercontent.com/u/48436?v=3"
        , simpleUserUrl = "https://api.github.com/users/coffeemug"
        , simpleUserType = OwnerUser
        }
  , issueCommentUrl =
      "https://api.github.com/repos/rethinkdb/rethinkdb/issues/comments/46059944"
  , issueCommentHtmlUrl =
      "https://github.com/rethinkdb/rethinkdb/issues/2542#issuecomment-46059944"
  , issueCommentCreatedAt = 2014 (-06) (-13) 21 : 07 : 51 UTC
  , issueCommentBody =
      "> Is this any different from applying a `.filter(r.row('id').eq(id))`?\r\n\r\nScalability. If you filter, the changefeed has to look at every row, so you can't create millions of them. With a changefeed on `get`, you might be able to (at least theoretically).\r\n\r\n> You do the changes call first and then do a get.\r\n\r\nYou might lose documents in between. The flag would guarantee atomicity."
  , issueCommentId = 46059944
  }