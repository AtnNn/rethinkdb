IssueComment
  { issueCommentUpdatedAt = 2015 (-05) (-28) 00 : 17 : 45 UTC
  , issueCommentUser =
      SimpleUser
        { simpleUserId = Id 1777134
        , simpleUserLogin = N "mlucy"
        , simpleUserAvatarUrl =
            "https://avatars.githubusercontent.com/u/1777134?v=3"
        , simpleUserUrl = "https://api.github.com/users/mlucy"
        , simpleUserType = OwnerUser
        }
  , issueCommentUrl =
      "https://api.github.com/repos/rethinkdb/rethinkdb/issues/comments/106119040"
  , issueCommentHtmlUrl =
      "https://github.com/rethinkdb/rethinkdb/issues/1396#issuecomment-106119040"
  , issueCommentCreatedAt = 2015 (-05) (-28) 00 : 17 : 45 UTC
  , issueCommentBody =
      "Thanks for the thoughts @tkodw !\r\n\r\nWikipedia says LZ4 is byte-oriented, so it will have the same problem as Snappy in that it won't be able to compress common bytes down to sub-byte sizes.  In a perfect world we'd be able to use a compression scheme that makes use of entropy encoding, because it turns out our serialization format responds very well to that (I did some rough benchmarks on typical data about a year ago).  We might end up using a byte-oriented compression scheme if gzip turns out to be too slow for our needs and we can't find a better compression scheme that includes entropy encoding.\r\n\r\nWe've definitely thought about static dictionaries.  In a perfect world we'd be able to have shared non-static dictionaries because most people use a de facto schema for their data, so we'd be able to get a lot of extra compression from sharing a symbol table across rows.  This is obviously hard, but maybe we could do something simple that works well in the common case and doesn't degrade too poorly for schemaless data."
  , issueCommentId = 106119040
  }