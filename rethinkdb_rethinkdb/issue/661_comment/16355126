IssueComment
  { issueCommentUpdatedAt = 2013 (-04) (-14) 17 : 34 : 59 UTC
  , issueCommentUser =
      SimpleUser
        { simpleUserId = Id 1777134
        , simpleUserLogin = N "mlucy"
        , simpleUserAvatarUrl =
            "https://avatars.githubusercontent.com/u/1777134?v=3"
        , simpleUserUrl = "https://api.github.com/users/mlucy"
        , simpleUserType = OwnerUser
        }
  , issueCommentUrl =
      "https://api.github.com/repos/rethinkdb/rethinkdb/issues/comments/16355126"
  , issueCommentHtmlUrl =
      "https://github.com/rethinkdb/rethinkdb/issues/661#issuecomment-16355126"
  , issueCommentCreatedAt = 2013 (-04) (-14) 17 : 34 : 59 UTC
  , issueCommentBody =
      "I might have misunderstood the previous comments, but I think the only scenario where it has a performance cost that can't be better addressed with batch sizing is when the time necessary to compute the batches is dominated by network latency, which seems like a fairly rare case.  Even if people decide to go through the public Internet, their latency is likely to be <100 ms.  I get more like .2 ms from newton to dr-doom.\r\n\r\nEven in that scenario, I think the performance issue is better addressed by sending the queries of the inner loop through a separate connection to the same server."
  , issueCommentId = 16355126
  }