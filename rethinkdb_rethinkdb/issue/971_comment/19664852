IssueComment
  { issueCommentUpdatedAt = 2013 (-06) (-19) 06 : 10 : 38 UTC
  , issueCommentUser =
      SimpleUser
        { simpleUserId = Id 43867
        , simpleUserLogin = N "jdoliner"
        , simpleUserAvatarUrl =
            "https://avatars.githubusercontent.com/u/43867?v=3"
        , simpleUserUrl = "https://api.github.com/users/jdoliner"
        , simpleUserType = OwnerUser
        }
  , issueCommentUrl =
      "https://api.github.com/repos/rethinkdb/rethinkdb/issues/comments/19664852"
  , issueCommentHtmlUrl =
      "https://github.com/rethinkdb/rethinkdb/issues/971#issuecomment-19664852"
  , issueCommentCreatedAt = 2013 (-06) (-19) 06 : 10 : 38 UTC
  , issueCommentBody =
      "So one downside I see to picking 10,000 as an arbitrary size limit is that if a user happens to be storing an array that size in a document they're going to run in to problems when they try to migrate on the other hand if we did things memory footprint based and picked a cap over 10MB we'd avoid this problem.\r\n\r\nAlso doing an array size limit like this doesn't actually seem like it addresses the problem that well. The point of this limit is to prevent people from running themselves out of memory or accidentally sending too much stuff over the network but an array of 10,000 numbers really isn't that unreasonable while an array of even 1,000 very large dicts is."
  , issueCommentId = 19664852
  }