IssueComment
  { issueCommentUpdatedAt = 2015 (-05) (-02) 02 : 13 : 59 UTC
  , issueCommentUser =
      SimpleUser
        { simpleUserId = Id 505365
        , simpleUserLogin = N "danielmewes"
        , simpleUserAvatarUrl =
            "https://avatars.githubusercontent.com/u/505365?v=3"
        , simpleUserUrl = "https://api.github.com/users/danielmewes"
        , simpleUserType = OwnerUser
        }
  , issueCommentUrl =
      "https://api.github.com/repos/rethinkdb/rethinkdb/issues/comments/98290649"
  , issueCommentHtmlUrl =
      "https://github.com/rethinkdb/rethinkdb/issues/4036#issuecomment-98290649"
  , issueCommentCreatedAt = 2015 (-05) (-02) 02 : 13 : 59 UTC
  , issueCommentBody =
      "It appears that if the server is using SSD storage, the bottleneck partially shifts to the Python driver. It seems to become relatively slow when it encounters the large documents (though the PHP driver for example is even slower).\r\nThat being said the server is using a fair bit of CPU as well. In contrast to rotational drives, I/O doesn't seem to be the primary bottleneck on SSDs anymore.\r\n\r\n@kikohs to explain what the Python driver has to do with this: The `rethinkdb export` script internally uses the Python driver to load the data from the server."
  , issueCommentId = 98290649
  }