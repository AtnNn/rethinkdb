IssueComment
  { issueCommentUpdatedAt = 2013 (-12) (-14) 23 : 06 : 52 UTC
  , issueCommentUser =
      SimpleUser
        { simpleUserId = Id 139396
        , simpleUserLogin = N "wojons"
        , simpleUserAvatarUrl =
            "https://avatars.githubusercontent.com/u/139396?v=3"
        , simpleUserUrl = "https://api.github.com/users/wojons"
        , simpleUserType = OwnerUser
        }
  , issueCommentUrl =
      "https://api.github.com/repos/rethinkdb/rethinkdb/issues/comments/30593617"
  , issueCommentHtmlUrl =
      "https://github.com/rethinkdb/rethinkdb/issues/1771#issuecomment-30593617"
  , issueCommentCreatedAt = 2013 (-12) (-14) 23 : 06 : 52 UTC
  , issueCommentBody =
      "There are always use cases in mind for things like memory tables. For example its nice to have fully queryable data that is super fast and exists in memory. Its nice to have that queryable cache. There can be two modes. One is if it works like a FIFO or something like that the older docs get pushed out. Or as you said it just rejects the writes. I guess a 3rd type can always be putting it on disk. Not to say its a good thing but its great for the cases when the delete script is running cleaning up the table at the same time the big insert comes into place. \r\n\r\nBut back to my use case as you know i keep stats in rethinkdb so when new stats come in I would write them to both the memory table and the disk table. If the stats are still in the cache be able to try to get the recent docs from there if not just hit the disk based ones. "
  , issueCommentId = 30593617
  }