IssueComment
  { issueCommentUpdatedAt = 2016 (-01) (-13) 20 : 43 : 42 UTC
  , issueCommentUser =
      SimpleUser
        { simpleUserId = Id 949134
        , simpleUserLogin = N "WesleyDavid"
        , simpleUserAvatarUrl =
            "https://avatars.githubusercontent.com/u/949134?v=3"
        , simpleUserUrl = "https://api.github.com/users/WesleyDavid"
        , simpleUserType = OwnerUser
        }
  , issueCommentUrl =
      "https://api.github.com/repos/rethinkdb/rethinkdb/issues/comments/171415583"
  , issueCommentHtmlUrl =
      "https://github.com/rethinkdb/rethinkdb/issues/4608#issuecomment-171415583"
  , issueCommentCreatedAt = 2016 (-01) (-13) 19 : 59 : 28 UTC
  , issueCommentBody =
      "Just a note to add a voice to this conversation:\r\n\r\nIn my scenario I keep track of many RethinkDB clusters for customers, and each cluster is spread across at least three physical hosts. Customers are responsible for their management of the actual data, so I don't cross the threshold into the running Rethink process.\r\n\r\nIn this case, customers that are unfamiliar with RethinkDB defaults had created tables, but not explicitly configured sharding and replication. The default 1 shard and 1 replica option was used for most, if not all tables. One physical host had an outage that resulted in all data being lost on that host. All customers that had tables residing only on that host had data loss. In discussing with customers, it appears that the expectation of most people that aren't deeply familiar with RethinkDB is: \"Well, it's a cluster so it must replicate data, right? Right!\"\r\n\r\nA default of 2 replicas, if there's enough nodes, would be a positive thing IMO."
  , issueCommentId = 171415583
  }