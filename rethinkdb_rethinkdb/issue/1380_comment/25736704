IssueComment
  { issueCommentUpdatedAt = 2013 (-10) (-04) 23 : 24 : 44 UTC
  , issueCommentUser =
      SimpleUser
        { simpleUserId = Id 505365
        , simpleUserLogin = N "danielmewes"
        , simpleUserAvatarUrl =
            "https://avatars.githubusercontent.com/u/505365?v=3"
        , simpleUserUrl = "https://api.github.com/users/danielmewes"
        , simpleUserType = OwnerUser
        }
  , issueCommentUrl =
      "https://api.github.com/repos/rethinkdb/rethinkdb/issues/comments/25736704"
  , issueCommentHtmlUrl =
      "https://github.com/rethinkdb/rethinkdb/issues/1380#issuecomment-25736704"
  , issueCommentCreatedAt = 2013 (-10) (-04) 23 : 24 : 44 UTC
  , issueCommentBody =
      "After the previous crash, I tried to restart the failed node. I could see on the web interface that it resumed the resharding for a few seconds. Then the same node crashed again, but with a different error:\r\n\r\n```\r\nerror: Error in src/buffer_cache/mirrored/mirrored.cc at line 681:\r\nerror: Assertion failed: [inner_buf->version_id <= version_to_access] \r\nerror: Backtrace:\r\nerror: Fri Oct  4 16:20:42 2013\r\n       \r\n       1: rethinkdb_backtrace(void**, int) at thread_stack_pcs.cc:150\r\n       2: lazy_backtrace_t::lazy_backtrace_t() at backtrace.cc:250\r\n       3: format_backtrace(bool) at backtrace.cc:197\r\n       4: report_fatal_error(char const*, int, char const*, ...) at errors.cc:68\r\n       5: mc_buf_lock_t::acquire_block(unsigned long) at mirrored.cc:681\r\n       6: mc_buf_lock_t::initialize(unsigned long, file_account_t*, lock_in_line_callback_t*) at mirrored.cc:594\r\n       7: mc_buf_lock_t::mc_buf_lock_t(mc_transaction_t*, unsigned long, access_t, buffer_cache_order_mode_t, lock_in_line_callback_t*) at mirrored.cc:536\r\n       8: scc_buf_lock_t<mc_cache_t>::scc_buf_lock_t(scc_transaction_t<mc_cache_t>*, unsigned long, access_t, buffer_cache_order_mode_t, lock_in_line_callback_t*) at semantic_checking.tcc:145\r\n       9: scc_buf_lock_t<mc_cache_t>::scc_buf_lock_t(scc_transaction_t<mc_cache_t>*, unsigned long, access_t, buffer_cache_order_mode_t, lock_in_line_callback_t*) at semantic_checking.hpp:154\r\n       10: process_a_leaf_node(traversal_state_t*, scoped_ptr_t<scc_buf_lock_t<mc_cache_t> >*, int, btree_key_t const*, btree_key_t const*) at parallel_traversal.cc:480\r\n       11: do_a_subtree_traversal_fsm_t::on_node_ready(scoped_ptr_t<scc_buf_lock_t<mc_cache_t> >*) at parallel_traversal.cc:412\r\n       12: acquire_a_node_fsm_t::you_may_acquire() at parallel_traversal.cc:274\r\n       13: traversal_state_t::coro_pool_callback(acquisition_waiter_callback_t*, signal_t*) at parallel_traversal.cc:196\r\n       14: coro_pool_t<acquisition_waiter_callback_t*>::worker_run(acquisition_waiter_callback_t*, auto_drainer_t::lock_t) at coro_pool.hpp:69\r\n...\r\n```\r\n\r\nI would also like to point out that the node which crashed was the same all three times. Not sure if that is a co-incidence or something was corrupted in that node's state or alternatively gets corrupted at the point where the crashed node reconnects."
  , issueCommentId = 25736704
  }