IssueComment
  { issueCommentUpdatedAt = 2015 (-09) (-04) 02 : 02 : 12 UTC
  , issueCommentUser =
      SimpleUser
        { simpleUserId = Id 505365
        , simpleUserLogin = N "danielmewes"
        , simpleUserAvatarUrl =
            "https://avatars.githubusercontent.com/u/505365?v=3"
        , simpleUserUrl = "https://api.github.com/users/danielmewes"
        , simpleUserType = OwnerUser
        }
  , issueCommentUrl =
      "https://api.github.com/repos/rethinkdb/rethinkdb/issues/comments/137623196"
  , issueCommentHtmlUrl =
      "https://github.com/rethinkdb/rethinkdb/issues/4569#issuecomment-137623196"
  , issueCommentCreatedAt = 2015 (-09) (-04) 02 : 02 : 12 UTC
  , issueCommentBody =
      "We're currently preparing for the next RethinkDB point release (2.1.3), which will come with an optimized Python driver (#4585, #4782, #4795).\r\nWe've additionally optimized the latency for data-heavy queries like this one on the server side.\r\n\r\nUsing the RethinkDB 2.1.3 code base, switching the datetime object generated by `utc_now()` out for a Unix timestamp, and using UltraJSON in the driver (see https://github.com/rethinkdb/rethinkdb/pull/4585#issuecomment-137621286), I'm now getting the following numbers:\r\n```\r\ncount is 300000\r\nint query took 1645ms\r\n```\r\n\r\n... or about 550ms per 100,000 rows.\r\n"
  , issueCommentId = 137623196
  }