Issue
  { issueClosedAt = Just 2016 (-08) (-17) 23 : 33 : 33 UTC
  , issueUpdatedAt = 2016 (-08) (-17) 23 : 36 : 50 UTC
  , issueEventsUrl =
      "https://api.github.com/repos/rethinkdb/rethinkdb/issues/6060/events"
  , issueHtmlUrl =
      Just "https://github.com/rethinkdb/rethinkdb/issues/6060"
  , issueClosedBy = Nothing
  , issueLabels = []
  , issueNumber = 6060
  , issueAssignee =
      Just
        SimpleUser
          { simpleUserId = Id 7431361
          , simpleUserLogin = N "larkost"
          , simpleUserAvatarUrl =
              "https://avatars.githubusercontent.com/u/7431361?v=3"
          , simpleUserUrl = "https://api.github.com/users/larkost"
          , simpleUserType = OwnerUser
          }
  , issueUser =
      SimpleUser
        { simpleUserId = Id 877936
        , simpleUserLogin = N "marshall007"
        , simpleUserAvatarUrl =
            "https://avatars.githubusercontent.com/u/877936?v=3"
        , simpleUserUrl = "https://api.github.com/users/marshall007"
        , simpleUserType = OwnerUser
        }
  , issueTitle = "Add `--fast` option to `rethinkdb restore`"
  , issuePullRequest = Nothing
  , issueUrl =
      "https://api.github.com/repos/rethinkdb/rethinkdb/issues/6060"
  , issueCreatedAt = 2016 (-08) (-16) 19 : 48 : 00 UTC
  , issueBody =
      Just
        "In cases where you don't care about downtime or are provisioning a brand new cluster, it would be nice to have an option that follows best practices for getting the data restored as quickly as possible. From my experience, this means:\r\n\r\n1. create db and tables with appropriate shard/replica settings\r\n1. restore data with `--no-secondary-indices`\r\n1. restore secondary indices\r\n\r\nDepending on the size of the machine, restoring onto a single shard/replica first and then updating the table config and letting it backfill to other nodes as a second step can sometimes be even faster. Some testing probably needs to be done to verify which is actually faster in the general case or if a heuristic can be applied to determine which method we should use.\r\n\r\nIn the future, I would like to see better throughput overall when restoring, perhaps with a dedicated, lower-level protocol for streaming data in and/or serializing straight to disk. For now, having a flag that at least performs these tasks in the optimal order seems like a good start.\r\n\r\nRegardless, the current behavior of sharding + creating indices up front is definitely the slowest. It would be nice not having to remember all this and micromanage the restore process each time."
  , issueState = "closed"
  , issueId = Id 171501399
  , issueComments = 4
  , issueMilestone =
      Just
        Milestone
          { milestoneCreator =
              SimpleUser
                { simpleUserId = Id 505365
                , simpleUserLogin = N "danielmewes"
                , simpleUserAvatarUrl =
                    "https://avatars.githubusercontent.com/u/505365?v=3"
                , simpleUserUrl = "https://api.github.com/users/danielmewes"
                , simpleUserType = OwnerUser
                }
          , milestoneDueOn = Nothing
          , milestoneOpenIssues = 86
          , milestoneNumber = 123
          , milestoneClosedIssues = 22
          , milestoneDescription = Just ""
          , milestoneTitle = "2.4-polish"
          , milestoneUrl =
              "https://api.github.com/repos/rethinkdb/rethinkdb/milestones/123"
          , milestoneCreatedAt = 2016 (-04) (-28) 19 : 25 : 10 UTC
          , milestoneState = "open"
          }
  }