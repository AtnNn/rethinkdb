IssueComment
  { issueCommentUpdatedAt = 2014 (-06) (-20) 02 : 23 : 01 UTC
  , issueCommentUser =
      SimpleUser
        { simpleUserId = Id 505365
        , simpleUserLogin = N "danielmewes"
        , simpleUserAvatarUrl =
            "https://avatars.githubusercontent.com/u/505365?v=3"
        , simpleUserUrl = "https://api.github.com/users/danielmewes"
        , simpleUserType = OwnerUser
        }
  , issueCommentUrl =
      "https://api.github.com/repos/rethinkdb/rethinkdb/issues/comments/46639029"
  , issueCommentHtmlUrl =
      "https://github.com/rethinkdb/rethinkdb/issues/137#issuecomment-46639029"
  , issueCommentCreatedAt = 2014 (-06) (-20) 02 : 23 : 01 UTC
  , issueCommentBody =
      "I think the advantage of storing chunks explicitly is that we wouldn't have to adapt our backfilling and query code etc. to deal with giant blobs.\r\nA lot of code would have to be adapted if we wanted to be able to \"stream\" blobs.\r\n\r\nPretty sure we shouldn't expose any \"chunk\" table to the user though. I think the chunks should be stored in the same file with the table that references them. We can make the chunks reference-counted if we want to allow the same file to be linked from multiple documents. A chunk couldn't be shared between multiple tables, but I think that would be ok."
  , issueCommentId = 46639029
  }