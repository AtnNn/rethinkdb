IssueComment
  { issueCommentUpdatedAt = 2014 (-06) (-25) 06 : 27 : 54 UTC
  , issueCommentUser =
      SimpleUser
        { simpleUserId = Id 1777134
        , simpleUserLogin = N "mlucy"
        , simpleUserAvatarUrl =
            "https://avatars.githubusercontent.com/u/1777134?v=3"
        , simpleUserUrl = "https://api.github.com/users/mlucy"
        , simpleUserType = OwnerUser
        }
  , issueCommentUrl =
      "https://api.github.com/repos/rethinkdb/rethinkdb/issues/comments/47064715"
  , issueCommentHtmlUrl =
      "https://github.com/rethinkdb/rethinkdb/issues/137#issuecomment-47064715"
  , issueCommentCreatedAt = 2014 (-06) (-25) 06 : 27 : 54 UTC
  , issueCommentBody =
      "So, I've been thinking about this more.\r\n\r\nFirst, the things I think everyone agrees on:\r\n* We should have separate binary data and file pseudotypes.\r\n* When you retrieve an object containing a file, that file pseudotype should turn into a native object that behaves like a file in the language you're using (supporting `seek` etc.)\r\n\r\nApart from that, though, we've sort of gone back and forth between two basic designs:\r\n\r\n#### Every File Lives in an Object\r\n\r\nThis is basically what Karl just described.  You insert a file by inserting an object containing that file.  That object is the only object which has a reference to that file.\r\n\r\nProperties:\r\n* Every file lives in exactly one object.\r\n* Files can be stored in objects in normal tables.  There's no way to list all files, but users can choose to only insert objects containing files into a special table, and reading from that table will be like listing files.\r\n* Files are created by inserting rows and dropped by deleting those rows.\r\n\r\nPros:\r\n* Doesn't involve adding any new ReQL commands, just a new pseudotype.\r\n* Encourages people to always have metadata attached to their files, which is probably a good programming habit.\r\n\r\nCons:\r\n* Changes our assumptions about objects.\r\n  - Can an object which is the sole owner of a 10GB file be copied to another table?  What happens?  Does that table get some sort of reference to the file, or do we copy the whole file?\r\n  - How do you handle an interrupted insert?\r\n    * We need some way to resume uploading a large file -- we can't assume the connection will survive long enough to upload a large file.  Think of people in situations like ours when Comcast was dropping connections every 3 hours.  (This is also why we do secondary index creation asynchronously rather than aborting it if the connection drops.)\r\n    * We either need to not consider the document \"inserted\" until the whole file is uploaded, in which case we need some place to store these zombie objects, or we need to let the object be stored in an incomplete state and let it be completed later.\r\n* Might not match our user's mental model.  It isn't similar to what GridFS does.  Talking to Slava, he seems to think that what people really want is something that feels like it's built on top of RethinkDB, not built-in support for giant blobs of data.\r\n* Possible to lose files.  Are you going to look in every object in every table to figure out where that 100GB file is?\r\n* Ties the sharding scheme used for files very tightly to the sharding scheme used on whatever table you insert the object into.  When we talked about this on Friday, we decided that was fine, but after talking with Slava it sounds like people might want more than that.\r\n\r\n#### Files Are a New Abstraction\r\n\r\nThis approach would treat files more like tables.  We'd add new commands:\r\n* `r.file_create`\r\n* `r.file_drop`\r\n* `r.file_list`\r\n* `r.file_resume`\r\n* `r.file`\r\n\r\nThe example analagous to the one above would be:\r\n```\r\nimageFile = open('inputFile')\r\nr.fileCreate(imageFile, name: 'foo') # `name` is optional, defaults to the name of the file locally\r\nr.table('users').insert({id: 1, image: r.file('foo')})\r\n```\r\n\r\nWhen you retrieved the object with `id` 1, the pseudotype in the `image` field would turn into a native object which supports `seek`, `read`, etc.\r\n\r\nPros:\r\n* Very flexible.\r\n  - Easy to add support for things we haven't thought of, since it's a new abstraction with new `file_` prefixed commands.\r\n  - Easy to imitate the other way of doing things with this one.\r\n  - Gives us more options with respect to distributing and sharding files.  If we decide we want to let people shard individual files, this works well with that.\r\n* Lets you store files in multiple objects in an obvious way.\r\n* We don't need to think about any of our object semantics.\r\n  - Resuming an upload is trivial, and it makes more sense for a file to be in an incomplete state then for an object to be in an incomplete state.\r\n* Easy to manage files.\r\n* Easy to add a frontend for -- the web UI knows where to find all the files.\r\n* Feels the way Slava thinks this feature should feel to people.\r\n\r\nCons:\r\n* Introduces a bunch of new abstractions.\r\n* Feels less tightly integrated with the rest of ReQL.  Feels sort of tacked on.\r\n* Might be slightly more work to implement.\r\n* People can have files with no metadata attached.\r\n  - This makes code harder to audit.  (@srh has more thoughts on this)\r\n\r\n---\r\n\r\nI'm genuinely torn between the two.  After describing them to Slava on Monday, I got the feeling he was leaning strongly toward option 2.  (@coffeemug, could you confirm?)\r\n\r\nThere's also the question with option 2 of whether to use a metadata table and a chunks table, or to not let people shard individual files and just store them in blobs.  That's a whole separate can of worms."
  , issueCommentId = 47064715
  }