IssueComment
  { issueCommentUpdatedAt = 2015 (-06) (-25) 18 : 47 : 49 UTC
  , issueCommentUser =
      SimpleUser
        { simpleUserId = Id 505365
        , simpleUserLogin = N "danielmewes"
        , simpleUserAvatarUrl =
            "https://avatars.githubusercontent.com/u/505365?v=3"
        , simpleUserUrl = "https://api.github.com/users/danielmewes"
        , simpleUserType = OwnerUser
        }
  , issueCommentUrl =
      "https://api.github.com/repos/rethinkdb/rethinkdb/issues/comments/115360131"
  , issueCommentHtmlUrl =
      "https://github.com/rethinkdb/rethinkdb/issues/4451#issuecomment-115360131"
  , issueCommentCreatedAt = 2015 (-06) (-25) 18 : 47 : 49 UTC
  , issueCommentBody =
      "Thanks for the report and pull request (https://github.com/rethinkdb/rethinkdb/pull/4452) @sebadiaz !\r\n\r\nI'm wondering if there's a way to avoid having to set the buffer size manually for large files. I think that isn't very user friendly. Could we adapt it automatically to the file size, or use some different data structure that grows automatically? I don't know much about what that buffer is currently used for in the import script unfortunately.\r\nPinging @Tryneus .\r\n"
  , issueCommentId = 115360131
  }