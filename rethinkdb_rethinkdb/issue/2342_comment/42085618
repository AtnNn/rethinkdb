IssueComment
  { issueCommentUpdatedAt = 2014 (-05) (-02) 22 : 30 : 42 UTC
  , issueCommentUser =
      SimpleUser
        { simpleUserId = Id 258437
        , simpleUserLogin = N "srh"
        , simpleUserAvatarUrl =
            "https://avatars.githubusercontent.com/u/258437?v=3"
        , simpleUserUrl = "https://api.github.com/users/srh"
        , simpleUserType = OwnerUser
        }
  , issueCommentUrl =
      "https://api.github.com/repos/rethinkdb/rethinkdb/issues/comments/42085618"
  , issueCommentHtmlUrl =
      "https://github.com/rethinkdb/rethinkdb/issues/2342#issuecomment-42085618"
  , issueCommentCreatedAt = 2014 (-05) (-02) 22 : 30 : 42 UTC
  , issueCommentBody =
      "> @srh i am guessing that the parser re does its job everytime the client requests the next batch and the parser then sends the full query but some sort of skip back to the nodes?\r\n\r\nNo -- datum streams are cached as long as the client connection is open (unless they time out?) and they send a request to stores asking only for the next data.  They generally store the greatest key or least key that they received from a store and send the next query asking for keys greater than said key.  That's more efficient than doing a skip query (because skip queries are not efficient)."
  , issueCommentId = 42085618
  }