Issue
  { issueClosedAt = Just 2015 (-08) (-18) 23 : 45 : 24 UTC
  , issueUpdatedAt = 2015 (-08) (-27) 16 : 50 : 38 UTC
  , issueEventsUrl =
      "https://api.github.com/repos/rethinkdb/rethinkdb/issues/4710/events"
  , issueHtmlUrl =
      Just "https://github.com/rethinkdb/rethinkdb/issues/4710"
  , issueClosedBy = Nothing
  , issueLabels =
      [ IssueLabel
          { labelColor = "e10c02"
          , labelUrl =
              "https://api.github.com/repos/rethinkdb/rethinkdb/labels/pr:high"
          , labelName = "pr:high"
          }
      , IssueLabel
          { labelColor = "e102d8"
          , labelUrl =
              "https://api.github.com/repos/rethinkdb/rethinkdb/labels/tp:bug"
          , labelName = "tp:bug"
          }
      ]
  , issueNumber = 4710
  , issueAssignee =
      Just
        SimpleUser
          { simpleUserId = Id 552910
          , simpleUserLogin = N "Tryneus"
          , simpleUserAvatarUrl =
              "https://avatars.githubusercontent.com/u/552910?v=3"
          , simpleUserUrl = "https://api.github.com/users/Tryneus"
          , simpleUserType = OwnerUser
          }
  , issueUser =
      SimpleUser
        { simpleUserId = Id 13452583
        , simpleUserLogin = N "vyerukon"
        , simpleUserAvatarUrl =
            "https://avatars.githubusercontent.com/u/13452583?v=3"
        , simpleUserUrl = "https://api.github.com/users/vyerukon"
        , simpleUserType = OwnerUser
        }
  , issueTitle = "Nodes crash problems in version 2.1.1"
  , issuePullRequest = Nothing
  , issueUrl =
      "https://api.github.com/repos/rethinkdb/rethinkdb/issues/4710"
  , issueCreatedAt = 2015 (-08) (-18) 17 : 37 : 41 UTC
  , issueBody =
      Just
        "We have a cluster with 9 nodes across 3 sites and we recently upgraded rethinkdb software to 2.1.1 to overcome the fail-over problem.\n\nHost information: \nuname -a = Linux XXXX 2.6.32-504.1.3.el6.x86_64 #1 SMP Tue Nov 11 07:57:22 PST 2014 x86_64 x86_64 x86_64 GNU/Linux\nSharding configuration: 3 shards vs 7 replicas\n\nAfter upgrade we are now facing the server crash problems in the below mentioned scenarios\n\n1) When the rethink process of primary on first site brought down it crashed the last two nodes of third site with the error as stated below\n\n2) When the rethink process on a primary node of a site is brought down, it gets a node of its sharding cluster to act as primary and when the acting primary node is brought down it crashed 2 nodes of the 3rd site with below error\n\n3) We have a script to restart all nodes one by one and it follows this order in restarting \"Primary->Secondary->Secondary->Primary->Secondary-Secondary->Primary->Secondary->Secondary\", whenever this script is executed each and everytime any of 1 or 2 nodes will crash with below error and its random every time and no specific pattern is observed.\n## Error information:\n\n2015-08-18T10:29:00.238929247 153.246372s error: Error in src/rpc/connectivity/cluster.cc at line 171:\n2015-08-18T10:29:00.239008799 153.246434s error: Guarantee failed: [!send_mutex.is_locked()]\n2015-08-18T10:29:00.239170671 153.246596s error: Backtrace:\n2015-08-18T10:29:00.285774158 153.293212s error: Tue Aug 18 10:29:00 2015\\n\\n1: backtrace_t::backtrace_t() at 0xb0b0e0 (rethinkdb)\\n2: format_backtrace(bool) at 0xb0b440 (rethinkdb)\\n3: report_fatal_error(char const_, int, char const_, ...) at 0xd0f700 (rethinkdb)\\n4: connectivity_cluster_t::connection_t::~connection_t() at 0xa39662 (rethinkdb)\\n5: connectivity_cluster_t::run_t::handle(keepalive_tcp_conn_stream_t_, boost::optional<peer_id_t>, boost::optional<peer_address_t>, auto_drainer_t::lock_t, bool_) at 0xa3bccc (rethinkdb)\\n6: connectivity_cluster_t::run_t::on_new_connection(scoped_ptr_t<linux_tcp_conn_descriptor_t> const&, auto_drainer_t::lock_t) at 0xa3c3a0 (rethinkdb)\\n7: std::_Function_handler<void ()(scoped_ptr_t<linux_tcp_conn_descriptor_t>&), std::_Bind<std::_Mem_fn<void (connectivity_cluster_t::run_t::*)(scoped_ptr_t<linux_tcp_conn_descriptor_t> const&, auto_drainer_t::lock_t)> ()(connectivity_cluster_t::run_t*, std::_Placeholder<1>, auto_drainer_t::lock_t)> >::_M_invoke(std::_Any_data const&, scoped_ptr_t<linux_tcp_conn_descriptor_t>&) at 0xa3d465 (rethinkdb)\\n8: linux_nonthrowing_tcp_listener_t::handle(int) at 0xa1c4fc (rethinkdb)\\n9: coro_t::run() at 0xa33a58 (rethinkdb)\n\nEventually we would see random nodes crashing every time when we perform the tests.\n"
  , issueState = "closed"
  , issueId = Id 101709192
  , issueComments = 6
  , issueMilestone =
      Just
        Milestone
          { milestoneCreator =
              SimpleUser
                { simpleUserId = Id 505365
                , simpleUserLogin = N "danielmewes"
                , simpleUserAvatarUrl =
                    "https://avatars.githubusercontent.com/u/505365?v=3"
                , simpleUserUrl = "https://api.github.com/users/danielmewes"
                , simpleUserType = OwnerUser
                }
          , milestoneDueOn = Nothing
          , milestoneOpenIssues = 0
          , milestoneNumber = 106
          , milestoneClosedIssues = 18
          , milestoneDescription = Just ""
          , milestoneTitle = "2.1.2"
          , milestoneUrl =
              "https://api.github.com/repos/rethinkdb/rethinkdb/milestones/106"
          , milestoneCreatedAt = 2015 (-08) (-21) 22 : 34 : 48 UTC
          , milestoneState = "closed"
          }
  }