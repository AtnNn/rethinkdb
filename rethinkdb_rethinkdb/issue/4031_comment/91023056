IssueComment
  { issueCommentUpdatedAt = 2015 (-04) (-08) 20 : 15 : 10 UTC
  , issueCommentUser =
      SimpleUser
        { simpleUserId = Id 4754399
        , simpleUserLogin = N "bigtree3131"
        , simpleUserAvatarUrl =
            "https://avatars.githubusercontent.com/u/4754399?v=3"
        , simpleUserUrl = "https://api.github.com/users/bigtree3131"
        , simpleUserType = OwnerUser
        }
  , issueCommentUrl =
      "https://api.github.com/repos/rethinkdb/rethinkdb/issues/comments/91023056"
  , issueCommentHtmlUrl =
      "https://github.com/rethinkdb/rethinkdb/issues/4031#issuecomment-91023056"
  , issueCommentCreatedAt = 2015 (-04) (-08) 20 : 15 : 10 UTC
  , issueCommentBody =
      "so for a query like:\r\n\r\nr.table(MY_TABLE).map(lambda x: \r\n{\r\n'NEW_ARR_OF_DOCS: x['ARR_OF_DOCS'].filter(lambda y: \r\n     r.expr(MY_ARRAY_OF_VALS).contains(y['VAL_FIELD'])\r\n)\r\n}\r\n)\r\n\r\nI'd assume the optimal way to execute a query like this would be to create an array once and hash the values so that the complexity is N * M * O(1) as opposed to N * M * O(L) where \r\nr.table(MY_TABLE).count() == N\r\nx['ARR_OF_DOCS'].count() == M\r\nr.expr(MY_ARRAY_OF_VALS).count() == L"
  , issueCommentId = 91023056
  }