IssueComment
  { issueCommentUpdatedAt = 2014 (-10) (-01) 09 : 10 : 03 UTC
  , issueCommentUser =
      SimpleUser
        { simpleUserId = Id 3922707
        , simpleUserLogin = N "datarefinery"
        , simpleUserAvatarUrl =
            "https://avatars.githubusercontent.com/u/3922707?v=3"
        , simpleUserUrl = "https://api.github.com/users/datarefinery"
        , simpleUserType = OwnerUser
        }
  , issueCommentUrl =
      "https://api.github.com/repos/rethinkdb/rethinkdb/issues/comments/57437564"
  , issueCommentHtmlUrl =
      "https://github.com/rethinkdb/rethinkdb/issues/3105#issuecomment-57437564"
  , issueCommentCreatedAt = 2014 (-10) (-01) 09 : 10 : 03 UTC
  , issueCommentBody =
      "@segphault thank you that's helpful - I misunderstood slice to take real id's as ranges opposed to how it seems to work, which is with offsets which indeed is quite helpful..\r\nSadly I'm finding the same linear performance e.g. a slice 100000,101000 takes about a minute whereas a slice 190000,191000 takes 2\r\n\r\nI think its because my docs are quite big and theres so much work to do to get them off disk in either scenario"
  , issueCommentId = 57437564
  }