IssueComment
  { issueCommentUpdatedAt = 2014 (-10) (-26) 05 : 47 : 15 UTC
  , issueCommentUser =
      SimpleUser
        { simpleUserId = Id 505365
        , simpleUserLogin = N "danielmewes"
        , simpleUserAvatarUrl =
            "https://avatars.githubusercontent.com/u/505365?v=3"
        , simpleUserUrl = "https://api.github.com/users/danielmewes"
        , simpleUserType = OwnerUser
        }
  , issueCommentUrl =
      "https://api.github.com/repos/rethinkdb/rethinkdb/issues/comments/60507320"
  , issueCommentHtmlUrl =
      "https://github.com/rethinkdb/rethinkdb/issues/3245#issuecomment-60507320"
  , issueCommentCreatedAt = 2014 (-10) (-26) 05 : 41 : 44 UTC
  , issueCommentBody =
      "___Setup___\r\n* Ubuntu 12.04\r\n* Xeon E3-1245 v3 (3.4 GHz quad core)\r\n* Rotational hard disk (7200 RPM)\r\n* MySQL 5.5 with InnoDB. Configuration: InnoDB buffer pool 4 GB, innodb_flush_log_at_trx_commit=0\r\n* RethinkDB 1.15.1. Configuration: 4 GB cache size\r\n\r\n\r\n\r\n___Strict Schema___\r\nLet's first try a strictly enforced schema with MySQL. This should make storing and processing the rows very efficient for MySQL. RethinkDB as a schema-less database is likely going to have a disadvantage here, but let's see...\r\n\r\n* For MySQL, the table is created as follows:\r\n```\r\nCREATE TABLE t1(id CHAR(13) NOT NULL PRIMARY KEY, name VARCHAR(255), date CHAR(25), f1 DOUBLE, f2 DOUBLE, f3 DOUBLE, slug CHAR(32), INDEX slug_idx(slug)) ENGINE = INNODB\r\n```\r\n* Note that all fields except the `name` have fixed lengths.\r\n* There is a single index on `slug` (@gotlium mentioned a second index, but I don't know what index that was so I skipped it)\r\n* An example document looks like this:\r\n```\r\n{\r\n    \"date\": \"2014-10-25T22:12:31-07:00\" ,\r\n    \"f1\": 3 ,\r\n    \"f2\": 9 ,\r\n    \"f3\": 3 ,\r\n    \"id\": \"544c82bff00f4\" ,\r\n    \"name\": \"544c82bfefd6f\" ,\r\n    \"slug\": \"cfcd208495d565ef66e7dff9f98764da\"\r\n}\r\n```\r\n\r\n__Insert__\r\nI inserted 2 million documents in batches of 600 at a time. Sets of 150 documents each share the same `slug` and `name` value.\r\nFor RethinkDB I used soft durability and noreply.\r\nFor MySQL I set innodb_flush_log_at_trx_commit=0 to get equivalent behavior to RethinkDB soft durability.\r\n\r\n_Queries_\r\nMySQL\r\n```\r\nINSERT INTO t1 VALUES $sqlDocs\r\n```\r\nRethinkDB\r\n```\r\nr\\table(\"t1\")->insert($batch)\r\n```\r\n\r\n_Result_\r\n\r\n```\r\nRunning MySQL insert...\r\nDuration: 281.554356813 s\r\n\r\nRunning RethinkDB insert...\r\nDuration: 262.251695871 s\r\n```\r\n\r\n_Conclusion - Inconclusive_\r\nRethinkDB and MySQL take about the same time for the inserts on rotational drives. Note however that this comparison is not entirely even because MySQL doesn't have an equivalent to the noreply flag.\r\nMySQL also offers a special LOAD DATA INFILE syntax for \"real\" batch loading of a complete data set. I didn't test that because that command has a very different use case.\r\n\r\n\r\n__Group/Sum over the whole table__\r\nThe query was run 10 times (the duration shows the sum of all runs).\r\n\r\n_Queries_\r\nMySQL\r\n```\r\nSELECT SQL_NO_CACHE name, SUM(f1) FROM t1 GROUP BY name\r\n```\r\nRethinkDB\r\n```\r\nr\\table(\"t1\")->group(\"name\")->sum(\"f1\")\r\n```\r\n\r\n_Result_\r\n```\r\nRunning MySQL group...\r\nDuration: 25.7749450207 s\r\n\r\nRunning RethinkDB group...\r\nDuration: 125.764950037 s\r\n```\r\n\r\n_Conclusion - MySQL ~5x faster_\r\nMySQL is faster than RethinkDB by a factor of about 5.\r\n\r\n\r\n__Select 150 documents through a secondary index__\r\nThe query was run 10000 times (the duration shows the sum of all runs).\r\n\r\n_Queries_\r\nMySQL\r\n```\r\nSELECT SQL_NO_CACHE * FROM t1 WHERE slug = '$slug'\r\n```\r\nRethinkDB\r\n```\r\nr\\table(\"t1\")->getAll($slug, array(\"index\" => \"slug\"))\r\n```\r\n\r\n_Result_\r\n```\r\nRunning MySQL select...\r\nDuration: 9.83339381218 s\r\n\r\nRunning RethinkDB select...\r\nDuration: 73.8544569016 s\r\n```\r\n\r\n_Conclusion - MySQL ~7x faster_\r\nMySQL is faster than RethinkDB by a factor of about 7. Checking RethinkDB's query profile shows that the vast majority of the time is needed not for computing the results, but for transferring the query results to the client. It's possible that the JSON encoding/decoding that we use in our wire protocol is responsible for this (in contrast to MySQL's binary protocol). However this needs further investigation.\r\n\r\n\r\n__Select 150 documents and group+sum them__\r\nThe query was run 10000 times (the duration shows the sum of all runs).\r\n\r\n_Queries_\r\nMySQL\r\n```\r\nSELECT SQL_NO_CACHE name, SUM(f1) FROM t1 WHERE slug = '$slug' GROUP BY name\r\n```\r\nRethinkDB\r\n```\r\nr\\table(\"t1\")->getAll($slug, array(\"index\" => \"slug\"))->group(\"name\")->sum(\"f1\")\r\n```\r\n\r\n_Result_\r\n```\r\nRunning MySQL select group...\r\nDuration: 2.53938603401 s\r\n\r\nRunning RethinkDB select group...\r\nDuration: 11.6621789932 s\r\n```\r\n\r\n_Conclusion - MySQL ~5x faster_\r\nMySQL is faster than RethinkDB by a factor of about 5.\r\n\r\n\r\n\r\n\r\n\r\n___Slightly Weaker Schema___\r\nOne big difference between MySQL and RethinkDB is that RethinkDB is schemaless. This can be a disadvantage in cases where the schema is actually fixed, but gives you a lot more flexibility and often more performance if it isn't.\r\nIt's not really possible to emulate the same degree of freedom in MySQL. As a minor move towards a less restrictive schema, I changed all text fields to be variably sized in MySQL. Note that this is still a lot more restrictive than what RethinkDB operates on (where you can have a different number of fields in each document, they can be of different types, can be nested etc...).\r\n\r\n* For MySQL, the table is created as follows:\r\n```\r\nCREATE TABLE t1(id CHAR(13) NOT NULL PRIMARY KEY, name TEXT, date TEXT, f1 DOUBLE, f2 DOUBLE, f3 DOUBLE, slug TEXT, INDEX slug_idx(slug(255))) ENGINE = INNODB\r\n```\r\n\r\n\r\n__Insert__\r\nMySQL\r\n```\r\nINSERT INTO t1 VALUES $sqlDocs\r\n```\r\nRethinkDB\r\n```\r\nr\\table(\"t1\")->insert($batch)\r\n```\r\n\r\n_Result_\r\n\r\n```\r\nRunning MySQL insert...\r\nDuration: 284.870942116 s\r\n\r\nRunning RethinkDB insert...\r\nDuration: 265.842845201 s\r\n```\r\n\r\n_Conclusion - Inconclusive_\r\nThere's no significant difference in insert performance compared to the stricter schema above.\r\n\r\n\r\n\r\n__Group/Sum over the whole table__\r\nThe query was run 10 times (the duration shows the sum of all runs).\r\n\r\n_Queries_\r\nMySQL\r\n```\r\nSELECT SQL_NO_CACHE name, SUM(f1) FROM t1 GROUP BY name\r\n```\r\nRethinkDB\r\n```\r\nr\\table(\"t1\")->group(\"name\")->sum(\"f1\")\r\n```\r\n\r\n_Result_\r\n```\r\nRunning MySQL group...\r\nDuration: 419.434604883 s\r\n\r\nRunning RethinkDB group...\r\nDuration: 131.422641039 s\r\n```\r\n\r\n_Conclusion - RethinkDB ~3x faster_\r\nWith variably sized text fields, RethinkDB is significantly faster for this simple analytical query. In fact MySQL became slower by a factor of 16x just by making the schema slightly more flexible.\r\n\r\n__Select 150 documents through a secondary index__\r\nThe query was run 10000 times (the duration shows the sum of all runs).\r\n\r\n_Queries_\r\n```\r\nSELECT SQL_NO_CACHE * FROM t1 WHERE slug = '$slug'\r\n```\r\nRethinkDB\r\n```\r\nr\\table(\"t1\")->getAll($slug, array(\"index\" => \"slug\"))\r\n```\r\n\r\n_Result_\r\n```\r\nRunning MySQL select...\r\nDuration: 11.1877129078 s\r\n\r\nRunning RethinkDB select...\r\nDuration: 71.2674908638 s\r\n```\r\n\r\n_Conclusion - MySQL ~6x faster_\r\nThere isn't that much change here. MySQL is still significantly faster than RethinkDB. The same remarks regarding transferring the result set as above apply.\r\n\r\n\r\n__Select 150 documents and group+sum them__\r\nThe query was run 10000 times (the duration shows the sum of all runs).\r\n\r\n_Queries_\r\nMySQL\r\n```\r\nSELECT SQL_NO_CACHE name, SUM(f1) FROM t1 WHERE slug = '$slug' GROUP BY name\r\n```\r\nRethinkDB\r\n```\r\nr\\table(\"t1\")->getAll($slug, array(\"index\" => \"slug\"))->group(\"name\")->sum(\"f1\")\r\n```\r\n\r\n_Result_\r\n```\r\nRunning MySQL select group...\r\nDuration: 14.0788550377 s\r\n\r\nRunning RethinkDB select group...\r\nDuration: 11.6054229736 s\r\n```\r\n\r\n_Conclusion - ~Even_\r\nHere we get another indication that InnoDB doesn't like variable length text columns very much. While MySQL was significantly faster than RethinkDB with the highly restricted schema above, the difference between the DBMSs is now small.\r\n\r\n\r\n\r\n\r\n___Overall Conclusion___\r\nThis test shows that if you can structure your data into a conservative schema of fixed-size data and don't need the option of easy and highly scalable sharding, replication and concurrency, you might get significantly more performance out of a traditional relational database.\r\n\r\nIf on the other hand your data does not fit well into a traditional schema, you might find a schemaless system like RethinkDB giving you better performance for many queries. You also gain a lot of flexibility, many unique features (e.g. our change feeds), super easy and performant clustering, and not least the great expressiveness, joy and power of ReQL.\r\n\r\nObviously results will differ significantly for different workloads, different document structures, different hardware etc...\r\n\r\nIt's also possible that I missed some opportunities for parameter tuning and such. Please leave a comment if something comes to your mind.\r\n\r\nAll this being said, we definitely have a number of things left to investigate and optimize in RethinkDB. There are a couple of queries that are still clearly slower than we would like them to be (e.g. the `getAll()` query fetching 150 documents).\r\n\r\n\r\n\r\n___Download___\r\nYou can run this yourself on your hardware. The test scripts are written in PHP, and require the PHP-RQL driver for RethinkDB http://php-rql.dnsalias.net/ and the MySQL-ND driver for MySQL (Ubuntu package php5-mysqlnd).\r\n\r\nThe test scripts and my.cnf file used can be downloaded here: http://dmewes.com/~daniel/rdb-mysql-bench.zip"
  , issueCommentId = 60507320
  }