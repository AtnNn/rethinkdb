IssueComment
  { issueCommentUpdatedAt = 2016 (-07) (-15) 04 : 06 : 05 UTC
  , issueCommentUser =
      SimpleUser
        { simpleUserId = Id 505365
        , simpleUserLogin = N "danielmewes"
        , simpleUserAvatarUrl =
            "https://avatars.githubusercontent.com/u/505365?v=3"
        , simpleUserUrl = "https://api.github.com/users/danielmewes"
        , simpleUserType = OwnerUser
        }
  , issueCommentUrl =
      "https://api.github.com/repos/rethinkdb/rethinkdb/issues/comments/232855208"
  , issueCommentHtmlUrl =
      "https://github.com/rethinkdb/rethinkdb/issues/5949#issuecomment-232855208"
  , issueCommentCreatedAt = 2016 (-07) (-15) 04 : 05 : 45 UTC
  , issueCommentBody =
      "@Calavoow you can already pass an array to `getAll`, but you have to use the special `r.args` command:\r\n```js\r\n.getAll(r.args(ids))\r\n```\r\n\r\nThe explicit `r.args` avoids the ambiguity with index values that are arrays.\r\n\r\nThat being said, I would not recommend passing 100k IDs into a `getAll` (or any ReQL command) at once. The ReQL implementation was designed with terms receiving only a handful of arguments (maybe 100s) in mind, and I have no idea how it behaves for 100k arguments. It might stall the server for a moment, generate high latencies for other concurrent queries,  or require a lot of RAM.\r\n\r\nIt would be better to split the IDs up into batches of maybe 100-1000 or so on the client-side, and then issuing one such `getAll.update(...)` at a time."
  , issueCommentId = 232855208
  }