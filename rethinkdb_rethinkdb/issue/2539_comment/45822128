IssueComment
  { issueCommentUpdatedAt = 2014 (-06) (-12) 01 : 58 : 00 UTC
  , issueCommentUser =
      SimpleUser
        { simpleUserId = Id 505365
        , simpleUserLogin = N "danielmewes"
        , simpleUserAvatarUrl =
            "https://avatars.githubusercontent.com/u/505365?v=3"
        , simpleUserUrl = "https://api.github.com/users/danielmewes"
        , simpleUserType = OwnerUser
        }
  , issueCommentUrl =
      "https://api.github.com/repos/rethinkdb/rethinkdb/issues/comments/45822128"
  , issueCommentHtmlUrl =
      "https://github.com/rethinkdb/rethinkdb/issues/2539#issuecomment-45822128"
  , issueCommentCreatedAt = 2014 (-06) (-12) 01 : 58 : 00 UTC
  , issueCommentBody =
      "Arrr this is not really a bug it turns out.\r\n\r\nI was using batched inserts of 100 documents per batch.\r\nWith a single range shard, the batch is divided into 8 sub-batches of ~12 documents each for the different hash shards.\r\nIncreasing the number of range shards makes the batches per shard smaller and smaller, until they become essentially single document inserts.\r\nAt the same time the overhead for sending out all the cluster messages increases.\r\n\r\nIncreasing the batch size makes the performance with more shards much more reasonable.\r\n\r\n@coffeemug I think what you mean is for range reads. Which would also be something worth investigating..."
  , issueCommentId = 45822128
  }