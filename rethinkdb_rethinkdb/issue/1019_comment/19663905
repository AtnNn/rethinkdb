IssueComment
  { issueCommentUpdatedAt = 2013 (-06) (-19) 05 : 32 : 54 UTC
  , issueCommentUser =
      SimpleUser
        { simpleUserId = Id 48436
        , simpleUserLogin = N "coffeemug"
        , simpleUserAvatarUrl =
            "https://avatars.githubusercontent.com/u/48436?v=3"
        , simpleUserUrl = "https://api.github.com/users/coffeemug"
        , simpleUserType = OwnerUser
        }
  , issueCommentUrl =
      "https://api.github.com/repos/rethinkdb/rethinkdb/issues/comments/19663905"
  , issueCommentHtmlUrl =
      "https://github.com/rethinkdb/rethinkdb/issues/1019#issuecomment-19663905"
  , issueCommentCreatedAt = 2013 (-06) (-19) 05 : 32 : 09 UTC
  , issueCommentBody =
      "> what happens, if write requests count is more than the max number of the write req. that one master can handle ?\r\n\r\nIn most cases you can shard the table and add more masters. The issue you bring up becomes problematic when you approach a case where a single row (say, a really popular counter) has so many updates that a single machine can no longer handle it. At this level of scale RethinkDB isn't the product for you, but I think this really becomes a theoretical problem. I don't think that any off the shelf NoSQL system can handle that well (even dynamo-based masterless systems like cassandra will crumble in this case because of write conflict resolution algorithms). So at this point, you'd probably need to roll your own custom solution, but I think very, very few (if any) businesses ever reach such incredible levels of scale.\r\n\r\n> is the statement below valid also for write reqs. or just for read reqs\r\n\r\nThe statement applies to both reads and writes."
  , issueCommentId = 19663905
  }