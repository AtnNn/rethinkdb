IssueComment
  { issueCommentUpdatedAt = 2014 (-07) (-23) 22 : 46 : 55 UTC
  , issueCommentUser =
      SimpleUser
        { simpleUserId = Id 232327
        , simpleUserLogin = N "colegleason"
        , simpleUserAvatarUrl =
            "https://avatars.githubusercontent.com/u/232327?v=3"
        , simpleUserUrl = "https://api.github.com/users/colegleason"
        , simpleUserType = OwnerUser
        }
  , issueCommentUrl =
      "https://api.github.com/repos/rethinkdb/rethinkdb/issues/comments/49946600"
  , issueCommentHtmlUrl =
      "https://github.com/rethinkdb/rethinkdb/issues/2738#issuecomment-49946600"
  , issueCommentCreatedAt = 2014 (-07) (-23) 22 : 46 : 20 UTC
  , issueCommentBody =
      "I'm trying to find a solution that involves as little production downtime as possible. Since it seems like there is a node with a problem `rethinkdb_data` directory, I'm planning to just blow that away and bring up a new node. It should then backfill the replicas from the other nodes.\r\n\r\nDoes that sound reasonable to get rid of the metadata corruption?\r\n\r\nAlternatively @timmaxw, if I email the metadata files to you, will I be able to change those in a running rethinkdb cluster? Should I be worried about changes to that file after I send it off to you? Additionally, do those files contain any sort of sensitive data?"
  , issueCommentId = 49946600
  }