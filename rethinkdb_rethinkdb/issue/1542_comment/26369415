IssueComment
  { issueCommentUpdatedAt = 2013 (-10) (-15) 20 : 30 : 12 UTC
  , issueCommentUser =
      SimpleUser
        { simpleUserId = Id 43867
        , simpleUserLogin = N "jdoliner"
        , simpleUserAvatarUrl =
            "https://avatars.githubusercontent.com/u/43867?v=3"
        , simpleUserUrl = "https://api.github.com/users/jdoliner"
        , simpleUserType = OwnerUser
        }
  , issueCommentUrl =
      "https://api.github.com/repos/rethinkdb/rethinkdb/issues/comments/26369415"
  , issueCommentHtmlUrl =
      "https://github.com/rethinkdb/rethinkdb/issues/1542#issuecomment-26369415"
  , issueCommentCreatedAt = 2013 (-10) (-15) 20 : 30 : 12 UTC
  , issueCommentBody =
      "@wojons That would actually be a substantial downgrade in performance. Right now we compute filter values lazily so you start getting data back immediately and as the user requests more data only then do we actually read it off disk and apply the filter function. If we did them all in parallel from the get go we'd have to store the results in memory until they were actually needed. Which is untenable due to memory requirements, but also just generally slower."
  , issueCommentId = 26369415
  }