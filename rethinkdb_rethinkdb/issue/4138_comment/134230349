IssueComment
  { issueCommentUpdatedAt = 2015 (-08) (-24) 14 : 45 : 33 UTC
  , issueCommentUser =
      SimpleUser
        { simpleUserId = Id 3797598
        , simpleUserLogin = N "CezarCretu"
        , simpleUserAvatarUrl =
            "https://avatars.githubusercontent.com/u/3797598?v=3"
        , simpleUserUrl = "https://api.github.com/users/CezarCretu"
        , simpleUserType = OwnerUser
        }
  , issueCommentUrl =
      "https://api.github.com/repos/rethinkdb/rethinkdb/issues/comments/134230349"
  , issueCommentHtmlUrl =
      "https://github.com/rethinkdb/rethinkdb/issues/4138#issuecomment-134230349"
  , issueCommentCreatedAt = 2015 (-08) (-24) 14 : 44 : 43 UTC
  , issueCommentBody =
      "I've run into this today, was advised on IRC to share my use case as it might be relevant.\r\n\r\nMy schema, relevant bits: ```{hash, timestamp}```\r\n\r\nI was trying to get the first x unique items (by hash), ordered by timestamp.\r\n Since both ```orderBy(index)``` and ```distinct(index)``` require ```table```, I was left with something like this:\r\n```orderby(index)('hash').distinct().limit(x)``` which is terribly inefficient for most data sets since at the moment it reads the whole table (300k documents vs ~x*5 documents in my  case).\r\n\r\nThe workaround suggested to me (might be of use to others) was to handle ```.distinct().limit()``` client-side, which is viable if I stream elements one-by-one straight from the orderBy, but far less than ideal."
  , issueCommentId = 134230349
  }