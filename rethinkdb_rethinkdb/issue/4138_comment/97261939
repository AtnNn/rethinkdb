IssueComment
  { issueCommentUpdatedAt = 2015 (-04) (-28) 23 : 24 : 56 UTC
  , issueCommentUser =
      SimpleUser
        { simpleUserId = Id 505365
        , simpleUserLogin = N "danielmewes"
        , simpleUserAvatarUrl =
            "https://avatars.githubusercontent.com/u/505365?v=3"
        , simpleUserUrl = "https://api.github.com/users/danielmewes"
        , simpleUserType = OwnerUser
        }
  , issueCommentUrl =
      "https://api.github.com/repos/rethinkdb/rethinkdb/issues/comments/97261939"
  , issueCommentHtmlUrl =
      "https://github.com/rethinkdb/rethinkdb/issues/4138#issuecomment-97261939"
  , issueCommentCreatedAt = 2015 (-04) (-28) 23 : 24 : 56 UTC
  , issueCommentBody =
      "Note that `getIntersecting` is already doing something similar for deduplicating results (it keeps a list of primary keys, and fails if that list grows over the array size limit).\r\n\r\nI think this change would be a pretty clear improvement from a technical perspective, and we should just make sure sure to document things accordingly.\r\n\r\nWe nowhere document that the array vs. stream distinction says something about performance characteristics either as far as I know. I think explicitly stating the performance characteristics of a given term in the API docs is strictly better than relying on this implicit notion."
  , issueCommentId = 97261939
  }