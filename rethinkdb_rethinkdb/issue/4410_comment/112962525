IssueComment
  { issueCommentUpdatedAt = 2015 (-06) (-17) 21 : 57 : 12 UTC
  , issueCommentUser =
      SimpleUser
        { simpleUserId = Id 505365
        , simpleUserLogin = N "danielmewes"
        , simpleUserAvatarUrl =
            "https://avatars.githubusercontent.com/u/505365?v=3"
        , simpleUserUrl = "https://api.github.com/users/danielmewes"
        , simpleUserType = OwnerUser
        }
  , issueCommentUrl =
      "https://api.github.com/repos/rethinkdb/rethinkdb/issues/comments/112962525"
  , issueCommentHtmlUrl =
      "https://github.com/rethinkdb/rethinkdb/issues/4410#issuecomment-112962525"
  , issueCommentCreatedAt = 2015 (-06) (-17) 21 : 57 : 12 UTC
  , issueCommentBody =
      "I can see the use case but I feel like there should be a cleaner solution to this problem.\r\n\r\n@marshall007 Have you tried this alternative query?\r\n```\r\nr.expr([doc1, doc2, doc3, ...]).forEach(table.get(r.row('id')).update(r.row, {durability: \"soft\"}))\r\ntable.sync() // Only run this if you need hard durability\r\n```\r\nDoes it run a lot slower than the batch insert?\r\n\r\nMaybe another option is to parallelize `forEach` (see https://github.com/rethinkdb/rethinkdb/issues/3804)."
  , issueCommentId = 112962525
  }