IssueComment
  { issueCommentUpdatedAt = 2016 (-06) (-01) 23 : 33 : 37 UTC
  , issueCommentUser =
      SimpleUser
        { simpleUserId = Id 505365
        , simpleUserLogin = N "danielmewes"
        , simpleUserAvatarUrl =
            "https://avatars.githubusercontent.com/u/505365?v=3"
        , simpleUserUrl = "https://api.github.com/users/danielmewes"
        , simpleUserType = OwnerUser
        }
  , issueCommentUrl =
      "https://api.github.com/repos/rethinkdb/rethinkdb/issues/comments/223155827"
  , issueCommentHtmlUrl =
      "https://github.com/rethinkdb/rethinkdb/issues/5815#issuecomment-223155827"
  , issueCommentCreatedAt = 2016 (-06) (-01) 23 : 33 : 37 UTC
  , issueCommentBody =
      "I wonder if we should change `accumulate_all` to use a batchspec that's not time restricted, but is still size restricted.\r\n\r\nEven for reads below the array size limit, reading huge chunks of data from a shard can be an issue because it hogs the network connection over a relatively long period, which impacts the latency of other queries."
  , issueCommentId = 223155827
  }