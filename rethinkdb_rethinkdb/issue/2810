Issue
  { issueClosedAt = Just 2014 (-08) (-06) 20 : 10 : 19 UTC
  , issueUpdatedAt = 2014 (-08) (-08) 23 : 03 : 55 UTC
  , issueEventsUrl =
      "https://api.github.com/repos/rethinkdb/rethinkdb/issues/2810/events"
  , issueHtmlUrl =
      Just "https://github.com/rethinkdb/rethinkdb/issues/2810"
  , issueClosedBy = Nothing
  , issueLabels =
      [ IssueLabel
          { labelColor = "e102d8"
          , labelUrl =
              "https://api.github.com/repos/rethinkdb/rethinkdb/labels/tp:bug"
          , labelName = "tp:bug"
          }
      ]
  , issueNumber = 2810
  , issueAssignee =
      Just
        SimpleUser
          { simpleUserId = Id 316661
          , simpleUserLogin = N "timmaxw"
          , simpleUserAvatarUrl =
              "https://avatars.githubusercontent.com/u/316661?v=3"
          , simpleUserUrl = "https://api.github.com/users/timmaxw"
          , simpleUserType = OwnerUser
          }
  , issueUser =
      SimpleUser
        { simpleUserId = Id 505365
        , simpleUserLogin = N "danielmewes"
        , simpleUserAvatarUrl =
            "https://avatars.githubusercontent.com/u/505365?v=3"
        , simpleUserUrl = "https://api.github.com/users/danielmewes"
        , simpleUserType = OwnerUser
        }
  , issueTitle =
      "\"Guarantee failed: [connection != __null] \" (auto_reconnect.cc)"
  , issuePullRequest = Nothing
  , issueUrl =
      "https://api.github.com/repos/rethinkdb/rethinkdb/issues/2810"
  , issueCreatedAt = 2014 (-08) (-04) 21 : 37 : 30 UTC
  , issueBody =
      Just
        "I got this once while running `test/run -j 8 -r 9 split_workloads.rebalance-2-multi-serial-mix` on next with the following small changes applied to work around other issues with this test (see below).\n\n```\ninfo: Running rethinkdb foo (debug) (CLANG 3.2 (tags/RELEASE_32/final))...\ninfo: Running on Linux 3.2.0-61-generic x86_64\ninfo: Using cache size of 9810 MB\ninfo: Loading data from directory /home/ssd3/daniel/rethinkdb/test/results/2014-08-04T14:21:12.QyxdDE/split_workloads.rebalance-2-multi-serial-mix.4/db-0\ninfo: Our machine ID is a0ce8bd7-57bf-490d-b96e-adfc61d26137\ninfo: Listening for intracluster connections on port 48105\ninfo: Listening for client driver connections on port 50486\ninfo: Listening for administrative HTTP connections on port 48628\ninfo: Listening on addresses: 127.0.0.1, 127.0.1.1, 10.0.3.1, 192.168.122.1, 192.168.0.7, 192.168.1.7, ::1, fe80::225:90ff:fe0d:8e8a%2, fe80::225:90ff:fe0d:8e8b%3, fe80::d423:feff:fe15:2cff%4\ninfo: Server ready\ninfo: Connected to server \"node_1\" da56d3e9-7470-48a4-83e6-ca67ec27fd98\ninfo: Connected to server \"node_2\" 789124d2-66ca-4b3d-ac88-291c268a49c2\ninfo: Applying data {\"datacenters\":{\"new\":{\"name\":\"517543\"}}}\nerror: Heartbeat timeout, killing connection to peer ::ffff:127.0.0.1\ninfo: Disconnected from server \"node_1\" da56d3e9-7470-48a4-83e6-ca67ec27fd98\ninfo: Connected to server \"node_1\" da56d3e9-7470-48a4-83e6-ca67ec27fd98\ninfo: Disconnected from server \"node_1\" da56d3e9-7470-48a4-83e6-ca67ec27fd98\nerror: Heartbeat timeout, killing connection to peer ::ffff:127.0.0.1\nerror: Heartbeat timeout, killing connection to peer ::ffff:127.0.0.1\ninfo: Disconnected from server \"node_2\" 789124d2-66ca-4b3d-ac88-291c268a49c2\ninfo: Server got SIGINT from pid 24344, uid 1014; shutting down...\ninfo: Shutting down client connections...\ninfo: All client connections closed.\ninfo: Shutting down storage engine... (This may take a while if you had a lot of unflushed data in the writeback cache.)\nVersion: rethinkdb foo (debug) (CLANG 3.2 (tags/RELEASE_32/final))\nerror: Error in src/clustering/administration/auto_reconnect.cc at line 33:\nerror: Guarantee failed: [connection != __null] \nerror: Backtrace:\nerror: Mon Aug  4 14:25:23 2014\n\n       1: rethinkdb_backtrace(void**, int) at rethinkdb_backtrace.cc:100\n       2: backtrace_t::backtrace_t() at backtrace.cc:203\n       3: lazy_backtrace_formatter_t::lazy_backtrace_formatter_t() at backtrace.cc:283\n       4: format_backtrace(bool) at backtrace.cc:198\n       5: report_fatal_error(char const*, int, char const*, ...) at errors.cc:83\n       6: auto_reconnector_t::on_connect_or_disconnect() at auto_reconnect.cc:33\n       7: boost::_mfi::mf0<void, auto_reconnector_t>::operator()(auto_reconnector_t*) const at mem_fn_template.hpp:49\n       8: void boost::_bi::list1<boost::_bi::value<auto_reconnector_t*> >::operator()<boost::_mfi::mf0<void, auto_reconnector_t>, boost::_bi::list0>(boost::_bi::type<void>, boost::_mfi::mf0<void, auto_reconnector_t>&, boost::_bi::list0&, int) at bind.hpp:254\n       9: boost::_bi::bind_t<void, boost::_mfi::mf0<void, auto_reconnector_t>, boost::_bi::list1<boost::_bi::value<auto_reconnector_t*> > >::operator()() at bind_template.hpp:20\n       10: std::_Function_handler<void (), boost::_bi::bind_t<void, boost::_mfi::mf0<void, auto_reconnector_t>, boost::_bi::list1<boost::_bi::value<auto_reconnector_t*> > > >::_M_invoke(std::_Any_data const&) at functional:1779\n       11: std::function<void ()>::operator()() const at functional:2160\n       12: call_function(std::function<void ()> const&) at watchable.hpp:167\n       13: void publisher_controller_t<std::function<void ()> >::publish<void (*)(std::function<void ()> const&)>(void (* const&)(std::function<void ()> const&)) at pubsub.hpp:139\n       14: subview_watchable_t<change_tracking_map_t<peer_id_t, uuid_u>, change_tracking_map_t<peer_id_t, cluster_directory_metadata_t>, incremental_field_getter_t<uuid_u, cluster_directory_metadata_t> >::lensed_value_cache_t::on_parent_changed() at watchable.tcc:106\n       15: std::_Mem_fn<void (subview_watchable_t<change_tracking_map_t<peer_id_t, uuid_u>, change_tracking_map_t<peer_id_t, cluster_directory_metadata_t>, incremental_field_getter_t<uuid_u, cluster_directory_metadata_t> >::lensed_value_cache_t::*)()>::operator()(subview_watchable_t<change_tracking_map_t<peer_id_t, uuid_u>, change_tracking_map_t<peer_id_t, cluster_directory_metadata_t>, incremental_field_getter_t<uuid_u, cluster_directory_metadata_t> >::lensed_value_cache_t*) const at functional:550\n       16: _ZNSt5_BindIFSt7_Mem_fnIMN19subview_watchable_tI21change_tracking_map_tI9peer_id_t6uuid_uES2_IS3_28cluster_directory_metadata_tE26incremental_field_getter_tIS4_S6_EE20lensed_value_cache_tEFvvEEPSB_EE6__callIvJEJLi0EEEET_OSt5tupleIJDpT0_EESt12_Index_tupleIJXspT1_EEE+0x43 at functional:1145\n       17: _ZNSt5_BindIFSt7_Mem_fnIMN19subview_watchable_tI21change_tracking_map_tI9peer_id_t6uuid_uES2_IS3_28cluster_directory_metadata_tE26incremental_field_getter_tIS4_S6_EE20lensed_value_cache_tEFvvEEPSB_EEclIJEvEET0_DpOT_+0x26 at functional:1203\n       18: std::_Function_handler<void (), std::_Bind<std::_Mem_fn<void (subview_watchable_t<change_tracking_map_t<peer_id_t, uuid_u>, change_tracking_map_t<peer_id_t, cluster_directory_metadata_t>, incremental_field_getter_t<uuid_u, cluster_directory_metadata_t> >::lensed_value_cache_t::*)()> (subview_watchable_t<change_tracking_map_t<peer_id_t, uuid_u>, change_tracking_map_t<peer_id_t, cluster_directory_metadata_t>, incremental_field_getter_t<uuid_u, cluster_directory_metadata_t> >::lensed_value_cache_t*)> >::_M_invoke(std::_Any_data const&) at functional:1779\n       19: std::function<void ()>::operator()() const at functional:2160\n       20: call_function(std::function<void ()> const&) at watchable.hpp:167\n       21: void publisher_controller_t<std::function<void ()> >::publish<void (*)(std::function<void ()> const&)>(void (* const&)(std::function<void ()> const&)) at pubsub.hpp:139\n       22: watchable_variable_t<change_tracking_map_t<peer_id_t, cluster_directory_metadata_t> >::apply_atomic_op(std::function<bool (change_tracking_map_t<peer_id_t, cluster_directory_metadata_t>*)> const&) at watchable.hpp:197\n       23: directory_read_manager_t<cluster_directory_metadata_t>::handle_connection(connectivity_cluster_t::connection_t*, auto_drainer_t::lock_t, boost::shared_ptr<cluster_directory_metadata_t> const&, fifo_enforcer_state_t, auto_drainer_t::lock_t) at read_manager.tcc:119\n       24: std::_Mem_fn<void (directory_read_manager_t<cluster_directory_metadata_t>::*)(connectivity_cluster_t::connection_t*, auto_drainer_t::lock_t, boost::shared_ptr<cluster_directory_metadata_t> const&, fifo_enforcer_state_t, auto_drainer_t::lock_t)>::operator()(directory_read_manager_t<cluster_directory_metadata_t>*, connectivity_cluster_t::connection_t*, auto_drainer_t::lock_t, boost::shared_ptr<cluster_directory_metadata_t> const&, fifo_enforcer_state_t, auto_drainer_t::lock_t) const at functional:550\n       25: _ZNSt5_BindIFSt7_Mem_fnIM24directory_read_manager_tI28cluster_directory_metadata_tEFvPN22connectivity_cluster_t12connection_tEN14auto_drainer_t6lock_tERKN5boost10shared_ptrIS2_EE21fifo_enforcer_state_tS8_EEPS3_S6_S8_SB_SE_S8_EE6__callIvJEJLi0ELi1ELi2ELi3ELi4ELi5EEEET_OSt5tupleIJDpT0_EESt12_Index_tupleIJXspT1_EEE+0x1b7 at functional:1145\n       26: _ZNSt5_BindIFSt7_Mem_fnIM24directory_read_manager_tI28cluster_directory_metadata_tEFvPN22connectivity_cluster_t12connection_tEN14auto_drainer_t6lock_tERKN5boost10shared_ptrIS2_EE21fifo_enforcer_state_tS8_EEPS3_S6_S8_SB_SE_S8_EEclIJEvEET0_DpOT_+0x26 at functional:1203\n       27: callable_action_instance_t<std::_Bind<std::_Mem_fn<void (directory_read_manager_t<cluster_directory_metadata_t>::*)(connectivity_cluster_t::connection_t*, auto_drainer_t::lock_t, boost::shared_ptr<cluster_directory_metadata_t> const&, fifo_enforcer_state_t, auto_drainer_t::lock_t)> (directory_read_manager_t<cluster_directory_metadata_t>*, connectivity_cluster_t::connection_t*, auto_drainer_t::lock_t, boost::shared_ptr<cluster_directory_metadata_t>, fifo_enforcer_state_t, auto_drainer_t::lock_t)> >::run_action() at callable_action.hpp:28\n       28: callable_action_wrapper_t::run() at runtime_utils.cc:43\n       29: coro_t::run() at coroutines.cc:197\n       30: coro_t* coro_t::spawn_sometime<std::_Bind<std::_Mem_fn<void (directory_read_manager_t<cluster_directory_metadata_t>::*)(connectivity_cluster_t::connection_t*, auto_drainer_t::lock_t, boost::shared_ptr<cluster_directory_metadata_t> const&, fifo_enforcer_state_t, auto_drainer_t::lock_t)> (directory_read_manager_t<cluster_directory_metadata_t>*, connectivity_cluster_t::connection_t*, auto_drainer_t::lock_t, boost::shared_ptr<cluster_directory_metadata_t>, fifo_enforcer_state_t, auto_drainer_t::lock_t)> >(std::_Bind<std::_Mem_fn<void (directory_read_manager_t<cluster_directory_metadata_t>::*)(connectivity_cluster_t::connection_t*, auto_drainer_t::lock_t, boost::shared_ptr<cluster_directory_metadata_t> const&, fifo_enforcer_state_t, auto_drainer_t::lock_t)> (directory_read_manager_t<cluster_directory_metadata_t>*, connectivity_cluster_t::connection_t*, auto_drainer_t::lock_t, boost::shared_ptr<cluster_directory_metadata_t>, fifo_enforcer_state_t, auto_drainer_t::lock_t)> const&) at coroutines.hpp:58\n       31: directory_read_manager_t<cluster_directory_metadata_t>::on_message(connectivity_cluster_t::connection_t*, auto_drainer_t::lock_t, read_stream_t*) at read_manager.tcc:69\n       32: connectivity_cluster_t::run_t::handle(keepalive_tcp_conn_stream_t*, boost::optional<peer_id_t>, boost::optional<peer_address_t>, auto_drainer_t::lock_t, bool*) at cluster.cc:1107\n       33: connectivity_cluster_t::run_t::on_new_connection(scoped_ptr_t<linux_tcp_conn_descriptor_t> const&, auto_drainer_t::lock_t) at cluster.cc:286\n       34: std::_Mem_fn<void (connectivity_cluster_t::run_t::*)(scoped_ptr_t<linux_tcp_conn_descriptor_t> const&, auto_drainer_t::lock_t)>::operator()(connectivity_cluster_t::run_t*, scoped_ptr_t<linux_tcp_conn_descriptor_t> const&, auto_drainer_t::lock_t) const at functional:550\n       35: _ZNSt5_BindIFSt7_Mem_fnIMN22connectivity_cluster_t5run_tEFvRK12scoped_ptr_tI27linux_tcp_conn_descriptor_tEN14auto_drainer_t6lock_tEEEPS2_St12_PlaceholderILi1EES9_EE6__callIvJRS5_EJLi0ELi1ELi2EEEET_OSt5tupleIJDpT0_EESt12_Index_tupleIJXspT1_EEE+0x9d at functional:1145\n       36: _ZNSt5_BindIFSt7_Mem_fnIMN22connectivity_cluster_t5run_tEFvRK12scoped_ptr_tI27linux_tcp_conn_descriptor_tEN14auto_drainer_t6lock_tEEEPS2_St12_PlaceholderILi1EES9_EEclIJRS5_EvEET0_DpOT_+0x3d at functional:1203\n       37: std::_Function_handler<void (scoped_ptr_t<linux_tcp_conn_descriptor_t>&), std::_Bind<std::_Mem_fn<void (connectivity_cluster_t::run_t::*)(scoped_ptr_t<linux_tcp_conn_descriptor_t> const&, auto_drainer_t::lock_t)> (connectivity_cluster_t::run_t*, std::_Placeholder<1>, auto_drainer_t::lock_t)> >::_M_invoke(std::_Any_data const&, scoped_ptr_t<linux_tcp_conn_descriptor_t>&) at functional:1779\n       38: std::function<void (scoped_ptr_t<linux_tcp_conn_descriptor_t>&)>::operator()(scoped_ptr_t<linux_tcp_conn_descriptor_t>&) const at functional:2160\n       39: linux_nonthrowing_tcp_listener_t::handle(int) at network.cc:939\n       40: std::_Mem_fn<void (linux_nonthrowing_tcp_listener_t::*)(int)>::operator()(linux_nonthrowing_tcp_listener_t*, int) const at functional:550\n       41: _ZNSt5_BindIFSt7_Mem_fnIM32linux_nonthrowing_tcp_listener_tFviEEPS1_iEE6__callIvJEJLi0ELi1EEEET_OSt5tupleIJDpT0_EESt12_Index_tupleIJXspT1_EEE+0x6f at functional:1145\n       42: _ZNSt5_BindIFSt7_Mem_fnIM32linux_nonthrowing_tcp_listener_tFviEEPS1_iEEclIJEvEET0_DpOT_+0x26 at functional:1203\n       43: callable_action_instance_t<std::_Bind<std::_Mem_fn<void (linux_nonthrowing_tcp_listener_t::*)(int)> (linux_nonthrowing_tcp_listener_t*, int)> >::run_action() at callable_action.hpp:28\n       44: callable_action_wrapper_t::run() at runtime_utils.cc:43\n       45: coro_t::run() at coroutines.cc:197\n       46: void coro_t::spawn_now_dangerously<std::_Bind<std::_Mem_fn<void (linux_nonthrowing_tcp_listener_t::*)(int)> (linux_nonthrowing_tcp_listener_t*, int)> >(std::_Bind<std::_Mem_fn<void (linux_nonthrowing_tcp_listener_t::*)(int)> (linux_nonthrowing_tcp_listener_t*, int)> const&) at coroutines.hpp:52\n       47: linux_nonthrowing_tcp_listener_t::accept_loop(auto_drainer_t::lock_t) at network.cc:907\n       48: std::_Mem_fn<void (linux_nonthrowing_tcp_listener_t::*)(auto_drainer_t::lock_t)>::operator()(linux_nonthrowing_tcp_listener_t*, auto_drainer_t::lock_t) const at functional:550\n       49: _ZNSt5_BindIFSt7_Mem_fnIM32linux_nonthrowing_tcp_listener_tFvN14auto_drainer_t6lock_tEEEPS1_S3_EE6__callIvJEJLi0ELi1EEEET_OSt5tupleIJDpT0_EESt12_Index_tupleIJXspT1_EEE+0x7c at functional:1145\n       50: _ZNSt5_BindIFSt7_Mem_fnIM32linux_nonthrowing_tcp_listener_tFvN14auto_drainer_t6lock_tEEEPS1_S3_EEclIJEvEET0_DpOT_+0x26 at functional:1203\n       51: callable_action_instance_t<std::_Bind<std::_Mem_fn<void (linux_nonthrowing_tcp_listener_t::*)(auto_drainer_t::lock_t)> (linux_nonthrowing_tcp_listener_t*, auto_drainer_t::lock_t)> >::run_action() at callable_action.hpp:28\n       52: callable_action_wrapper_t::run() at runtime_utils.cc:43\n       53: coro_t::run() at coroutines.cc:197\n       54: coro_t* coro_t::spawn_sometime<std::_Bind<std::_Mem_fn<void (linux_nonthrowing_tcp_listener_t::*)(auto_drainer_t::lock_t)> (linux_nonthrowing_tcp_listener_t*, auto_drainer_t::lock_t)> >(std::_Bind<std::_Mem_fn<void (linux_nonthrowing_tcp_listener_t::*)(auto_drainer_t::lock_t)> (linux_nonthrowing_tcp_listener_t*, auto_drainer_t::lock_t)> const&) at coroutines.hpp:58\n       55: linux_nonthrowing_tcp_listener_t::begin_listening() at network.cc:686\n       56: linux_tcp_listener_t::linux_tcp_listener_t(linux_tcp_bound_socket_t*, std::function<void (scoped_ptr_t<linux_tcp_conn_descriptor_t>&)> const&) at network.cc:983\n       57: connectivity_cluster_t::run_t::run_t(connectivity_cluster_t*, std::set<ip_address_t, std::less<ip_address_t>, std::allocator<ip_address_t> > const&, peer_address_t const&, int, int) at cluster.cc:245\n       58: do_serve(io_backender_t*, bool, base_path_t const&, metadata_persistence::cluster_persistent_file_t*, metadata_persistence::auth_persistent_file_t*, unsigned long, serve_info_t const&, os_signal_cond_t*) at serve.cc:150\n       59: serve(io_backender_t*, base_path_t const&, metadata_persistence::cluster_persistent_file_t*, metadata_persistence::auth_persistent_file_t*, unsigned long, serve_info_t const&, os_signal_cond_t*) at serve.cc:398\n       60: run_rethinkdb_serve(base_path_t const&, serve_info_t*, file_direct_io_mode_t, int, unsigned long, uuid_u const*, cluster_semilattice_metadata_t const*, directory_lock_t*, bool*) at command_line.cc:851\n       61: _ZNSt5_BindIFPFvRK11base_path_tP12serve_info_t21file_direct_io_mode_timPK6uuid_uPK30cluster_semilattice_metadata_tP16directory_lock_tPbES0_S4_S5_imPS6_PS9_SD_SE_EE6__callIvJEJLi0ELi1ELi2ELi3ELi4ELi5ELi6ELi7ELi8EEEET_OSt5tupleIJDpT0_EESt12_Index_tupleIJXspT1_EEE+0x1e0 at functional:1145\n       62: _ZNSt5_BindIFPFvRK11base_path_tP12serve_info_t21file_direct_io_mode_timPK6uuid_uPK30cluster_semilattice_metadata_tP16directory_lock_tPbES0_S4_S5_imPS6_PS9_SD_SE_EEclIJEvEET0_DpOT_+0x26 at functional:1203\n       63: std::_Function_handler<void (), std::_Bind<void (*(base_path_t, serve_info_t*, file_direct_io_mode_t, int, unsigned long, uuid_u*, cluster_semilattice_metadata_t*, directory_lock_t*, bool*))(base_path_t const&, serve_info_t*, file_direct_io_mode_t, int, unsigned long, uuid_u const*, cluster_semilattice_metadata_t const*, directory_lock_t*, bool*)> >::_M_invoke(std::_Any_data const&) at functional:1779\n       64: std::function<void ()>::operator()() const at functional:2160\n       65: starter_t::run_wrapper(std::function<void ()> const&) at runtime.cc:61\n       66: std::_Mem_fn<void (starter_t::*)(std::function<void ()> const&)>::operator()(starter_t*, std::function<void ()> const&) const at functional:550\n       67: _ZNSt5_BindIFSt7_Mem_fnIM9starter_tFvRKSt8functionIFvvEEEEPS1_S4_EE6__callIvJEJLi0ELi1EEEET_OSt5tupleIJDpT0_EESt12_Index_tupleIJXspT1_EEE+0x70 at functional:1145\n       68: _ZNSt5_BindIFSt7_Mem_fnIM9starter_tFvRKSt8functionIFvvEEEEPS1_S4_EEclIJEvEET0_DpOT_+0x26 at functional:1203\n       69: std::_Function_handler<void (), std::_Bind<std::_Mem_fn<void (starter_t::*)(std::function<void ()> const&)> (starter_t*, std::function<void ()>)> >::_M_invoke(std::_Any_data const&) at functional:1779\n       70: std::function<void ()>::operator()() const at functional:2160\n       71: callable_action_instance_t<std::function<void ()> >::run_action() at callable_action.hpp:28\n       72: callable_action_wrapper_t::run() at runtime_utils.cc:43\n       73: coro_t::run() at coroutines.cc:197\n       74: coro_t* coro_t::spawn_sometime<std::function<void ()> >(std::function<void ()> const&) at coroutines.hpp:58\n       75: starter_t::on_thread_switch() at runtime.cc:57\n       76: linux_message_hub_t::on_event(int) at message_hub.cc:154\n       77: epoll_event_queue_t::run() at epoll.cc:115\n       78: linux_thread_pool_t::start_thread(void*) at thread_pool.cc:155\n       79: /lib/x86_64-linux-gnu/libpthread.so.0(+0x7e9a) [0x7fc9b36f7e9a] at 0x7fc9b36f7e9a (/lib/x86_64-linux-gnu/libpthread.so.0)\n       80: clone+0x6d at 0x7fc9b34243fd (/lib/x86_64-linux-gnu/libc.so.6)\nerror: Exiting.\n```\n\nAs you can see there were hearbeat timeouts, and the crash happened when the server was shut down.\n\nThe changes I made to work around some other failure cases:\n\n```\ndiff --git a/src/clustering/immediate_consistency/branch/broadcaster.cc b/src/clustering/immediate_consistency/branch/broadcaster.cc\nindex 255f955..7d75c37 100644\n--- a/src/clustering/immediate_consistency/branch/broadcaster.cc\n+++ b/src/clustering/immediate_consistency/branch/broadcaster.cc\n@@ -202,7 +202,7 @@ public:\n         queue_count_membership(&c->broadcaster_collection, &queue_count, uuid_to_str(d.write_mailbox.get_peer().get_uuid()) + \"_broadcast_queue_count\"),\n         background_write_queue(&queue_count),\n         // TODO magic constant\n-        background_write_workers(100, &background_write_queue, &background_write_caller),\n+        background_write_workers(10, &background_write_queue, &background_write_caller),\n         controller(c),\n         upgrade_mailbox(controller->mailbox_manager,\n             boost::bind(&dispatchee_t::upgrade, this, _1, _2, auto_drainer_t::lock_t(&drainer))),\ndiff --git a/src/clustering/immediate_consistency/branch/listener.cc b/src/clustering/immediate_consistency/branch/listener.cc\nindex 396c312..8a34aa3 100644\n--- a/src/clustering/immediate_consistency/branch/listener.cc\n+++ b/src/clustering/immediate_consistency/branch/listener.cc\n@@ -21,7 +21,7 @@\n\n /* `WRITE_QUEUE_CORO_POOL_SIZE` is the number of coroutines that will be used\n when draining the write queue after completing a backfill. */\n-#define WRITE_QUEUE_CORO_POOL_SIZE 1000\n+#define WRITE_QUEUE_CORO_POOL_SIZE 10\n\n /* When we have caught up to the master to within\n `WRITE_QUEUE_SEMAPHORE_LONG_TERM_CAPACITY` elements, then we consider ourselves\ndiff --git a/test/memcached_workloads/multi_serial_mix.py b/test/memcached_workloads/multi_serial_mix.py\nindex b90ffcb..3694a14 100755\n--- a/test/memcached_workloads/multi_serial_mix.py\n+++ b/test/memcached_workloads/multi_serial_mix.py\n@@ -66,7 +66,7 @@ try:\n     def time_remaining():\n         time_elapsed = time.time() - start_time\n         # Give subprocesses lots of extra time\n-        return opts[\"duration\"] * 2 - time_elapsed + 1\n+        return opts[\"duration\"] * 2 - time_elapsed + 30\n\n     for process, id in processes:\n         tr = time_remaining()\n```\n"
  , issueState = "closed"
  , issueId = Id 39463838
  , issueComments = 5
  , issueMilestone =
      Just
        Milestone
          { milestoneCreator =
              SimpleUser
                { simpleUserId = Id 48436
                , simpleUserLogin = N "coffeemug"
                , simpleUserAvatarUrl =
                    "https://avatars.githubusercontent.com/u/48436?v=3"
                , simpleUserUrl = "https://api.github.com/users/coffeemug"
                , simpleUserType = OwnerUser
                }
          , milestoneDueOn = Nothing
          , milestoneOpenIssues = 0
          , milestoneNumber = 71
          , milestoneClosedIssues = 113
          , milestoneDescription = Just ""
          , milestoneTitle = "1.14"
          , milestoneUrl =
              "https://api.github.com/repos/rethinkdb/rethinkdb/milestones/71"
          , milestoneCreatedAt = 2014 (-06) (-11) 22 : 31 : 05 UTC
          , milestoneState = "closed"
          }
  }