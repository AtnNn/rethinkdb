IssueComment
  { issueCommentUpdatedAt = 2014 (-02) (-12) 23 : 25 : 28 UTC
  , issueCommentUser =
      SimpleUser
        { simpleUserId = Id 505365
        , simpleUserLogin = N "danielmewes"
        , simpleUserAvatarUrl =
            "https://avatars.githubusercontent.com/u/505365?v=3"
        , simpleUserUrl = "https://api.github.com/users/danielmewes"
        , simpleUserType = OwnerUser
        }
  , issueCommentUrl =
      "https://api.github.com/repos/rethinkdb/rethinkdb/issues/comments/34931213"
  , issueCommentHtmlUrl =
      "https://github.com/rethinkdb/rethinkdb/issues/1820#issuecomment-34931213"
  , issueCommentCreatedAt = 2014 (-02) (-12) 23 : 25 : 28 UTC
  , issueCommentBody =
      "@srh: I think it is still a problem in theory. However looking at the alt cache, I see that `alt_memory_tracker_t` puts a relatively hard limit on the number of outstanding changed blocks. So that might be enough to ensure that each individual `log_serializer_t::index_write()` is sufficiently small for this not to be a problem.\r\nIt doesn't protect us from the case where someone (or some internal code) does a `r.table('hugeTable').delete()` in a single transaction. That would still generate a huge `index_write()` transaction as far as I see. In that specific case we could probably just split up the transaction in the query code though."
  , issueCommentId = 34931213
  }