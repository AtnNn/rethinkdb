IssueComment
  { issueCommentUpdatedAt = 2013 (-04) (-02) 02 : 41 : 39 UTC
  , issueCommentUser =
      SimpleUser
        { simpleUserId = Id 48436
        , simpleUserLogin = N "coffeemug"
        , simpleUserAvatarUrl =
            "https://avatars.githubusercontent.com/u/48436?v=3"
        , simpleUserUrl = "https://api.github.com/users/coffeemug"
        , simpleUserType = OwnerUser
        }
  , issueCommentUrl =
      "https://api.github.com/repos/rethinkdb/rethinkdb/issues/comments/15750351"
  , issueCommentHtmlUrl =
      "https://github.com/rethinkdb/rethinkdb/issues/570#issuecomment-15750351"
  , issueCommentCreatedAt = 2013 (-04) (-02) 02 : 40 : 51 UTC
  , issueCommentBody =
      "I really like this proposal, for all of the following reasons:\r\n\r\n* It's incremental. Instead of spending months debating various evaluation models and then discovering that they break in some edge cases, don't fit reality, etc. this proposal takes our existing system and converts it to the one that's actually desirable via a small, incremental change.\r\n* It maintains safety semantics for people that want them. For example, if we make filter drop rows on error, the users will get confused when they get nothing back because of a silly error somewhere. With this proposal, people can pick between both models extremely easily, and get a safe model by default (which seems very sensible to me).\r\n* If we discover additional issues somewhere, we can tune the specific commands to fix them (whereas if we discover additional issues in a new evaluation model, they will quite possibly mean redoing everything).\r\n* Last but very much not least, this is easy to do. We can likely have this whole problem go away in just two days of development time.\r\n\r\nI'd really like to hear what @al3xandru and @jdoliner think about it."
  , issueCommentId = 15750351
  }