IssueComment
  { issueCommentUpdatedAt = 2013 (-08) (-29) 22 : 28 : 54 UTC
  , issueCommentUser =
      SimpleUser
        { simpleUserId = Id 1777134
        , simpleUserLogin = N "mlucy"
        , simpleUserAvatarUrl =
            "https://avatars.githubusercontent.com/u/1777134?v=3"
        , simpleUserUrl = "https://api.github.com/users/mlucy"
        , simpleUserType = OwnerUser
        }
  , issueCommentUrl =
      "https://api.github.com/repos/rethinkdb/rethinkdb/issues/comments/23528476"
  , issueCommentHtmlUrl =
      "https://github.com/rethinkdb/rethinkdb/issues/1385#issuecomment-23528476"
  , issueCommentCreatedAt = 2013 (-08) (-29) 22 : 28 : 54 UTC
  , issueCommentBody =
      "This seems different from that workload -- 2k writes/sec and 60 writes/sec aren't really in the same ballpark.\r\n\r\n@underrun --\r\n* Are you on an SSD or a rotational drive?\r\n* Are you using hard or soft durability?\r\n* What's your cluster setup?  How many nodes, how shards on the table, how many replicas, how many write acks?\r\n* Is there an obvious bottleneck on the machine running RethinkDB?  Is CPU utilization at 100%, for instance, or is the disk throughput saturated?\r\n* Is there an obvious bottleneck on the machine running the clients?  If you restart the clients, do you see the same performance numbers?\r\n* How are you doing the writes?  Are you sending one document at a time, or are you doing batched writes?  Are you doing one connection per write, or sending them all through the same connection?  If the former, are you closing the old connections?\r\n\r\nSorry for the barrage of questions, but it will make nailing down the performance problem much easier on our end."
  , issueCommentId = 23528476
  }