IssueComment
  { issueCommentUpdatedAt = 2013 (-09) (-12) 22 : 24 : 50 UTC
  , issueCommentUser =
      SimpleUser
        { simpleUserId = Id 258437
        , simpleUserLogin = N "srh"
        , simpleUserAvatarUrl =
            "https://avatars.githubusercontent.com/u/258437?v=3"
        , simpleUserUrl = "https://api.github.com/users/srh"
        , simpleUserType = OwnerUser
        }
  , issueCommentUrl =
      "https://api.github.com/repos/rethinkdb/rethinkdb/issues/comments/24360758"
  , issueCommentHtmlUrl =
      "https://github.com/rethinkdb/rethinkdb/issues/1424#issuecomment-24360758"
  , issueCommentCreatedAt = 2013 (-09) (-12) 22 : 24 : 50 UTC
  , issueCommentBody =
      "Well there's a big gap between what was promised with compression and what we got.  75% and 90% ratios were promised, and instead we get 50% on documents where basic variable object length encoding would get about 30%.  You can't think properly about the CPU/performance tradeoff if you don't have a reasonable baseline.  Also, this would help in the circumstances where we don't use compression -- we serialize strings and objects a lot."
  , issueCommentId = 24360758
  }