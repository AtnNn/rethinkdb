Issue
  { issueClosedAt = Just 2016 (-07) (-06) 18 : 22 : 46 UTC
  , issueUpdatedAt = 2016 (-07) (-13) 01 : 19 : 10 UTC
  , issueEventsUrl =
      "https://api.github.com/repos/rethinkdb/rethinkdb/issues/5902/events"
  , issueHtmlUrl =
      Just "https://github.com/rethinkdb/rethinkdb/issues/5902"
  , issueClosedBy = Nothing
  , issueLabels = []
  , issueNumber = 5902
  , issueAssignee = Nothing
  , issueUser =
      SimpleUser
        { simpleUserId = Id 1210951
        , simpleUserLogin = N "ttmc"
        , simpleUserAvatarUrl =
            "https://avatars.githubusercontent.com/u/1210951?v=3"
        , simpleUserUrl = "https://api.github.com/users/ttmc"
        , simpleUserType = OwnerUser
        }
  , issueTitle = "Question about memory (RAM) requirements"
  , issuePullRequest = Nothing
  , issueUrl =
      "https://api.github.com/repos/rethinkdb/rethinkdb/issues/5902"
  , issueCreatedAt = 2016 (-07) (-01) 15 : 31 : 55 UTC
  , issueBody =
      Just
        "I'm confused by the documentation about RethinkDB's memory (RAM) requirements, especially for clusters.\r\n\r\nFrom the page on [Limitations in RethinkDB](https://rethinkdb.com/limitations/):\r\n\r\n> RethinkDB requires data structures in RAM on each server proportional to the size of the data on that server\8217s disk, usually around 1% of the size of the total data set.\r\n\r\nIs \"the total data set\" referring to the data _on that server_ or in the entire cluster?\r\n\r\n<hr>\r\n\r\nFrom the page about [RethinkDB Architecture](https://www.rethinkdb.com/docs/architecture/):\r\n\r\n> RethinkDB can operate on a terabyte of data with about ten gigabytes of free RAM.\r\n\r\nAssuming that \"a terabyte of data\" is referring to the entire data set (i.e. the sum of the data in all primary replica shards), is the \"ten gigabytes of free RAM\" the RAM on _each server_ or the total RAM across all servers?\r\n\r\n<hr>\r\n\r\nThere's also a documentation page titled [Understanding RethinkDB memory requirements](https://rethinkdb.com/docs/memory-usage/), and it breaks apart the RAM requirements. I'm most concerned about the RAM requirements that grow with the data set, i.e. the RAM required for the metadata and indexes.\r\n\r\nThat's discussed in the last subsection (\"Internal metadata\"), but again it's not clear if the required memory is per server, or across the entire cluster."
  , issueState = "closed"
  , issueId = Id 163420304
  , issueComments = 3
  , issueMilestone =
      Just
        Milestone
          { milestoneCreator =
              SimpleUser
                { simpleUserId = Id 706854
                , simpleUserLogin = N "AtnNn"
                , simpleUserAvatarUrl =
                    "https://avatars.githubusercontent.com/u/706854?v=3"
                , simpleUserUrl = "https://api.github.com/users/AtnNn"
                , simpleUserType = OwnerUser
                }
          , milestoneDueOn = Nothing
          , milestoneOpenIssues = 0
          , milestoneNumber = 26
          , milestoneClosedIssues = 316
          , milestoneDescription =
              Just
                "These issues are neither bugs nor feature requests. Spam, user questions and accidentally created issues end up here."
          , milestoneTitle = "invalid"
          , milestoneUrl =
              "https://api.github.com/repos/rethinkdb/rethinkdb/milestones/26"
          , milestoneCreatedAt = 2013 (-04) (-05) 01 : 37 : 20 UTC
          , milestoneState = "closed"
          }
  }