Issue
  { issueClosedAt = Just 2013 (-10) (-07) 19 : 46 : 31 UTC
  , issueUpdatedAt = 2013 (-10) (-22) 20 : 36 : 05 UTC
  , issueEventsUrl =
      "https://api.github.com/repos/rethinkdb/rethinkdb/issues/1380/events"
  , issueHtmlUrl =
      Just "https://github.com/rethinkdb/rethinkdb/issues/1380"
  , issueClosedBy = Nothing
  , issueLabels =
      [ IssueLabel
          { labelColor = "e10c02"
          , labelUrl =
              "https://api.github.com/repos/rethinkdb/rethinkdb/labels/pr:high"
          , labelName = "pr:high"
          }
      , IssueLabel
          { labelColor = "e102d8"
          , labelUrl =
              "https://api.github.com/repos/rethinkdb/rethinkdb/labels/tp:bug"
          , labelName = "tp:bug"
          }
      ]
  , issueNumber = 1380
  , issueAssignee =
      Just
        SimpleUser
          { simpleUserId = Id 505365
          , simpleUserLogin = N "danielmewes"
          , simpleUserAvatarUrl =
              "https://avatars.githubusercontent.com/u/505365?v=3"
          , simpleUserUrl = "https://api.github.com/users/danielmewes"
          , simpleUserType = OwnerUser
          }
  , issueUser =
      SimpleUser
        { simpleUserId = Id 588857
        , simpleUserLogin = N "wuub"
        , simpleUserAvatarUrl =
            "https://avatars.githubusercontent.com/u/588857?v=3"
        , simpleUserUrl = "https://api.github.com/users/wuub"
        , simpleUserType = OwnerUser
        }
  , issueTitle =
      "Crashes with smallish table during stressful rebalance after replication & sharding change"
  , issuePullRequest = Nothing
  , issueUrl =
      "https://api.github.com/repos/rethinkdb/rethinkdb/issues/1380"
  , issueCreatedAt = 2013 (-08) (-28) 14 : 38 : 25 UTC
  , issueBody =
      Just
        "Hi guys,\n\nI've tried IRC but it's a bit quiet there:\n\nI'm testing rethinkdb locally, version 1.8.0, 32bit ubuntu 13.04, 4GB+ free ram.\n- 3 node cluster (nothing fancy, rethinkdb -j ... -o ...)\n- 1 table with \n- 150k records \n- average record size ~400byte \n- default cache size of 1024MB.\n\n_Then_ I do something stupid:\n1) set the number of shards to: 16\n2) immediately set number of replicas to: 3\n\nRebalancing starts, writes/sec rise significantly (up to 5k+/sec) and then one (or more) node crashes with something like this: \n\n```\nVersion: rethinkdb 1.8.0-0ubuntu1~raring (GCC 4.7.3)\nerror: Error in src/arch/runtime/thread_pool.cc at line 319:\nerror: Segmentation fault from reading the address (nil).\nerror: Backtrace:\naddr2line: 'rethinkdb': No such file\nerror: Wed Aug 28 16:19:37 2013\n\n       1: format_backtrace(bool) at 0x8b3e296 (rethinkdb)\n       2: report_fatal_error(char const*, int, char const*, ...) at 0x8ad9395 (rethinkdb)\n       3: linux_thread_pool_t::sigsegv_handler(int, siginfo_t*, void*) at 0x864a8fe (rethinkdb)\n       4: [0xb776b40c]\n       5: mc_cache_t::register_buf_snapshot(mc_inner_buf_t*, mc_inner_buf_t::buf_snapshot_t*, unsigned long long, unsigned long long) at 0x87b8fec (rethinkdb)\n       6: mc_inner_buf_t::snapshot_if_needed(unsigned long long, bool) at 0x87b9a0f (rethinkdb)\n       7: mc_buf_lock_t::acquire_block(unsigned long long) at 0x87b9d15 (rethinkdb)\n       8: mc_buf_lock_t::initialize(unsigned long long, file_account_t*, lock_in_line_callback_t*) at 0x87b9ea1 (rethinkdb)\n       9: mc_buf_lock_t::mc_buf_lock_t(mc_transaction_t*, unsigned long long, access_t, buffer_cache_order_mode_t, lock_in_line_callback_t*) at 0x87ba250 (rethinkdb)\n       10: process_a_leaf_node(traversal_state_t*, scoped_ptr_t<mc_buf_lock_t>*, int, btree_key_t const*, btree_key_t const*) at 0x8ae78fd (rethinkdb)\n       11: do_a_subtree_traversal_fsm_t::on_node_ready(scoped_ptr_t<mc_buf_lock_t>*) at 0x8aea368 (rethinkdb)\n       12: acquire_a_node_fsm_t::you_may_acquire() at 0x8ae8c62 (rethinkdb)\n       13: coro_pool_t<acquisition_waiter_callback_t*>::worker_run(acquisition_waiter_callback_t*, auto_drainer_t::lock_t) at 0x8ae8b88 (rethinkdb)\n       14: callable_action_instance_t<boost::_bi::bind_t<void, boost::_mfi::mf2<void, coro_pool_t<acquisition_waiter_callback_t*>, acquisition_waiter_callback_t*, auto_drainer_t::lock_t>, boost::_bi::list3<boost::_bi::value<coro_pool_t<acquisition_waiter_callback_t*>*>, boost::_bi::value<acquisition_waiter_callback_t*>, boost::_bi::value<auto_drainer_t::lock_t> > > >::run_action() at 0x8ae8da5 (rethinkdb)\n       15: coro_t::run() at 0x8647bec (rethinkdb)\nerror: Exiting.\nTrace/breakpoint trap\n```\n\nAm I doing something wrong? Is this OOM error? If so, what can I do to prevent such issues in the future (even at the cost of degraded performance).\n\nI was able to recreate this pretty easily, so if this backtrace is somehow broken I can rerun the test. \n"
  , issueState = "closed"
  , issueId = Id 18673352
  , issueComments = 14
  , issueMilestone =
      Just
        Milestone
          { milestoneCreator =
              SimpleUser
                { simpleUserId = Id 706854
                , simpleUserLogin = N "AtnNn"
                , simpleUserAvatarUrl =
                    "https://avatars.githubusercontent.com/u/706854?v=3"
                , simpleUserUrl = "https://api.github.com/users/AtnNn"
                , simpleUserType = OwnerUser
                }
          , milestoneDueOn = Nothing
          , milestoneOpenIssues = 0
          , milestoneNumber = 51
          , milestoneClosedIssues = 14
          , milestoneDescription = Nothing
          , milestoneTitle = "1.10.1"
          , milestoneUrl =
              "https://api.github.com/repos/rethinkdb/rethinkdb/milestones/51"
          , milestoneCreatedAt = 2013 (-10) (-22) 20 : 34 : 54 UTC
          , milestoneState = "closed"
          }
  }