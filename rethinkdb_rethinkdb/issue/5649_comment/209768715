IssueComment
  { issueCommentUpdatedAt = 2016 (-04) (-14) 19 : 02 : 22 UTC
  , issueCommentUser =
      SimpleUser
        { simpleUserId = Id 478118
        , simpleUserLogin = N "bchavez"
        , simpleUserAvatarUrl =
            "https://avatars.githubusercontent.com/u/478118?v=3"
        , simpleUserUrl = "https://api.github.com/users/bchavez"
        , simpleUserType = OwnerUser
        }
  , issueCommentUrl =
      "https://api.github.com/repos/rethinkdb/rethinkdb/issues/comments/209768715"
  , issueCommentHtmlUrl =
      "https://github.com/rethinkdb/rethinkdb/pull/5649#issuecomment-209768715"
  , issueCommentCreatedAt = 2016 (-04) (-14) 05 : 22 : 48 UTC
  , issueCommentBody =
      "Hi Peter,\r\n\r\nI'll try my best to answer your questions. Forgive me if I accidentally get something wrong, I don't have my IDE with me at the moment.\r\n\r\n> 3. Good point about accumulation/exhaustion if one node goes down for a while. The proper way of handling this would be to have a set of connection pools, one for each node. The lease logic would then round-robin through the set of connection pools, skipping pools that can not produce a working Connection (maybe with some time-based back-off algorithm for unavailable nodes). When node is again available, the logic would instantly (depending on the back-off) start producing Connections for it.\r\n\r\nSo, my gut feeling here is that using a lease-use-return pattern here is sort of antithetical to the design of the `Connection` object. `Connection` objects themselves are thread-safe, designed, and meant to be used by multiple threads concurrently regardless of the results and responses they produce. For example, five threads holding the same `Connection` object reference can call `.run` at virtually the same time without interfering with each other. Internally, the synchronization primitives inside `Connection` will ensure queries will get serialized individually, in whole, in some order, over the wire. Query responses from the server can be parsed in any order and awaiting threads in any order will be notified individually when their query response is ready: whether that response is a `ReqlError` or a legitimate data response.\r\n\r\nWhen a network I/O error occurs (ie: someone unplugs a cable or shuts down a server), all awaiting threads with pending responses on that particular faulted `Connection` are notified with an `IOException` and the `Connection` is internally shutdown and `.closed`. When the `Connection` is in this state, the `Connection` is non-recoverable and must be manually `.reconnected`.\r\n\r\nAbsent of network I/O error exceptions, the `Connection` can be re-used without problems. `ReqlError` exceptions are channeled to the corresponding thread to be dealt with however they see fit.\r\n\r\nSo, when we think about lease-use-return patterns like what we've discussed here, what we're really doing is introducing an extra layer of synchronization on top of an already existing internal layer synchronization primitives inside `Connection`, which, in my view, seems unnecessary. Our lease-use-return pattern is really only adding extra overhead and latency to a query with no substantial benefit.\r\n\r\nA better \"pooling\" pattern for `Connection`, I think, is a select-use pattern. Make a `Connection` selection and use it. Don't worry about returning it back to the `pool`. Select-use removes the responsibility of the caller to return the `Connection` to the `pool`. Removes the possibility of regressing in #5448. We don't have to depend on a GC that we can't control. We've minimized the number of locks we take on the way down to the wire. Last but not least we've eliminated the concept of 'exhaustion'. All wins I think. But how? Some pseudo code, in broad strokes:\r\n\r\n```\r\nclass HostEntry{\r\n  Connection Connection;\r\n  bool IsFaulted;\r\n  DateTime NextRetry;\r\n}\r\n\r\nclass HostPool{\r\n\r\n  HostEntry[] HostArray;\r\n  AtomicInteger next;\r\n\r\n  selectConnection(){\r\n    do{\r\n       var index = next.incrementAndGet();\r\n       var entry = HostArray[ index % HostArray.Length ];\r\n    } while( entry.IsFaulted )\r\n    return entry;\r\n  }\r\n  \r\n  addHost(Connection conn){\r\n    var updatedHostArray = new HostArray[HostArray.Length + 1];\r\n    Array.Copy(HostArray, updatedHostArray);\r\n    \r\n    var newHostEntry = new HostEntry(conn);\r\n    updatedHostArray[LAST] = newHostEntry;\r\n    HostArray = updatedHostArray;\r\n  }\r\n  \r\n}\r\n```\r\n\r\nSome precautions like making sure we don't get stuck in the loop when all nodes are down... etc.\r\n\r\nSelect-use pattern invites the question: Does it make sense to maintain multiple connections to the **same** server from the **same** process? The answer: Maybe, maybe not. Last I can recall from a conversation I had was that multiple client connections to the same server can offer only *slightly* better performance on a multi-core RethinkDB server. Is it worth it? I don't know. It's hard to say without some hard numbers. My gut feeling here is that it may not be worth the cost of extra complexity and maintenance. If I had to hazard a guess, there's probably a point of diminishing returns. That point would converge even faster with multiple connections to the same server especially when multiple application servers are involved (`N app servers x N connections per server` against a RethinkDB server[or cluster]). Some empirical numbers on this subject would be really nice though.\r\n\r\nNow, how do we know when a `Connection` `IsFaulted`? Ah... the $10,000 question. A few ways maybe...\r\n\r\nOption A: Using exceptions as a control signal (yes, I know, the code smell is real and ugly, but works):\r\n```\r\npublic <T> T run(ConnectionPool pool) {\r\n    var hostEntry = pool.selectConnection();\r\n    var conn = hostEntry.Connection;\r\n    try{\r\n      T res = this.run(conn);\r\n      return res;\r\n    }\r\n    catch(IOException ex){\r\n      //network fault\r\n      pool.markFaulted(hostEntry);\r\n      rethrow ex;\r\n    }\r\n    catch(Exception e){\r\n      rethrow e;\r\n    }\r\n}\r\n```\r\nand the debate on whether or not using exceptions as control signals is a good idea in practice rages on... :smiley_cat: \r\n\r\nOption B: Bubble up the `.close` event (or via the `Connection.ResponsePump`). Basically, modify `Connection` to allow the registration of some lambda callbacks that will be called when a fault is detected. The pool would register a callback with the connection when it's setup/connected. When a `Connection` fault is detected we instantly know to exclude the faulted node from selection by registering `pool.markFaulted` in our callback.\r\n\r\n\r\n> 2. About possible resources leak: should all uses of `Connection` try-catch exceptions and `.close()` the `Connection`? This is not indicated in docs/examples.\r\n\r\nI'm not sure. Depends on your application and whether you favor fail-early-fail-fast or prefer defensively guarding against query and network errors.\r\n\r\n-----\r\n\r\nI *hope* I've answered the questions below with my explanation above.\r\n\r\n> 1. As I understand there is no way for user code (or ConnectionPool wrapper) to know if an exception thrown by Connection can be recovered from?\r\n\r\n> Are there any exceptions thrown by Connection that are recoverable? If yes, than they should be expected by user code and should be a checked exception (forcing user at compile time to deal with this possible situation).\r\n\r\n> Can Connection continue to be used after such exception? If yes, then they should probably not be an exception, but an error code.\r\n\r\n> Can en exception happen that affects just one Cursor and others Cursors can happily continue working? If yes, then the exception should be thrown on the Cursor, or the Cursor instead just produces the error code.\r\n\r\n-----\r\n\r\nAnd finally, some helpful links if you're curious:\r\n\r\nJava connection is now thread-safe\r\nhttps://github.com/rethinkdb/rethinkdb/pull/5292\r\n\r\nSpecifically, section on **Regarding Connection Pooling**\r\nhttps://github.com/rethinkdb/rethinkdb/pull/5292#issuecomment-172261625\r\n\r\nThe design notes for .NET Connection Pooling here:\r\nhttps://github.com/bchavez/RethinkDb.Driver/issues/17\r\n\r\nAssociated documentation for .NET Connection Pooling:\r\nhttps://github.com/bchavez/RethinkDb.Driver/wiki/Connections-&-Pooling\r\n\r\nThe .NET driver implementation is here:\r\nhttps://github.com/bchavez/RethinkDb.Driver/tree/master/Source/RethinkDb.Driver/Net/Clustering\r\n\r\n\r\nMy particular implementation is heavily optimized for selection performance so I'm bending OO-SOLID rules. I think I've done both Option A and B. We could probably just get by with option B honestly. It's getting late. :)\r\n\r\nI hope this helps,\r\nBrian"
  , issueCommentId = 209768715
  }