IssueComment
  { issueCommentUpdatedAt = 2016 (-09) (-15) 18 : 48 : 29 UTC
  , issueCommentUser =
      SimpleUser
        { simpleUserId = Id 505365
        , simpleUserLogin = N "danielmewes"
        , simpleUserAvatarUrl =
            "https://avatars.githubusercontent.com/u/505365?v=3"
        , simpleUserUrl = "https://api.github.com/users/danielmewes"
        , simpleUserType = OwnerUser
        }
  , issueCommentUrl =
      "https://api.github.com/repos/rethinkdb/rethinkdb/issues/comments/247416451"
  , issueCommentHtmlUrl =
      "https://github.com/rethinkdb/rethinkdb/issues/6055#issuecomment-247416451"
  , issueCommentCreatedAt = 2016 (-09) (-15) 18 : 48 : 29 UTC
  , issueCommentBody =
      "@bsharpe Hmm hard to say. One thing that could help a bit is if you can move over existing shards without adding any new shards. In that case, downtime should be very very short.\r\n\r\nYou could take this to the extreme, and shard tables into more shards than necessary once (let's say 16). This can be done through the `reconfigure` command, but not through the web UI (which limits the number of shards to the number of servers in the cluster). After that, you can change the replica assignment of those shards by updating the `table_config` document without adding or removing any shards.\r\nHowever some queries become less efficient when there are more shards than servers, so this is not without drawbacks."
  , issueCommentId = 247416451
  }