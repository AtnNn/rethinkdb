IssueComment
  { issueCommentUpdatedAt = 2013 (-08) (-27) 23 : 13 : 18 UTC
  , issueCommentUser =
      SimpleUser
        { simpleUserId = Id 1777134
        , simpleUserLogin = N "mlucy"
        , simpleUserAvatarUrl =
            "https://avatars.githubusercontent.com/u/1777134?v=3"
        , simpleUserUrl = "https://api.github.com/users/mlucy"
        , simpleUserType = OwnerUser
        }
  , issueCommentUrl =
      "https://api.github.com/repos/rethinkdb/rethinkdb/issues/comments/23378809"
  , issueCommentHtmlUrl =
      "https://github.com/rethinkdb/rethinkdb/issues/1369#issuecomment-23378809"
  , issueCommentCreatedAt = 2013 (-08) (-27) 23 : 13 : 18 UTC
  , issueCommentBody =
      "I'm going to work on setting this up.  I'm gonna go with 2K documents for\r\nnow.  I might deviate slightly from the specifications (in particular, I\r\nthink that 4 nodes would be better than 2 with out current resources).\r\n\r\n\r\nOn Tue, Aug 27, 2013 at 3:19 PM, Michel <notifications@github.com> wrote:\r\n\r\n> a bunch of other data (irrelevant what it is, just has to fill up the docs\r\n> to 1-2KB)\r\n>\r\n> Last time I tried using big documents (yesterday), I noticed that adding\r\n> one field to reach 256KB was quite different than adding 256 fields of 1KB\r\n> (on an Atom, 2GB of RAM and a rotational drive). I can try again if needed.\r\n>\r\n> We should periodically drop clients and connect new ones (i.e. pick a\r\n> random client and reconnect every second).\r\n>\r\n> We should keep a few clients always connected I think. It would be a nice\r\n> way to know that we don't have leaks when clients stay connected for a long\r\n> time.\r\n>\r\n> \8212\r\n> Reply to this email directly or view it on GitHub<https://github.com/rethinkdb/rethinkdb/issues/1369#issuecomment-23375945>\r\n> .\r\n>"
  , issueCommentId = 23378809
  }