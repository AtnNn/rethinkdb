IssueComment
  { issueCommentUpdatedAt = 2013 (-08) (-27) 22 : 19 : 49 UTC
  , issueCommentUser =
      SimpleUser
        { simpleUserId = Id 1461947
        , simpleUserLogin = N "neumino"
        , simpleUserAvatarUrl =
            "https://avatars.githubusercontent.com/u/1461947?v=3"
        , simpleUserUrl = "https://api.github.com/users/neumino"
        , simpleUserType = OwnerUser
        }
  , issueCommentUrl =
      "https://api.github.com/repos/rethinkdb/rethinkdb/issues/comments/23375945"
  , issueCommentHtmlUrl =
      "https://github.com/rethinkdb/rethinkdb/issues/1369#issuecomment-23375945"
  , issueCommentCreatedAt = 2013 (-08) (-27) 22 : 19 : 49 UTC
  , issueCommentBody =
      ">  a bunch of other data (irrelevant what it is, just has to fill up the docs to 1-2KB)\r\n\r\nLast time I tried using big documents (yesterday), I noticed that adding one field to reach 256KB was quite different than adding 256 fields of 1KB (on an Atom, 2GB of RAM and a rotational drive). I can try again if needed.\r\n\r\n> We should periodically drop clients and connect new ones (i.e. pick a random client and reconnect every second).\r\n\r\nWe should keep a few clients always connected I think. It would be a nice way to know that we don't have leaks when clients stay connected for a long time."
  , issueCommentId = 23375945
  }