IssueComment
  { issueCommentUpdatedAt = 2013 (-02) (-18) 07 : 06 : 00 UTC
  , issueCommentUser =
      SimpleUser
        { simpleUserId = Id 43867
        , simpleUserLogin = N "jdoliner"
        , simpleUserAvatarUrl =
            "https://avatars.githubusercontent.com/u/43867?v=3"
        , simpleUserUrl = "https://api.github.com/users/jdoliner"
        , simpleUserType = OwnerUser
        }
  , issueCommentUrl =
      "https://api.github.com/repos/rethinkdb/rethinkdb/issues/comments/13708855"
  , issueCommentHtmlUrl =
      "https://github.com/rethinkdb/rethinkdb/issues/159#issuecomment-13708855"
  , issueCommentCreatedAt = 2013 (-02) (-18) 07 : 06 : 00 UTC
  , issueCommentBody =
      "So I realized we could do a temporary fix for this and rather than sort by loading things in to a std::vector and sorting we could load them in to a BTree using the order_by values as keys and then read them back out again. It's a bit of a hack but I actually think it would work pretty well and it means that we won't crash by going out of memory. What do people think? It's a small amount of work and I don't think there's much chance we're actually going to solve this the right way anytime within the next 6 months."
  , issueCommentId = 13708855
  }