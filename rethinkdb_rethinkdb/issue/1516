Issue
  { issueClosedAt = Just 2013 (-11) (-08) 00 : 27 : 29 UTC
  , issueUpdatedAt = 2013 (-11) (-13) 00 : 25 : 32 UTC
  , issueEventsUrl =
      "https://api.github.com/repos/rethinkdb/rethinkdb/issues/1516/events"
  , issueHtmlUrl =
      Just "https://github.com/rethinkdb/rethinkdb/issues/1516"
  , issueClosedBy = Nothing
  , issueLabels =
      [ IssueLabel
          { labelColor = "e102d8"
          , labelUrl =
              "https://api.github.com/repos/rethinkdb/rethinkdb/labels/tp:bug"
          , labelName = "tp:bug"
          }
      ]
  , issueNumber = 1516
  , issueAssignee =
      Just
        SimpleUser
          { simpleUserId = Id 505365
          , simpleUserLogin = N "danielmewes"
          , simpleUserAvatarUrl =
              "https://avatars.githubusercontent.com/u/505365?v=3"
          , simpleUserUrl = "https://api.github.com/users/danielmewes"
          , simpleUserType = OwnerUser
          }
  , issueUser =
      SimpleUser
        { simpleUserId = Id 505365
        , simpleUserLogin = N "danielmewes"
        , simpleUserAvatarUrl =
            "https://avatars.githubusercontent.com/u/505365?v=3"
        , simpleUserUrl = "https://api.github.com/users/danielmewes"
        , simpleUserType = OwnerUser
        }
  , issueTitle =
      "Too many coroutines when re-sharding, node becomes unresponsive"
  , issuePullRequest = Nothing
  , issueUrl =
      "https://api.github.com/repos/rethinkdb/rethinkdb/issues/1516"
  , issueCreatedAt = 2013 (-10) (-05) 00 : 00 : 33 UTC
  , issueBody =
      Just
        "I was re-sharding and changing the number of replicas for a table of 150k documents, 400 bytes each on a cluster of three nodes.\n\nThree things happened: 1. The web-UI became unresponsive and timed out. 2. The node from which I had issued the re-sharding also didn't answer client connections anymore (at least one other node still did) 3. After a while, one of the nodes triggered an assertion that there were too many co-routines.\n\n```\n       1: rethinkdb_backtrace(void**, int) at thread_stack_pcs.cc:150\n       2: lazy_backtrace_t::lazy_backtrace_t() at backtrace.cc:250\n       3: format_backtrace(bool) at backtrace.cc:197\n       4: report_fatal_error(char const*, int, char const*, ...) at errors.cc:68\n       5: coro_t::coro_t() at coroutines.cc:134\n       6: coro_t::get_coro() at coroutines.cc:356\n       7: coro_t* coro_t::get_and_init_coro<boost::_bi::bind_t<void, boost::_mfi::mf3<void, mailbox_manager_t, threadnum_t, unsigned long, string_read_stream_t*>, boost::_bi::list4<boost::_bi::value<mailbox_manager_t*>, boost::_bi::value<threadnum_t>, boost::_bi::value<unsigned long>, boost::_bi::value<string_read_stream_t*> > > >(boost::_bi::bind_t<void, boost::_mfi::mf3<void, mailbox_manager_t, threadnum_t, unsigned long, string_read_stream_t*>, boost::_bi::list4<boost::_bi::value<mailbox_manager_t*>, boost::_bi::value<threadnum_t>, boost::_bi::value<unsigned long>, boost::_bi::value<string_read_stream_t*> > > const&) at coroutines.hpp:126\n       8: void coro_t::spawn_now_dangerously<boost::_bi::bind_t<void, boost::_mfi::mf3<void, mailbox_manager_t, threadnum_t, unsigned long, string_read_stream_t*>, boost::_bi::list4<boost::_bi::value<mailbox_manager_t*>, boost::_bi::value<threadnum_t>, boost::_bi::value<unsigned long>, boost::_bi::value<string_read_stream_t*> > > >(boost::_bi::bind_t<void, boost::_mfi::mf3<void, mailbox_manager_t, threadnum_t, unsigned long, string_read_stream_t*>, boost::_bi::list4<boost::_bi::value<mailbox_manager_t*>, boost::_bi::value<threadnum_t>, boost::_bi::value<unsigned long>, boost::_bi::value<string_read_stream_t*> > > const&) at coroutines.hpp:32\n       9: mailbox_manager_t::on_message(peer_id_t, string_read_stream_t*) at mailbox.cc:125\n       10: message_multiplexer_t::run_t::on_message(peer_id_t, string_read_stream_t*) at multiplexer.cc:35\n       11: connectivity_cluster_t::run_t::handle(keepalive_tcp_conn_stream_t*, boost::optional<peer_id_t>, boost::optional<peer_address_t>, auto_drainer_t::lock_t, bool*) at cluster.cc:792\n       12: connectivity_cluster_t::run_t::connect_to_peer(peer_address_t const*, int, boost::optional<peer_id_t>, auto_drainer_t::lock_t, bool*, semaphore_t*) at cluster.cc:244\n...\n```\n\n(Also see\nhttps://github.com/rethinkdb/rethinkdb/issues/1380#issuecomment-25736071 )\n\n@jdoliner mentioned that using a coro pool could be a way to avoid this.\n"
  , issueState = "closed"
  , issueId = Id 20556179
  , issueComments = 37
  , issueMilestone =
      Just
        Milestone
          { milestoneCreator =
              SimpleUser
                { simpleUserId = Id 48436
                , simpleUserLogin = N "coffeemug"
                , simpleUserAvatarUrl =
                    "https://avatars.githubusercontent.com/u/48436?v=3"
                , simpleUserUrl = "https://api.github.com/users/coffeemug"
                , simpleUserType = OwnerUser
                }
          , milestoneDueOn = Just 2013 (-11) (-21) 08 : 00 : 00 UTC
          , milestoneOpenIssues = 0
          , milestoneNumber = 46
          , milestoneClosedIssues = 79
          , milestoneDescription = Just ""
          , milestoneTitle = "1.11"
          , milestoneUrl =
              "https://api.github.com/repos/rethinkdb/rethinkdb/milestones/46"
          , milestoneCreatedAt = 2013 (-07) (-27) 05 : 40 : 03 UTC
          , milestoneState = "closed"
          }
  }