IssueComment
  { issueCommentUpdatedAt = 2014 (-07) (-21) 06 : 00 : 16 UTC
  , issueCommentUser =
      SimpleUser
        { simpleUserId = Id 218725
        , simpleUserLogin = N "dminkovsky"
        , simpleUserAvatarUrl =
            "https://avatars.githubusercontent.com/u/218725?v=3"
        , simpleUserUrl = "https://api.github.com/users/dminkovsky"
        , simpleUserType = OwnerUser
        }
  , issueCommentUrl =
      "https://api.github.com/repos/rethinkdb/rethinkdb/issues/comments/49573918"
  , issueCommentHtmlUrl =
      "https://github.com/rethinkdb/rethinkdb/issues/195#issuecomment-49573918"
  , issueCommentCreatedAt = 2014 (-07) (-21) 06 : 00 : 16 UTC
  , issueCommentBody =
      "Basically interested in how such an integration can deal with events like:\r\n\r\n> The server will buffer up to 100,000 elements. If the buffer limit is hit, early changes will be discarded, and the client will receive an object of the form {error: \"Changefeed cache over array size limit, skipped X elements.\"} where X is the number of elements skipped.\r\n\r\n> If the table becomes unavailable, the changefeed will be disconnected, and a runtime exception will be thrown by the driver."
  , issueCommentId = 49573918
  }