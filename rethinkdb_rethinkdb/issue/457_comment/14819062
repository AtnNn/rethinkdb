IssueComment
  { issueCommentUpdatedAt = 2013 (-03) (-13) 02 : 58 : 36 UTC
  , issueCommentUser =
      SimpleUser
        { simpleUserId = Id 1461947
        , simpleUserLogin = N "neumino"
        , simpleUserAvatarUrl =
            "https://avatars.githubusercontent.com/u/1461947?v=3"
        , simpleUserUrl = "https://api.github.com/users/neumino"
        , simpleUserType = OwnerUser
        }
  , issueCommentUrl =
      "https://api.github.com/repos/rethinkdb/rethinkdb/issues/comments/14819062"
  , issueCommentHtmlUrl =
      "https://github.com/rethinkdb/rethinkdb/issues/457#issuecomment-14819062"
  , issueCommentCreatedAt = 2013 (-03) (-13) 02 : 58 : 36 UTC
  , issueCommentBody =
      "I have a table with 10K documents.\r\nI pull 2000 documents from them, then do some random get, using one thread, 100 connections (using `/home/michel/fuzzer/clean/buikd/fuzzer-read*.js`\r\n\r\nHere's what I get\r\n```\r\n1.4\r\n260 reads/sec\r\n\r\n1.3.2\r\n680 reads/sec\r\n```\r\n\r\nI'll merge all the files and clean my code. But we have a rough idea of the numbers now."
  , issueCommentId = 14819062
  }