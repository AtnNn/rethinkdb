IssueComment
  { issueCommentUpdatedAt = 2014 (-08) (-08) 18 : 48 : 01 UTC
  , issueCommentUser =
      SimpleUser
        { simpleUserId = Id 505365
        , simpleUserLogin = N "danielmewes"
        , simpleUserAvatarUrl =
            "https://avatars.githubusercontent.com/u/505365?v=3"
        , simpleUserUrl = "https://api.github.com/users/danielmewes"
        , simpleUserType = OwnerUser
        }
  , issueCommentUrl =
      "https://api.github.com/repos/rethinkdb/rethinkdb/issues/comments/51642484"
  , issueCommentHtmlUrl =
      "https://github.com/rethinkdb/rethinkdb/issues/2703#issuecomment-51642484"
  , issueCommentCreatedAt = 2014 (-08) (-08) 18 : 48 : 01 UTC
  , issueCommentBody =
      "@bigtree3131 Thank you for the additional info! Running out of memory on a 128GB machine doesn't sound right, and makes me thing that there is some corruption going on in RethinkDB. Unless the data you are oeprating on is *really* large.\r\nHow big is the backed up data?\r\n\r\n@bigtree3131 If you can send me the dmesg output to daniel@rethinkdb.com that would be great.  Having the data might be helpful too, but I would like to first look at the dmesg output before sending you through the trouble of uploading it (we can arrange for a secure upload site).\r\n\r\nRunning some memory checker certainly doesn't hurt. HD issues in my experience often leave some trace in dmesg. I will also look for that."
  , issueCommentId = 51642484
  }