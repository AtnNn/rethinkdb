IssueComment
  { issueCommentUpdatedAt = 2015 (-08) (-05) 23 : 13 : 49 UTC
  , issueCommentUser =
      SimpleUser
        { simpleUserId = Id 505365
        , simpleUserLogin = N "danielmewes"
        , simpleUserAvatarUrl =
            "https://avatars.githubusercontent.com/u/505365?v=3"
        , simpleUserUrl = "https://api.github.com/users/danielmewes"
        , simpleUserType = OwnerUser
        }
  , issueCommentUrl =
      "https://api.github.com/repos/rethinkdb/rethinkdb/issues/comments/128180750"
  , issueCommentHtmlUrl =
      "https://github.com/rethinkdb/rethinkdb/issues/4629#issuecomment-128180750"
  , issueCommentCreatedAt = 2015 (-08) (-05) 23 : 13 : 49 UTC
  , issueCommentBody =
      "@coffeemug Because if you do large writes e.g. `r.table(...).delete()` or the `UPDATE collection SET field = field + 1 WHERE field > 20` that @Slava mentioned, we will potentially have to return a huge number of write IDs to the write query. This can go into the gigabytes.\r\n\r\nI feel like this might be an acceptable restriction assuming it makes our implementation a lot easier, but it's not perfect."
  , issueCommentId = 128180750
  }