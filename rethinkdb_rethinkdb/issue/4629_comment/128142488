IssueComment
  { issueCommentUpdatedAt = 2015 (-08) (-05) 20 : 44 : 36 UTC
  , issueCommentUser =
      SimpleUser
        { simpleUserId = Id 2608446
        , simpleUserLogin = N "Slava"
        , simpleUserAvatarUrl =
            "https://avatars.githubusercontent.com/u/2608446?v=3"
        , simpleUserUrl = "https://api.github.com/users/Slava"
        , simpleUserType = OwnerUser
        }
  , issueCommentUrl =
      "https://api.github.com/repos/rethinkdb/rethinkdb/issues/comments/128142488"
  , issueCommentHtmlUrl =
      "https://github.com/rethinkdb/rethinkdb/issues/4629#issuecomment-128142488"
  , issueCommentCreatedAt = 2015 (-08) (-05) 20 : 44 : 36 UTC
  , issueCommentBody =
      "@danielmewes I see.\r\n\r\nI think if the application-level driver gets the write IDs per write, it should be enough to have \"per primary key\" monotonically increasing write IDs.\r\n\r\nBut you need to think more, what happens when a query touches a lot of documents? Would you return write IDs for all of them? Like a query of `UPDATE collection SET field = field + 1 WHERE field > 20` and it updates 200 rows?\r\n\r\nIf the write IDs are monotonically increasing globally, then you can just return the latest ID."
  , issueCommentId = 128142488
  }