Issue
  { issueClosedAt = Nothing
  , issueUpdatedAt = 2014 (-02) (-21) 21 : 56 : 58 UTC
  , issueEventsUrl =
      "https://api.github.com/repos/rethinkdb/rethinkdb/issues/1653/events"
  , issueHtmlUrl =
      Just "https://github.com/rethinkdb/rethinkdb/issues/1653"
  , issueClosedBy = Nothing
  , issueLabels = []
  , issueNumber = 1653
  , issueAssignee = Nothing
  , issueUser =
      SimpleUser
        { simpleUserId = Id 139396
        , simpleUserLogin = N "wojons"
        , simpleUserAvatarUrl =
            "https://avatars.githubusercontent.com/u/139396?v=3"
        , simpleUserUrl = "https://api.github.com/users/wojons"
        , simpleUserType = OwnerUser
        }
  , issueTitle = "Feature: DC/Route"
  , issuePullRequest = Nothing
  , issueUrl =
      "https://api.github.com/repos/rethinkdb/rethinkdb/issues/1653"
  , issueCreatedAt = 2013 (-11) (-17) 23 : 00 : 22 UTC
  , issueBody =
      Just
        "When running large jobs in rethinkdb I see it max out the load average. This normally happanes with complex work loads. If i had 2 or more clusters of servers wraped in datacenter grouping i was thinking things like the following would work.\n\n``` js\nr.dc('analaytics').db('my_data').table('hello_world').beween('a', 'zzz').dc('superfast').filter(function(row){\n    return row(\"book\").match(\"*love*\")\n}).limit(10)\n```\n\n``` js\nr.dc('analaytics').db('my_data').table('hello_world').beween('a', 'zzz').dc('superfast', function(row){\n    return row(\"book\").match(\"*love*\")\n}).limit(10)\n```\n\nThere are many ways this could look like but the idea is if you have a server with super larger disks and complex results and it has a slow cpu and then you have a much faster cpu that you can processes a lot more data on it would be useful to be able to route parts of processing pipeline to other sets a of servers. Of course this means the command has to be run backwards or it will have to return back to the first servers. There are smart ways that it can be accomplished. if the processing servers are only filtering but they are not manipulating the data they can also send back the document id to pass onto the client making the request. \n"
  , issueState = "open"
  , issueId = Id 22807617
  , issueComments = 4
  , issueMilestone =
      Just
        Milestone
          { milestoneCreator =
              SimpleUser
                { simpleUserId = Id 48436
                , simpleUserLogin = N "coffeemug"
                , simpleUserAvatarUrl =
                    "https://avatars.githubusercontent.com/u/48436?v=3"
                , simpleUserUrl = "https://api.github.com/users/coffeemug"
                , simpleUserType = OwnerUser
                }
          , milestoneDueOn = Nothing
          , milestoneOpenIssues = 882
          , milestoneNumber = 2
          , milestoneClosedIssues = 0
          , milestoneDescription =
              Just
                "Issues in this milestone are not an immediate priority, and will be periodically revisited. When we decide to work on an issue in backlog, we'll move it to next."
          , milestoneTitle = "backlog"
          , milestoneUrl =
              "https://api.github.com/repos/rethinkdb/rethinkdb/milestones/2"
          , milestoneCreatedAt = 2012 (-11) (-11) 14 : 16 : 11 UTC
          , milestoneState = "open"
          }
  }