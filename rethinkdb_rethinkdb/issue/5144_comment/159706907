IssueComment
  { issueCommentUpdatedAt = 2015 (-11) (-25) 19 : 24 : 37 UTC
  , issueCommentUser =
      SimpleUser
        { simpleUserId = Id 505365
        , simpleUserLogin = N "danielmewes"
        , simpleUserAvatarUrl =
            "https://avatars.githubusercontent.com/u/505365?v=3"
        , simpleUserUrl = "https://api.github.com/users/danielmewes"
        , simpleUserType = OwnerUser
        }
  , issueCommentUrl =
      "https://api.github.com/repos/rethinkdb/rethinkdb/issues/comments/159706907"
  , issueCommentHtmlUrl =
      "https://github.com/rethinkdb/rethinkdb/issues/5144#issuecomment-159706907"
  , issueCommentCreatedAt = 2015 (-11) (-25) 19 : 24 : 37 UTC
  , issueCommentBody =
      "Oh I see, thanks for updating the description.\r\n\r\nSo this\r\n\r\n> If the cluster dies before table_sizes is updated: Once the cluster is restarted, it's just a matter of truncating all AO files to the number of bytes ascribed to them by table_sizes.\r\n\r\nwould actually require a completely new storage format for AO tables.\r\n\r\nOr alternatively we could somehow generate incrementing IDs by insertion order across the cluster, so that we could truncate the documents in the table through that. This might be a complex problem in itself."
  , issueCommentId = 159706907
  }