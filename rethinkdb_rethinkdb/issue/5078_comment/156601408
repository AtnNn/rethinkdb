IssueComment
  { issueCommentUpdatedAt = 2015 (-11) (-14) 00 : 55 : 50 UTC
  , issueCommentUser =
      SimpleUser
        { simpleUserId = Id 67937
        , simpleUserLogin = N "encryptio"
        , simpleUserAvatarUrl =
            "https://avatars.githubusercontent.com/u/67937?v=3"
        , simpleUserUrl = "https://api.github.com/users/encryptio"
        , simpleUserType = OwnerUser
        }
  , issueCommentUrl =
      "https://api.github.com/repos/rethinkdb/rethinkdb/issues/comments/156601408"
  , issueCommentHtmlUrl =
      "https://github.com/rethinkdb/rethinkdb/issues/5078#issuecomment-156601408"
  , issueCommentCreatedAt = 2015 (-11) (-14) 00 : 55 : 50 UTC
  , issueCommentBody =
      "Looking at this a bit closer, we are using the approximate counts, and that seems to work okay wrt the memory usage in the server process. (It still could be better if we limited concurrency properly at this stage.)\r\n\r\nThe python worker processes use 13-17MB each when they're idle, and the few active ones sit at 22-30MB before they exit. Overall memory usage for the system linearly dwindles down to normal as the export continues. Meanwhile, the `rethinkdb` server memory only changes a relatively small amount (100MB total when exporting 600 tables.)\r\n\r\nLooks like limiting the `export` process count is the best use of development time by far to fix this problem (see #4809)."
  , issueCommentId = 156601408
  }